{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCR3P5ElkzLDqDN+SJEkWX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiwoo1004/python/blob/main/%EC%8B%AC%EC%9E%A5%EB%B3%91_%EB%B0%9C%EB%B3%91_%EC%98%88%EC%B8%A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "OWo-RwlNFfo4",
        "outputId": "6084bbf1-f088-4988-9ab2-0c247503b647"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1272747f-e592-4a7d-889e-04def9d2ce15\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1272747f-e592-4a7d-889e-04def9d2ce15\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving heart disease classification dataset.csv to heart disease classification dataset (3).csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "thalach       5\n",
              "trestbps      4\n",
              "chol          1\n",
              "Unnamed: 0    0\n",
              "age           0\n",
              "sex           0\n",
              "cp            0\n",
              "fbs           0\n",
              "restecg       0\n",
              "exang         0\n",
              "oldpeak       0\n",
              "slope         0\n",
              "ca            0\n",
              "thal          0\n",
              "target        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "myfile = files.upload()\n",
        "df = pd.read_csv('heart disease classification dataset.csv')\n",
        "\n",
        "df.isnull().sum().sort_values(ascending=False).head(20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[:,['thalach','trestbps','chol']] = pd.get_dummies(df.loc[:,['thalach','trestbps','chol']])\n",
        "\n",
        "df.loc[:,['thalach','trestbps','chol']] = df.loc[:,['thalach','trestbps','chol']].fillna(df.loc[:,['thalach','trestbps','chol']].mean())\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "46TC8TQNHtQx",
        "outputId": "d40cf5fb-9f4c-497a-f5f2-66ed4d241a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  age     sex  cp    trestbps   chol  fbs  restecg  thalach  \\\n",
              "0             0   63    male   3  145.000000  233.0    1        0    150.0   \n",
              "1             1   37    male   2  130.000000  250.0    0        1    187.0   \n",
              "2             2   41  female   1  130.000000  204.0    0        0    172.0   \n",
              "3             3   56    male   1  120.000000  236.0    0        1    178.0   \n",
              "4             4   57  female   0  131.712375  354.0    0        1    163.0   \n",
              "..          ...  ...     ...  ..         ...    ...  ...      ...      ...   \n",
              "298         298   57  female   0  140.000000  241.0    0        1    123.0   \n",
              "299         299   45    male   3  110.000000  264.0    0        1    132.0   \n",
              "300         300   68    male   0  144.000000  193.0    1        1    141.0   \n",
              "301         301   57    male   0  131.712375  131.0    0        1    115.0   \n",
              "302         302   57  female   1  130.000000  236.0    0        0    174.0   \n",
              "\n",
              "     exang  oldpeak  slope  ca  thal target  \n",
              "0        0      2.3      0   0     1    yes  \n",
              "1        0      3.5      0   0     2    yes  \n",
              "2        0      1.4      2   0     2    yes  \n",
              "3        0      0.8      2   0     2    yes  \n",
              "4        1      0.6      2   0     2    yes  \n",
              "..     ...      ...    ...  ..   ...    ...  \n",
              "298      1      0.2      1   0     3     no  \n",
              "299      0      1.2      1   0     3     no  \n",
              "300      0      3.4      1   2     3     no  \n",
              "301      1      1.2      1   1     3     no  \n",
              "302      0      0.0      1   1     2     no  \n",
              "\n",
              "[303 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22b2c8c3-4284-4997-9600-419c78d5407b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>male</td>\n",
              "      <td>3</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>233.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>male</td>\n",
              "      <td>2</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>41</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>204.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>56</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>236.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>57</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>131.712375</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>298</td>\n",
              "      <td>57</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>241.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>123.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>299</td>\n",
              "      <td>45</td>\n",
              "      <td>male</td>\n",
              "      <td>3</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>264.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>300</td>\n",
              "      <td>68</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>193.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>141.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>301</td>\n",
              "      <td>57</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>131.712375</td>\n",
              "      <td>131.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>115.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>302</td>\n",
              "      <td>57</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>236.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22b2c8c3-4284-4997-9600-419c78d5407b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22b2c8c3-4284-4997-9600-419c78d5407b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22b2c8c3-4284-4997-9600-419c78d5407b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[:,2] = pd.get_dummies(df.iloc[:,2])\n",
        "df.iloc[:,14] = pd.get_dummies(df.iloc[:,14])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_HTiw4LUloeK",
        "outputId": "0c8c7213-724d-4c7f-bd52-ee01887c58ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  age  sex  cp    trestbps   chol  fbs  restecg  thalach  \\\n",
              "0             0   63    0   3  145.000000  233.0    1        0    150.0   \n",
              "1             1   37    0   2  130.000000  250.0    0        1    187.0   \n",
              "2             2   41    1   1  130.000000  204.0    0        0    172.0   \n",
              "3             3   56    0   1  120.000000  236.0    0        1    178.0   \n",
              "4             4   57    1   0  131.712375  354.0    0        1    163.0   \n",
              "..          ...  ...  ...  ..         ...    ...  ...      ...      ...   \n",
              "298         298   57    1   0  140.000000  241.0    0        1    123.0   \n",
              "299         299   45    0   3  110.000000  264.0    0        1    132.0   \n",
              "300         300   68    0   0  144.000000  193.0    1        1    141.0   \n",
              "301         301   57    0   0  131.712375  131.0    0        1    115.0   \n",
              "302         302   57    1   1  130.000000  236.0    0        0    174.0   \n",
              "\n",
              "     exang  oldpeak  slope  ca  thal  target  \n",
              "0        0      2.3      0   0     1       0  \n",
              "1        0      3.5      0   0     2       0  \n",
              "2        0      1.4      2   0     2       0  \n",
              "3        0      0.8      2   0     2       0  \n",
              "4        1      0.6      2   0     2       0  \n",
              "..     ...      ...    ...  ..   ...     ...  \n",
              "298      1      0.2      1   0     3       1  \n",
              "299      0      1.2      1   0     3       1  \n",
              "300      0      3.4      1   2     3       1  \n",
              "301      1      1.2      1   1     3       1  \n",
              "302      0      0.0      1   1     2       1  \n",
              "\n",
              "[303 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90e4fa46-bffc-489a-832e-0ea1d2882b49\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>233.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>204.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>236.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>131.712375</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>298</td>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>241.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>123.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>299</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>264.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>300</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>193.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>141.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>301</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>131.712375</td>\n",
              "      <td>131.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>115.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>302</td>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>236.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90e4fa46-bffc-489a-832e-0ea1d2882b49')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90e4fa46-bffc-489a-832e-0ea1d2882b49 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90e4fa46-bffc-489a-832e-0ea1d2882b49');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_df = (df - df.mean())/df.std()\n",
        "\n",
        "normalization_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "v7iL_WF0H5Sc",
        "outputId": "b93767eb-ed7c-4b88-ca93-9ee0e5725a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0       age       sex        cp      trestbps      chol  \\\n",
              "0     -1.723493  0.950624 -0.679881  1.969864  7.587772e-01 -0.256991   \n",
              "1     -1.712079 -1.912150 -0.679881  1.000921 -9.778352e-02  0.071053   \n",
              "2     -1.700665 -1.471723  1.465992  0.031978 -9.778352e-02 -0.816596   \n",
              "3     -1.689251  0.179877 -0.679881  0.031978 -6.688240e-01 -0.199101   \n",
              "4     -1.677837  0.289984  1.465992 -0.936965 -1.622995e-15  2.077912   \n",
              "..          ...       ...       ...       ...           ...       ...   \n",
              "298    1.677837  0.289984  1.465992 -0.936965  4.732569e-01 -0.102618   \n",
              "299    1.689251 -1.031296 -0.679881  1.969864 -1.239864e+00  0.341207   \n",
              "300    1.700665  1.501157 -0.679881 -0.936965  7.016731e-01 -1.028860   \n",
              "301    1.712079  0.289984 -0.679881 -0.936965 -1.622995e-15 -2.225257   \n",
              "302    1.723493  0.289984  1.465992  0.031978 -9.778352e-02 -0.199101   \n",
              "\n",
              "          fbs   restecg   thalach    exang   oldpeak     slope        ca  \\\n",
              "0    2.390484 -1.004171  0.005999 -0.69548  1.085542 -2.270822 -0.713249   \n",
              "1   -0.416945  0.897478  1.659547 -0.69548  2.119067 -2.270822 -0.713249   \n",
              "2   -0.416945 -1.004171  0.989190 -0.69548  0.310399  0.974740 -0.713249   \n",
              "3   -0.416945  0.897478  1.257333 -0.69548 -0.206364  0.974740 -0.713249   \n",
              "4   -0.416945  0.897478  0.586975  1.43311 -0.378618  0.974740 -0.713249   \n",
              "..        ...       ...       ...      ...       ...       ...       ...   \n",
              "298 -0.416945  0.897478 -1.200645  1.43311 -0.723126 -0.648041 -0.713249   \n",
              "299 -0.416945  0.897478 -0.798430 -0.69548  0.138144 -0.648041 -0.713249   \n",
              "300  2.390484  0.897478 -0.396216 -0.69548  2.032940 -0.648041  1.242538   \n",
              "301 -0.416945  0.897478 -1.558169  1.43311  0.138144 -0.648041  0.264644   \n",
              "302 -0.416945 -1.004171  1.078571 -0.69548 -0.895381 -0.648041  0.264644   \n",
              "\n",
              "         thal    target  \n",
              "0   -2.145324 -0.913019  \n",
              "1   -0.512075 -0.913019  \n",
              "2   -0.512075 -0.913019  \n",
              "3   -0.512075 -0.913019  \n",
              "4   -0.512075 -0.913019  \n",
              "..        ...       ...  \n",
              "298  1.121174  1.091653  \n",
              "299  1.121174  1.091653  \n",
              "300  1.121174  1.091653  \n",
              "301  1.121174  1.091653  \n",
              "302 -0.512075  1.091653  \n",
              "\n",
              "[303 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-646fc2e1-f34c-4dd7-b377-fd2b8bcf2478\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.723493</td>\n",
              "      <td>0.950624</td>\n",
              "      <td>-0.679881</td>\n",
              "      <td>1.969864</td>\n",
              "      <td>7.587772e-01</td>\n",
              "      <td>-0.256991</td>\n",
              "      <td>2.390484</td>\n",
              "      <td>-1.004171</td>\n",
              "      <td>0.005999</td>\n",
              "      <td>-0.69548</td>\n",
              "      <td>1.085542</td>\n",
              "      <td>-2.270822</td>\n",
              "      <td>-0.713249</td>\n",
              "      <td>-2.145324</td>\n",
              "      <td>-0.913019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.712079</td>\n",
              "      <td>-1.912150</td>\n",
              "      <td>-0.679881</td>\n",
              "      <td>1.000921</td>\n",
              "      <td>-9.778352e-02</td>\n",
              "      <td>0.071053</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>0.897478</td>\n",
              "      <td>1.659547</td>\n",
              "      <td>-0.69548</td>\n",
              "      <td>2.119067</td>\n",
              "      <td>-2.270822</td>\n",
              "      <td>-0.713249</td>\n",
              "      <td>-0.512075</td>\n",
              "      <td>-0.913019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.700665</td>\n",
              "      <td>-1.471723</td>\n",
              "      <td>1.465992</td>\n",
              "      <td>0.031978</td>\n",
              "      <td>-9.778352e-02</td>\n",
              "      <td>-0.816596</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>-1.004171</td>\n",
              "      <td>0.989190</td>\n",
              "      <td>-0.69548</td>\n",
              "      <td>0.310399</td>\n",
              "      <td>0.974740</td>\n",
              "      <td>-0.713249</td>\n",
              "      <td>-0.512075</td>\n",
              "      <td>-0.913019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.689251</td>\n",
              "      <td>0.179877</td>\n",
              "      <td>-0.679881</td>\n",
              "      <td>0.031978</td>\n",
              "      <td>-6.688240e-01</td>\n",
              "      <td>-0.199101</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>0.897478</td>\n",
              "      <td>1.257333</td>\n",
              "      <td>-0.69548</td>\n",
              "      <td>-0.206364</td>\n",
              "      <td>0.974740</td>\n",
              "      <td>-0.713249</td>\n",
              "      <td>-0.512075</td>\n",
              "      <td>-0.913019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.677837</td>\n",
              "      <td>0.289984</td>\n",
              "      <td>1.465992</td>\n",
              "      <td>-0.936965</td>\n",
              "      <td>-1.622995e-15</td>\n",
              "      <td>2.077912</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>0.897478</td>\n",
              "      <td>0.586975</td>\n",
              "      <td>1.43311</td>\n",
              "      <td>-0.378618</td>\n",
              "      <td>0.974740</td>\n",
              "      <td>-0.713249</td>\n",
              "      <td>-0.512075</td>\n",
              "      <td>-0.913019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>1.677837</td>\n",
              "      <td>0.289984</td>\n",
              "      <td>1.465992</td>\n",
              "      <td>-0.936965</td>\n",
              "      <td>4.732569e-01</td>\n",
              "      <td>-0.102618</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>0.897478</td>\n",
              "      <td>-1.200645</td>\n",
              "      <td>1.43311</td>\n",
              "      <td>-0.723126</td>\n",
              "      <td>-0.648041</td>\n",
              "      <td>-0.713249</td>\n",
              "      <td>1.121174</td>\n",
              "      <td>1.091653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>1.689251</td>\n",
              "      <td>-1.031296</td>\n",
              "      <td>-0.679881</td>\n",
              "      <td>1.969864</td>\n",
              "      <td>-1.239864e+00</td>\n",
              "      <td>0.341207</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>0.897478</td>\n",
              "      <td>-0.798430</td>\n",
              "      <td>-0.69548</td>\n",
              "      <td>0.138144</td>\n",
              "      <td>-0.648041</td>\n",
              "      <td>-0.713249</td>\n",
              "      <td>1.121174</td>\n",
              "      <td>1.091653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>1.700665</td>\n",
              "      <td>1.501157</td>\n",
              "      <td>-0.679881</td>\n",
              "      <td>-0.936965</td>\n",
              "      <td>7.016731e-01</td>\n",
              "      <td>-1.028860</td>\n",
              "      <td>2.390484</td>\n",
              "      <td>0.897478</td>\n",
              "      <td>-0.396216</td>\n",
              "      <td>-0.69548</td>\n",
              "      <td>2.032940</td>\n",
              "      <td>-0.648041</td>\n",
              "      <td>1.242538</td>\n",
              "      <td>1.121174</td>\n",
              "      <td>1.091653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>1.712079</td>\n",
              "      <td>0.289984</td>\n",
              "      <td>-0.679881</td>\n",
              "      <td>-0.936965</td>\n",
              "      <td>-1.622995e-15</td>\n",
              "      <td>-2.225257</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>0.897478</td>\n",
              "      <td>-1.558169</td>\n",
              "      <td>1.43311</td>\n",
              "      <td>0.138144</td>\n",
              "      <td>-0.648041</td>\n",
              "      <td>0.264644</td>\n",
              "      <td>1.121174</td>\n",
              "      <td>1.091653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>1.723493</td>\n",
              "      <td>0.289984</td>\n",
              "      <td>1.465992</td>\n",
              "      <td>0.031978</td>\n",
              "      <td>-9.778352e-02</td>\n",
              "      <td>-0.199101</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>-1.004171</td>\n",
              "      <td>1.078571</td>\n",
              "      <td>-0.69548</td>\n",
              "      <td>-0.895381</td>\n",
              "      <td>-0.648041</td>\n",
              "      <td>0.264644</td>\n",
              "      <td>-0.512075</td>\n",
              "      <td>1.091653</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-646fc2e1-f34c-4dd7-b377-fd2b8bcf2478')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-646fc2e1-f34c-4dd7-b377-fd2b8bcf2478 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-646fc2e1-f34c-4dd7-b377-fd2b8bcf2478');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "RANDOM_SEED = 3\n",
        "np.random.seed(RANDOM_SEED)\n",
        "x=normalization_df.iloc[:,1:14]\n",
        "\n",
        "y=df.iloc[:,14]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1,random_state=3)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10,  input_dim=13, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(30,  activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(40,  activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "modelpath=\"./data/model/Ch15-house.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=2000, batch_size=30, validation_split=0.2, callbacks=[early_stopping_callback, checkpointer])\n",
        "\n",
        "loss = model.evaluate(x_train,y_train)\n",
        "print('accuracy:',loss)\n",
        "\n",
        "y_loss = history.history['loss']\n",
        "y_accu = history.history['accuracy']\n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "\n",
        "plt.plot(x_len,y_loss)\n",
        "plt.plot(x_len,y_accu, marker='.', c=\"red\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cHpgwe5DMY_Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a960bd6a-96ce-4bbe-ca33-43011e90ff7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 10)                140       \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 30)                330       \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 30)                0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,751\n",
            "Trainable params: 1,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2000\n",
            "8/8 [==============================] - 1s 32ms/step - loss: 0.5078 - accuracy: 0.5300 - val_loss: 0.3603 - val_accuracy: 0.4909\n",
            "Epoch 2/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2956 - accuracy: 0.5530 - val_loss: 0.3180 - val_accuracy: 0.4909\n",
            "Epoch 3/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.3011 - accuracy: 0.5853 - val_loss: 0.2852 - val_accuracy: 0.5273\n",
            "Epoch 4/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.2542 - accuracy: 0.6175 - val_loss: 0.2579 - val_accuracy: 0.5818\n",
            "Epoch 5/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2487 - accuracy: 0.6452 - val_loss: 0.2473 - val_accuracy: 0.6000\n",
            "Epoch 6/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2443 - accuracy: 0.6406 - val_loss: 0.2343 - val_accuracy: 0.6364\n",
            "Epoch 7/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2230 - accuracy: 0.6820 - val_loss: 0.2236 - val_accuracy: 0.6909\n",
            "Epoch 8/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2308 - accuracy: 0.6636 - val_loss: 0.2176 - val_accuracy: 0.6909\n",
            "Epoch 9/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2201 - accuracy: 0.6774 - val_loss: 0.2108 - val_accuracy: 0.6909\n",
            "Epoch 10/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2008 - accuracy: 0.6959 - val_loss: 0.2098 - val_accuracy: 0.6727\n",
            "Epoch 11/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1869 - accuracy: 0.7327 - val_loss: 0.2051 - val_accuracy: 0.6909\n",
            "Epoch 12/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1949 - accuracy: 0.7327 - val_loss: 0.2019 - val_accuracy: 0.6909\n",
            "Epoch 13/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1876 - accuracy: 0.7235 - val_loss: 0.1982 - val_accuracy: 0.6364\n",
            "Epoch 14/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1746 - accuracy: 0.7419 - val_loss: 0.1945 - val_accuracy: 0.6545\n",
            "Epoch 15/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1827 - accuracy: 0.7097 - val_loss: 0.1912 - val_accuracy: 0.6727\n",
            "Epoch 16/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1820 - accuracy: 0.7604 - val_loss: 0.1867 - val_accuracy: 0.7091\n",
            "Epoch 17/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1773 - accuracy: 0.7788 - val_loss: 0.1848 - val_accuracy: 0.7091\n",
            "Epoch 18/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1877 - accuracy: 0.7143 - val_loss: 0.1858 - val_accuracy: 0.7091\n",
            "Epoch 19/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1682 - accuracy: 0.7512 - val_loss: 0.1823 - val_accuracy: 0.7273\n",
            "Epoch 20/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1626 - accuracy: 0.7696 - val_loss: 0.1793 - val_accuracy: 0.7455\n",
            "Epoch 21/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1760 - accuracy: 0.7512 - val_loss: 0.1786 - val_accuracy: 0.7273\n",
            "Epoch 22/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1691 - accuracy: 0.7604 - val_loss: 0.1819 - val_accuracy: 0.7273\n",
            "Epoch 23/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1660 - accuracy: 0.7696 - val_loss: 0.1820 - val_accuracy: 0.7455\n",
            "Epoch 24/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1390 - accuracy: 0.8341 - val_loss: 0.1738 - val_accuracy: 0.7455\n",
            "Epoch 25/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1543 - accuracy: 0.8157 - val_loss: 0.1718 - val_accuracy: 0.7818\n",
            "Epoch 26/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1504 - accuracy: 0.7788 - val_loss: 0.1703 - val_accuracy: 0.7636\n",
            "Epoch 27/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1504 - accuracy: 0.7650 - val_loss: 0.1661 - val_accuracy: 0.7455\n",
            "Epoch 28/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1516 - accuracy: 0.7972 - val_loss: 0.1677 - val_accuracy: 0.7455\n",
            "Epoch 29/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1481 - accuracy: 0.8111 - val_loss: 0.1707 - val_accuracy: 0.7455\n",
            "Epoch 30/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1379 - accuracy: 0.8479 - val_loss: 0.1714 - val_accuracy: 0.7636\n",
            "Epoch 31/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1478 - accuracy: 0.8065 - val_loss: 0.1693 - val_accuracy: 0.7273\n",
            "Epoch 32/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1362 - accuracy: 0.8249 - val_loss: 0.1695 - val_accuracy: 0.7636\n",
            "Epoch 33/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1405 - accuracy: 0.8341 - val_loss: 0.1685 - val_accuracy: 0.7636\n",
            "Epoch 34/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1343 - accuracy: 0.8571 - val_loss: 0.1663 - val_accuracy: 0.7636\n",
            "Epoch 35/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1307 - accuracy: 0.8387 - val_loss: 0.1629 - val_accuracy: 0.7455\n",
            "Epoch 36/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1186 - accuracy: 0.8802 - val_loss: 0.1609 - val_accuracy: 0.7273\n",
            "Epoch 37/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1459 - accuracy: 0.8295 - val_loss: 0.1658 - val_accuracy: 0.7273\n",
            "Epoch 38/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1270 - accuracy: 0.8433 - val_loss: 0.1615 - val_accuracy: 0.7818\n",
            "Epoch 39/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1313 - accuracy: 0.8479 - val_loss: 0.1613 - val_accuracy: 0.7455\n",
            "Epoch 40/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1314 - accuracy: 0.8203 - val_loss: 0.1681 - val_accuracy: 0.7636\n",
            "Epoch 41/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1392 - accuracy: 0.8341 - val_loss: 0.1672 - val_accuracy: 0.7636\n",
            "Epoch 42/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1358 - accuracy: 0.7972 - val_loss: 0.1675 - val_accuracy: 0.7273\n",
            "Epoch 43/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1162 - accuracy: 0.8341 - val_loss: 0.1672 - val_accuracy: 0.7273\n",
            "Epoch 44/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1251 - accuracy: 0.8433 - val_loss: 0.1625 - val_accuracy: 0.7455\n",
            "Epoch 45/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.1343 - accuracy: 0.8249 - val_loss: 0.1597 - val_accuracy: 0.7455\n",
            "Epoch 46/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1111 - accuracy: 0.8571 - val_loss: 0.1610 - val_accuracy: 0.7273\n",
            "Epoch 47/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1151 - accuracy: 0.9078 - val_loss: 0.1640 - val_accuracy: 0.7455\n",
            "Epoch 48/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1080 - accuracy: 0.8756 - val_loss: 0.1680 - val_accuracy: 0.7455\n",
            "Epoch 49/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1175 - accuracy: 0.8664 - val_loss: 0.1697 - val_accuracy: 0.7273\n",
            "Epoch 50/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1190 - accuracy: 0.8571 - val_loss: 0.1696 - val_accuracy: 0.7273\n",
            "Epoch 51/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1207 - accuracy: 0.8433 - val_loss: 0.1704 - val_accuracy: 0.7091\n",
            "Epoch 52/2000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1241 - accuracy: 0.8479 - val_loss: 0.1707 - val_accuracy: 0.7273\n",
            "Epoch 53/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.8664 - val_loss: 0.1698 - val_accuracy: 0.7273\n",
            "Epoch 54/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1149 - accuracy: 0.8664 - val_loss: 0.1627 - val_accuracy: 0.7455\n",
            "Epoch 55/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1086 - accuracy: 0.8848 - val_loss: 0.1620 - val_accuracy: 0.7091\n",
            "Epoch 56/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1081 - accuracy: 0.8710 - val_loss: 0.1688 - val_accuracy: 0.7273\n",
            "Epoch 57/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.8525 - val_loss: 0.1687 - val_accuracy: 0.7273\n",
            "Epoch 58/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1054 - accuracy: 0.8894 - val_loss: 0.1697 - val_accuracy: 0.7091\n",
            "Epoch 59/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 0.8571 - val_loss: 0.1766 - val_accuracy: 0.7273\n",
            "Epoch 60/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.8756 - val_loss: 0.1762 - val_accuracy: 0.7273\n",
            "Epoch 61/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1028 - accuracy: 0.8940 - val_loss: 0.1761 - val_accuracy: 0.7455\n",
            "Epoch 62/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1080 - accuracy: 0.8710 - val_loss: 0.1747 - val_accuracy: 0.7455\n",
            "Epoch 63/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.8618 - val_loss: 0.1732 - val_accuracy: 0.7636\n",
            "Epoch 64/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1134 - accuracy: 0.8525 - val_loss: 0.1725 - val_accuracy: 0.7636\n",
            "Epoch 65/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.8894 - val_loss: 0.1690 - val_accuracy: 0.7455\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1003 - accuracy: 0.8713\n",
            "accuracy: [0.10030906647443771, 0.8713235259056091]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3zU9f3A8dc7CUnIYISEFaaAKAKCBgEnoigucFXFUbEq1p8Drdq6itW2qNW6x6OWqq3W4q6KVFSWAhEJskEgzIQZ9sx+//743JFLckmO5JLLJe/n43GP3Hfc9/vOEd73uc8UVcUYY0z4iwh1AMYYY4LDEroxxjQQltCNMaaBsIRujDENhCV0Y4xpIKJCdePk5GTt0qVLqG5vjDFhaf78+TtUNcXfsZAl9C5dupCRkRGq2xtjTFgSkQ0VHbMqF2OMaSAsoRtjTANhCd0YYxoIS+jGGNNAWEI3xpgGwhK6McY0EJbQjTH+pafDk0+6nyYsBNQPXUSGAy8CkcAEVX2qzPHOwJtACrALuF5Vs4McqzGmrqSnw9lnQ0EBxMTA1KkweHCoozJVqLKELiKRwKvABUAvYJSI9Cpz2rPAv1S1L/AE8GSwAzXG1KHp0yEvD4qLIT8fZswIdUQmAIFUuZwCZKrqWlXNByYCI8uc0wuY5nk+3c9xY0w4adWq5LkqDBkSslBM4AJJ6KlAls92tmefr0XA5Z7nlwGJItKqzDmIyBgRyRCRjJycnOrEa4ypCz/+CE2bukReXAx79oQ6otCaMSMs2hOC1Sh6P3CWiCwAzgI2AUVlT1LVN1Q1TVXTUlL8zi1jjAm1Awfggw/g2mthyhQ49li46y7IzQ11ZDVT3UbeP/3JtSc88gicc07Nk/pXX9Xah0MgjaKbgI4+2x08+45Q1c14SugikgBcoaqN/CPdmDD10Ucuqd90E0RHw8svw/nnw7PPwqOPhjo6lwhnzHDfHgJtqE1Pd+fn50NsLEybFthr33oLxo1zz1Vdu8KMGdVvIJ40CS65BERcHEFubA6khD4P6CEiXUUkGrgG+Nz3BBFJFhHvtR7C9XgxpnFpKN383nzTlcpPPdVtn3ceXHkljB8P69eHNDRmz4Yzz4SHH4ahQwN/r6dOdckc3DeNQBp5X3kFfvUrSEtz1U/gqp9qUrvw5z+7n6q10thcZUJX1ULgTmAKsAL4QFWXicgTIjLCc9oQYKWIrALaAH8OapTG1HfeRPPoo8H5Wh4qq1bB99+7RCZSsv+559z2jTeG7kOrqAjGjoXCQredmwuvvRbYaw8eLL0dE1PxuenpMHy4q2YaOdK9H1OnuiqX9u3dv/HGjUcf/7p1MG8eREa6R3R08BubVTUkj5NPPlmNaTCuv17VlbtUIyNVx48PdUTV89BDLv7Nm8sfu/129/uJqDZtqjpnTt3FlZ+vevXV7v5RUS5GEbc9Zozq1KnuPfcX0+HDqh06qJ5wguoTT6h27Kjavbtqbm75c2fPdtf3/jt+913p48uWqTZr5l7/2GNH9x788peqsbGqn31WcawBADK0grxqCd2YmioudsnCm9BjY+s22QVLQYFq+/aqF1/s//gf/1jyO4Lq5Zer5uW537UGCaqUsteaM8cl4dNOc/d8+umSc2bOVP3tb0s+ZCIi/H/QPPecO2faNLc9ZYrb/tOfSp9XXKx66qlVfzB7rweBf7AtXepivP/+o39PyrCEbkxtmjnT/Ve69lr389ZbQx1R9Xz5pYv/44/9H58zxyWwiIiS0nFKimqTJi751bTUPnu2akyMu350tOptt7mf3uR5333+X3fzzSXnRESUTsL79qkmJ6sOG1b6NVdc4eJdv95tFxaq3nJL6W8AFf0+48eX/P6geuaZqlu2VP67XX65amKi6o4dgb8fFbCEbkxtuvBCl9gOHVIdOlT1mGNUi4pCHdXRu+IKl/zy8io+x1s6nj3blXS7di1JbCKqv/999e5dVKQ6aFDpbwC+j7KJumxMsbEl5770Usmxxx93+378sfRrNmxQjYtTvewyV50zapQ77/e/d79bZd84vB9skZElVT8xMS5pP/BA+df9+KO79uOPV++9KcMSujE1MWeO+3ru7z/4okVa6uv7u++67enT6zTEGps82SXNq68+utfNmeOSmTeZxsWpXnedq4sPtLReUKA6enTp0nFsrOq4ce5nIKX/OXPcPbt2dfFMmqSak+NKxZdf7v81Tz7p7pmaqkeqc47m9/Ym/VWrVC+5pOQ9iIxUfe+9knOHDXMflPv2BX79SlhCN6a6fBvJYmLKJ5Vrr1VNSFDdtcttHzzoGs1uuKHuY62uOXNctUl16/+9ye2f/1Q999ySxNakiXv/KpOXp/qLX5SUYMuWjo+2fn7HDtWTT3b/Zv37u9Lzv//t/9yZM0uqTpo0qVl10fjxLpGXbWP4zW/c87vvrv61y7CEbhqfYDXUXXRR6f+kt91WcmztWvefuGzd7m23uRLl3r11G2t1eRsWg9FDZ/x4V9L3Xu+EE1R37vR/7vTpqj17uvOefbb69yxrzx7Vvn1LYqisLtwba01/b99qmNhY1Ztuch/0R9t4GgBL6KZxmTPHNabVtHvd5MklvSd860q/+cYdv+MOV7LLzi79urlz3X+tN97wH5u3h8bs2a4roLeRsba6Alb1gXH22SVJraYx+CY2b2Npaqqr1x4/XvXbb937d9NNwSsd+/OHP5Rcv6Jk7RtrMN77su/zuHFVx1ANltBN4+JtCKuqMa0yS5a4+td+/VwSGj/e1cv26eM+LB56yH2t99fFz9uNcdCg0vu9HzTVafirrokTXZwVden7+ms90jOnNroezp+v2qlT+d/Vt5dIbfTbDzRZ1+a3o2B/YHhYQjehV5fVCnfcUTpJHs0958xRffhh1bZt3SMrq/TxnTtVjz++5PoV1Tn/9a/u+LJlbvvgQdVTTimd0K67zn1ING1asv+LLyqPrar30HvO22+rXnVV5R8YeXmuyqNbNzf4prb4lpZFXAPoN9/USrIrJdRVWbUUgyV0E1renhC1+Z/Xa88e1aQk1YEDS+q/q2qY843TN7lOmOD/vHHjqi5dbtvmjp1xhkuu3g8Bf32c58xRveceV3q/4AJXwi9r+nR3vLL3sGz3vbg41zjru+/hh0vOf+opt2/y5MDen+qqqKRaHxJuGLKEbkLr3nurToDB4k228+erHjjgkvuIEVW/btMm1dNPr7g06yuQr9Jz5pTu9ZCc7EqllSWxl15y5772Wun9S5e6bwtVvYdPPFH6G4C3T/icOa6UPGCAO/byy6obN7qEf+mlVb83wWDJO2gsoZvQ8q0CEal4JGJNbd/uehb84hcl+x57TEtVfZT14YeuKiQqysXmHSwSSL/nyhJU2d4ejz5adfxFRarnn+/u/fPPrqT+8suuhN2yZUm1RUWxebvIVVRfnpurOnKkHul7HRVVe/8WptZYQjehdcYZbjKjX/9aNT7eTY60alXw73PvvS6ZrVhRsi8nx5VEb7yx/PnPPFO61PvBB8ErSVa3QWzTJvetomfPki59F16ounWr6ptvuu2bby7/ugMHVNu0cX2v//zniu+Xn+8Gung/XOt6ki1TY5bQTejs2OGSrLeE+tNPrvohKUl17NjgJZONG109/U03lT92992uNLphQ8m+Dz4oXYKurZ4W1flwGD++JK6yg3OuuML1vsnJ8f+aQO71pz8Fr/+1qXOW0E3ovPOO+zObO7dk33vvlSSsYMxMOGeOalqaS9reyZZ8rV/vjt1zj9t++22X0Pr0qf2eFtVR2YCX5cvdMd/BTLt2qbZo4YafB6KWutOZulFZQg9kCTpjqm/SJGjTxq364rV+PUREuNVfarqkV3q6W+8xLw+iomDzZujcufQ5nTvDqFHw+uuwfDl8/TUMGwaffgqLFx/9cma1bcgQtwBDfn75RRCOPx5++Uu3ms4990CHDvDMM7B3r1v7MhCDB7sFG+rb721qrqJM7/sAhgMrgUzgQT/HOwHTgQXAYuDCqq5pJfRGID9ftXlz1V/9qvR+bwnR28g3cWL1rp+Xp3rWWYFVm3i/KXgbDev75FmVVdesW+eqYsaMcdO2xsW5OWVMo0AlJfQql6ATkUjgVeACoBcwSkR6lTntUdzSdP1xa44GuC6UadC+/96VHC+5pPR+bwnxoYfcQrn//e/RXTc9He67D048EWbODGxJr6yskiXVROr/EnGDB7v3x1/puUsX+PWvYcIEt65mbi48/nidh2jqn0CqXE4BMlV1LYCITARGAst9zlGgmed5c2BzMIM0YeqLL1zVwbBh5Y8NHuweIm7h3N/9Dvr1q/qavqu3g3vt2WdXXX0wZIj78PBXjRGOzj8fXn4ZVqxwH2Y5OdC9e6ijMiFWZQkdSAWyfLazPft8/QG4XkSygcnAXf4uJCJjRCRDRDJycnKqEa4JG6ouoQ8dCvHxFZ93//3QsqVbeDcQb71VkswjI90HQmWlWS/vt4I//tH9DPd648WLSy/iHOTV4014CiShB2IU8LaqdgAuBN4RkXLXVtU3VDVNVdNSUlKCdGtTL/38M6xZU766pawWLVzp/MsvYfbsys8tKHDJWKR6q6YHkvjDhfcbR22tHm/CUiBVLpuAjj7bHTz7fN2MazhFVdNFJBZIBrYHI0gThr74wv28+OKqz73zTnjhBZdsZ84sXfL09corsHYtPPWU6yHTmHtoWE8V44e4RtNKThCJAlYB5+AS+TzgWlVd5nPO/4D3VfVtETkemAqkaiUXT0tL04yMjCD8CqZS6emh+U9/5pmwfz8sWBDY+a++6hL76NEwZkz5WLdsgZ494YwzXFfIipK+MQ2ciMxX1TR/x6qsclHVQuBOYAqwAtebZZmIPCEiIzyn3QfcKiKLgP8AoytL5qaOeBsQH34Yzjmn7np27Nzpqk+qqm7x1aePS9Jvv+3q3cvG+sADru78pZcsmRtTgYAGFqnqZFxjp+++cT7PlwOnBTc0U2Mvv1zSgFidATzVLd2/9JKrEik7wKcys2e7RK3quuG9+GLJPWfOhH//G37/e+jWLfBrGtPI2EjRhurtt2HixJIRmSJH13A2c6brblhU5LoeBtozZOrUkhGLd90FvXoF9jrf0ZGq8P77bvvaa93IyLZt4cEHA4/fmEYoWL1cTH2Rng4jRsBNN8G558I337j+3XFxMGBAYNc4eBBuucX1Kikudkm2om5x6enw5JMwZQo88YSrZikudscqe11Zvt0KZ8yAcePgnXdg+HDYvh127YJFiwK7ljGNlJXQG5L0dDjrLJeIIyJc3bm3Dv2qq9zxM86o/Bp797qeKWvWuLlRCgtdKb1dO//3GzrUVed4m0xOPx3mzXOvq063Qm9p/owzYNs2+Nvf3HZRUc3mfDGmEbASekPy3nsumUPp4e3nnw9NmpR0JazIzp2u8fSHH1x1zXffuSH2bdvC2LGl+4mvXesmh8rNdclcBO6+2w33nz49OAN4brwRmja1vtbGBKjKbou1xbot1oIrr4SPPy5JgL4JddgwyM52Q8X9mTTJVbPs2gWffFK6/3hWlqu+2bDB7T9wAL79tqQRE8rfL1hC1e3SmHqqsm6LVuXSUOTmwrRpLnGffXb5BHjJJa6UnZlZfs6PWbNcvbuqa4hs1ar08Y4d4bnn3DU+/tjtGzUKnn3WJfnaTLi+1TDGmEpZlUu48DY+VtSX/LPPYPdu+O1v/Q9v9/YJnzSp/GtffLGkpF1Y6L8hc/FiVy8P7htAnz7Qvn3DGk5vTJizhB4OvI2djzxS8QChN9+ETp1cI6U/XbvCCSeUr0fPz3cl9KrmRxkyxB2z+mxj6i2rcqlr/uqEK6snVnW9VLyNnf4GCG3c6Lon/v73JaVofy65xFWT7N0LzZu7fX//O2zd6qpUcnMrrjqxuUOMqfcsodcl71D8ggJX0r3hBrf/nXdc3+2yA3iKi+Hee10SjYx0XfdUyyfTf/3L7R89uvL7X3yxm9jqq6/g6qtdf/M//tF1EbznnqqH1Ft9tjH1mlW51KUPPywZCVlY6Ob2fust97y4GA4fdskdXPK+9VY3jP7ee10Xwltuca+dPr3kmsXF7hpDh7pqlcoMGgTJySXVLi+/7Pp6P/mkzY9iTANgJfS65B3p6NutEEoPznn9dfjxRzh0yHUxHDcO/vAHl3BPPdXtf/ppV7rv3t0l+rVr3SjNqkRGwoUXuoS+Y4e7zkUXwWk2DY8xDYEl9LqyYIHrVjh6NBx7bOl66GnTXLXKgAGut8orr7j9TZq4oe++pednnnEJeexY12PlzTddffjllwcWxyWXuCqaq66CPXsCXyneGFPvWUKvK4884pZae+GFkgZJL9+66XnzSurLi4vLN4C2b+9K7PfdB+++Cx995Cavato0sDjOO89df/p0N1gokHU8jTFhwerQ68L338P//udmCyybzMsKpHvgXXe5LoijR7t690An3QJYtqykz/msWXU3R7oxptYFlNBFZLiIrBSRTBEpN4epiDwvIgs9j1Uisif4oYYpb7fDdu3cijxVCWQx4yZN4P/+r2RWw7vuCjwx+w4aKiiwxYWNaUCqrHIRkUjgVWAYkA3ME5HPPYtaAKCq9/qcfxfQvxZiDU9ffeVKwq+95qawDUQg3QP37i2ZS8U7Te3RzjtuA4SMaVACqUM/BchU1bUAIjIRGAksr+D8UcBjwQkvzM2eDTff7Oq9b745uNf2rvp+tInZBggZ02AFktBTgSyf7WxgoL8TRaQz0BWYVsHxMcAYgE6dOh1VoGHHO1e4N+HOnx/c5FmTxGwDhIxpkILdy+Ua4CNVLfJ3UFXfAN4AN31ukO9dv0yYULKeZ20tzmCJ2RjjI5BG0U1AR5/tDp59/lwD/KemQYW9SZPciM+qJrwyxpggCiShzwN6iEhXEYnGJe3Py54kIscBLYGG1w9u9uzKp6719cEHcNllcOKJMHlycFbuMcaYAFRZ5aKqhSJyJzAFiATeVNVlIvIEkKGq3uR+DTBRQ7UEUm2ZOdMtGKHqBu9UlJzT0+Gvf3Wr/Zx2Gnz5JTRr5kZ6GmNMHQioDl1VJwOTy+wbV2b7D8ELqx556aWSgTiHD8PXX5dP6N9/7xpACwvd9LWPP+6SuTHG1CEbKVqZ4mLIyHB14d55xj/5xPUB91q7Fq67ziVzcOfOnVv3sRpjGj2by6Uyn33mFo94/HE3OrO42M2jcs45blKrN990VSsiruGzqMgaQI0xIWMJvSKqbjGIY45xQ/ejPG9Vv36u0fOCC9x2RISb57xdOxusY4wJKUvoFZk5081L/vrrJckc3PzhN97o+pmDK52vXOmmr7VEbowJIatDr8jTT0Pr1i55l/WrX7keL9bH3BhTj1gJ3Z+FC92kWuPH+59n3OZDMcbUQ407oaen+0/Kf/kLJCbC7bdX/Fobdm+MqWcab0JPT4ezznJzgkdEuFV/Ro1yiyZPnOiet2gR6iiNMSZgjTehv/++S+bguiP+85/w9tslxz/5xCV9K4UbY8JE42wUzctz86yAa9hs2tSNAL3pppIFmW01H2NMmGmcJfRx42D1aldXXlhYUoceH++qW2w1H2NMGGp8CX3mTHjmGbj1VnjggdLHrPeKMSaMSagmR0xLS9OMjIy6venevdC3ryt9L1gACQl1e39jjKkhEZmvqmn+jjWuEvrVV0NWFrzxhiVzY0yD03gaRZ95BqZMcc/vvjuwxSqMMSaMNI6EfviwG/UJbtKt/HzrwWKMaXACSugiMlxEVopIpog8WME5V4nIchFZJiLvBTfMGnr6adizB2JibP4VY0yDVWUduohEAq8Cw4BsYJ6IfK6qy33O6QE8BJymqrtFpHVtBXzU1qxx0+Bec42rarEeLMaYBiqQRtFTgExVXQsgIhOBkcByn3NuBV5V1d0Aqro92IFW29ixbnGKZ5+F1FRL5MaYBiuQKpdUIMtnO9uzz9exwLEiMltEfhARvysji8gYEckQkYycnJzqRXw0vvjCrSj02GMumRtjTAMWrEbRKKAHMAQYBfxdRMrNbKWqb6hqmqqmpaSkBOnWFZgxw0241aWLK6UbY0wDF0hC3wR09Nnu4NnnKxv4XFULVHUdsAqX4EMjPR2GDXMNoVu2uIWejTGmgQskoc8DeohIVxGJBq4BPi9zzn9xpXNEJBlXBbM2iHEenY8/dnO0gPtpXRSNMY1AlQldVQuBO4EpwArgA1VdJiJPiMgIz2lTgJ0ishyYDjygqjtrK+gqeQcNWRdFY0wj0vDmcvniCxgxAu68E9q3ty6KxpgGpfHM5XL4sOtr3qsXPPec665ojDGNRMNK6E89BevXw/TplsyNMY1Ow5nLZc0aN8R/1CirMzfGNEoNI6Gnp8NFF7nFnp99NtTRGGNMSIR/lUt6uiuR5+e7apYNG1xjqDHGNDLhX0L/9FOXzAGKi63PuTGm0QrvhL5vH3z0kXtufc6NMY1c+Fa5FBa6KXGzsuCll+DAAetzboxp1MI3od9/P/zvf/C3v8GYMaGOxhhjQi78qlzS0+Gyy+DFF+Heey2ZG2OMR3iV0NPT4eyzIS/PdVG8/PJQR2SMMfVGeJXQZ8yAggL3XAS+/z6k4RhjTH0SXgl9yBBb6NkYYyoQXlUugwfD1Km20LMxxvgRXgkdXBK3RG6MMeUEVOUiIsNFZKWIZIrIg36OjxaRHBFZ6HncEvxQnU17DjPt5221dXljjAlbVSZ0EYkEXgUuAHoBo0Skl59T31fVfp7HhCDHecQXizbzq7czOJhXWFu3MMaYsBRICf0UIFNV16pqPjARGFm7YVUsOSEGgJz9eaEKwRhj6qVAEnoqkOWzne3ZV9YVIrJYRD4SkY7+LiQiY0QkQ0QycnJyqhEuJCdEA7DjgCV0Y4zxFaxui18AXVS1L/AN8E9/J6nqG6qapqppKSkp1bpRSqIroVtCN8aY0gJJ6JsA3xJ3B8++I1R1p6p6M+wE4OTghFdeilW5GGOMX4Ek9HlADxHpKiLRwDXA574niEg7n80RwIrghVhaUnw0IpBzIL+2bmGMMWGpyn7oqlooIncCU4BI4E1VXSYiTwAZqvo5cLeIjAAKgV3A6FoLODKCpLhoK6EbY0wZAQ0sUtXJwOQy+8b5PH8IeCi4oVUsOSHG6tCNMaaM8JrLxSMl0RK6McaUFZYJPTnBqlyMMaasME3oroSuqqEOxRhj6o2wTOgpiTHkFhRzML8o1KEYY0y9EZYJ3Yb/G2NMeeGZ0G20qDHGlBOWCd1GixpjTHlhmdCTE22CLmOMKSssE3pSnBv+v8NK6MYYc0RYJvSoyAhaxUeTYyV0Y4w5IiwTOrieLjn7bYIuY4zxCtuEbsP/jTGmtLBN6K6EbgndGGO8wjihR9vwf2OM8RG2CT0lMYa8wmL25xWGOhRjjKkXwjahe4f/W9dFY4xxAkroIjJcRFaKSKaIPFjJeVeIiIpIWvBC9O9IQrel6IwxBgggoYtIJPAqcAHQCxglIr38nJcIjAXmBjtIf1ISbfi/Mcb4CqSEfgqQqaprVTUfmAiM9HPeH4GngdwgxlehkhK6JXRjjIHAEnoqkOWzne3Zd4SInAR0VNUvK7uQiIwRkQwRycjJyTnqYH0lxUcTIZbQjTHGq8aNoiISATwH3FfVuar6hqqmqWpaSkpKje4bGSEkxVtfdGOM8QokoW8COvpsd/Ds80oEegMzRGQ9MAj4vG4aRqOthG6MMR6BJPR5QA8R6Soi0cA1wOfeg6q6V1WTVbWLqnYBfgBGqGpGrUTsIyXRSujGGONVZUJX1ULgTmAKsAL4QFWXicgTIjKitgOsTEpCjHVbNMYYj6hATlLVycDkMvvGVXDukJqHFZjkxBhyPMP/RaSubmuMMfVS2I4UBVdCzy8sZl+uDf83xpiwTui2FJ0xxpQI64SekhAL2HwuxhgDYZ7QvSV0W4rOGGPCPaHbjIvGGHNEWCf0lnHRREaIldCNMYYwT+hu+H80O2yxaGOMCe+EDq7axXq5GGNMA0joKZ7BRcYY09iFfUJPToi2RlFjjKEBJPSURDefi6qGOhRjjAmp8E/oCTHkFxWz77AN/zfGNG5hn9C9fdGtHt0Y09iFfUL3LhZtPV2MMY1d2Cf0IyV0axg1xjRyASV0ERkuIitFJFNEHvRz/NciskREForILBHpFfxQ/UtOsBkXjTEGAkjoIhIJvApcAPQCRvlJ2O+pah9V7Qf8BbdodJ04MvzfSujGmEYukBL6KUCmqq5V1XxgIjDS9wRV3eezGQ/UWR/CiAihVXzJYtGqyvLN+/jHrHWsyTlQV2EYY0zIBbIEXSqQ5bOdDQwse5KI3AH8BogGhvq7kIiMAcYAdOrU6WhjrVBKYgyLsvZy/4eL+G5VDts9pfUZK5N55+ZyoRpjTIMUtEZRVX1VVbsBvwMereCcN1Q1TVXTUlJSgnVrUls0ZeW2/Xy9bCsDuibxzJV9ufWMrny/egfrdhwM2n2MMaY+C6SEvgno6LPdwbOvIhOB12sS1NH606W9uX1IN/qkNicq0n1Gbd+fy1uz1/PvHzbw6MV11kZrjDEhE0gJfR7QQ0S6ikg0cA3wue8JItLDZ/MiYHXwQqxa62ax9O/U8kgyB2idGMvw3m35cH42h/OL6jIcY4wJiSoTuqoWAncCU4AVwAequkxEnhCREZ7T7hSRZSKyEFePfmOtRXwUrh/Umb2HC/hi8eZQh2KMMbUukCoXVHUyMLnMvnE+z8cGOa6gGNg1iR6tE/j3Dxu4Kq1j1S8wxpgwFvYjRSsjItwwuDOLsveyKGtPqMMxxpha1aATOsBl/VOJi47k3R82hDoUY4ypVQ0+oSfGNuHS/ql8vmgzew7Z2qPGmIarwSd0gOsHdiavsJiP5meHOhRjjKk1jSKh92rfjLTOLfn33I0UF9vKRsaYhqlRJHSAGwZ3Zt2Og1z++hxemrqaRVl7LLkbYxqUgLotNgQX923Ppj2HmbJsG89/u4rnvllFUnw0p3dPZkCXlpzcOYmebROJjJBQh2qMMdUioVpcOS0tTTMyMkJy750H8piVuYOZK3OYlbnjyGReCTFR9O/UgstPSuWy/h1CEpsxxlRGROarapq/Y0k+J4QAABPzSURBVI2mhO6rVUIMI/ulMrJfKqpK9u7DzN+wm4wNu5izZif3vr+IgkLlqgE2GMkYEz4aZUL3JSJ0TIqjY1Icl/ZPJb+wmFv+lcGDnyymZXw0w3q1CXWIxhgTkEbTKBqo6KgIXr/uJPp0aMGd7/3Ej+t2lTunqNgtolFQVByCCI0xxj9L6H7Ex0Tx1ugBpLZsyi3/nMfPW92CTNv25fLS1NWc8fQ0Lnzpe857/ju+WrqVULVDGGOMr0bZKBqo7N2HuPL1dBSlX8cWfLtiO0XFyhk9khl6XGvem7uR1dsPMKBLSx6+8Hj6d2oZ6pCNMQ1cZY2iltCrsHLrfq76WzqREcIv0jowakAnuiTHA1BYVMwHGdk8980qdhzIY8SJ7Xnqij7ERTf6pgljTC2xhF5D+3ILiImKICYq0u/xA3mF/G3mGl6dnskpXZN4c/QAS+rGmFpRWUK3OvQANIttUmEyB9d//b7zevL81f34cd0ubnprHofyC+swQmOMCTChi8hwEVkpIpki8qCf478RkeUislhEpopI5+CHWv+N7JfK81f3Y976XYx+ax4H8yypG2PqTpUJXUQigVeBC4BewCgRKbvq8gIgTVX7Ah8Bfwl2oOFiZL9UXrimPxnrXUndkroxpq4EUkI/BchU1bWqmg9MBEb6nqCq01X1kGfzB6BRj5sfcWJ7XrymP/M37ubaCXPJ2nWo6hcZY0wNBZLQU4Esn+1sz76K3Az8z98BERkjIhkikpGTkxN4lGHokhPb89p1J7F2+wEufPF7Pl/kf6HqHQfy+CAji5Vb99dxhMaYhiaoXTFE5HogDTjL33FVfQN4A1wvl2Deuz46/4S29BrbjHveX8jd/1nAjJXbeWJkb+KjI5m/YTfv/LCByUu2UFDk3oq+HZrzi5M7MOLEVJrHNQlx9MaYcBNIQt8E+M5S1cGzrxQRORd4BDhLVfOCE17465gUx/tjBvHytExenraajPW7iYuO5Oet+0mMjeL6QZ0Z2S+V+Rt282FGFr//bBl//HIFF/Ruy4MXHEe75k2DGk9uQRH/nruRvYfyGXvusTZdsDENSJX90EUkClgFnINL5POAa1V1mc85/XGNocNVdXUgNw6nfujBMm/9Lh76ZAkxURHcMKgzI/q1L9VfXVVZtnkfH83P5v15WURFCo9dcgJXnJSKSOnEm1tQxJRlW8nZn0fT6EiaNnGPuJgoerVrRkpiTKnzi4qV/y7YxHPfrGLTnsMAXHlyB/5yRV8iLKkbEzZqPLBIRC4EXgAigTdV9c8i8gSQoaqfi8i3QB9gi+clG1V1RGXXbIwJ/Whs2HmQBz5czI/rd3HOca0Zf3kf2jSLJXv3Id79YSPvz9vI7kMFFb7+mJR4BnZNYmDXVsQ2ieSFb1fx89b99EltzoMXHEfG+t08/+0qrkrrwFOXW1I3JlzYSNEwVVysvDVnPX/56mdioiI4qXNLvlvlGpOH9WrDjYO7cEJqc/IKijjseew9VMDCrD3MXbeLeet3sT/XdZvslBTHA+f35KI+7Y4k7+e+WcVLU1dzzYCOjL+sT5VJ/YtFm/n4p2wGHdOKESe2p32L4FYHGWOqZgk9zK3NOcCDnyxh3Y6DXJXWgWsHdiY1gGRaVKys2LKPLXtzOevYFKKjSndqUlX++vUqXpmeybUDO/Gnkb39JvU9h/IZ99kyPl+0meSEGHYcyEMEBnZN4tJ+qZx3QluS4qOD9vsaYypmCd1USFV5ZspKXpuxhpM7t+S8Xm04+7jW9GidgIjw3aocHvhoETsP5DP2nB7cPqQb2bsP89nCzXy2cBNrdxwEIDkhhu6t4+mWkkD31gkM79026A26xhhL6KYKqsqbs9fzYUYWP3v6w6e2aMqxbRKYvjKH7q0TeP6qfvTp0Lzc6xZn7+WHtTtZk3OAzO3usS+3kE5JcXx59+kkxlr3S2OCyRK6CdjmPYeZuSqH6T9vZ0HWHi7p257fDu9JbJOKJyfzpaqkr93J9RPmcmn/VJ67ql8tR2xM42KLRJuAtW/RlFGndGLUKZ2q9XoR4dRuydw1tAcvTl3NWcemMLJf+YHFuw/m8+WSLXRMiqNPanOrgzcmCCyhm1px19DuzMrcwaOfLuWkTi3pmBR35NjSTXu57Z35R/rDA3Ro2ZS+HZrTpVU8IqAKChSrkldQzL7cAvYdLmR/bgEH8wtp17wpx7drxvFtEzm+XTM6JcVZ10vT6FmVi6k1WbsOceGL33Ns20TeHzOIqMgIPpqfzcOfLiE5Pprnru5HsSpLsveyeNNelmTvJXv3IUQEAURAEGKaRNAstgmJsVE0i21C0+hIsncfYt2OgxR7/nybxUYx+rSu3HJGV5r5qbf/cd0uXpuRSXx0FL8bfhydWsWVOyfY8guLmfbzdob0TAm4ysqYqlgdugmZzxZuYuzEhdxxdjf2HS7knR82cGq3Vrw8qj+tEmKqvkAlDucXsXr7flZs2cf0n3P4atlWWsQ14fazuvHLwV1o6pkz5/lvVjErcwfJCTEcyi+ksFi5/axu3D6kW7lEq6ocLigKyopTf5q0nAmz1nFGj2T+/ss0S+omKCyhm5D6zfsL+WSBm/7ntjOP4YHzexIVGfzFspZk7+XZr1cyc1UOrRNj6NEmgdmZO0mKj+b2s7px/aDO7Dmcz5+/XMGkxVvomNSURy/qRcu4aBZs3M2CjXtYkLWbbfvy6J3ajOEntGV477Z0b5141LF8vzqHG/7xIyd3bslPG3dzardWTPjlAJpGH31S33uogE8WZDN1xXbaNIvluLaJ9GybyHFtE0lJjCk3LYRp2Cyhm5Dan1vAI58uZXjvtlzYp12t32/u2p08+/VK1u04xE2ndWH0qV2Ijyld4p6zZgePfbaM1dsPHNnXuVUc/Tu2oFNSHLMyd/DTxj2Am0ZhaM/W9OnQnOPbNeOY5PhKP5B2H8zn/Be+o1nTJnxx5+n8b+kW7v9wEQO6uPVmy8bij6qyMGsP783dyBeLN5NbUEz31gnsPVxAzv6Sue+OSY7nzdEDjixcHojV2/bz1dKtXDeoszVGhyFL6Mb4UVBUzOQlW4iPjqJ/pxblqoC27s3lm+Vb+WrZVuat201+UTEA0VER9GyTyLBebRhz5jGlqlJUlV+/O59pP2/nv3ecxgntXd/9zxZu4jcfLKJ/xxa8ddMACouUnzbu5qeNu5m/YTc5+/NQAE9jcF5BEZv35hIXHcnIfqlcN7ATvVPdtXYeyGPl1v2s2LqfV6atJrZJJO+PGVxlu8DCrD28Nj2Tr5dvA2BAl5a8e8vAStfLNfWPJXRjaqigqJg1OQdYsWUfK7bsZ5FnvpyuyfH8+dLenNo9GYD3523kdx8v4aELjuO2s7qVusaXi7cwduICmkZHHpljJzJC6OXppYPgaQwWIgTSuiRxab/2lQ7OWr55H9dO+IH46CgmjhlUqjcRuA+Y2Zk7eW1GJnPW7HSNx6d2oW3zpjz86RJ+cXIH/nJl35BU2xQWFddK1VtDZwndmFowa/UOHvnvEjbsPMTl/VO5blAnbvjHj/Tr2IJ3bx7otxvl9JXb+fSnTRzXLpGTO7Wkb4cW1apX97V0016umzCXhJgo3r9tEB1axlFYVMzkpVv528w1LNu8j9aJMdxyRleuHdiZBE+Vz/PfrOLFqat5+MLjGHNmtyruUj0FRcXsPJDPjgN5bNx1iJ+37mfV1v2s3LafDTsPcu7xbXhpVH9rMD4KltCNqSW5BUW8Mi2Tv323hoIipXnTJnx1zxl1Po/Nkuy9XDfhB5rHNeGGQZ35V/oGsncf5piUeMaccQyX9k8tlzSLi5W7Ji5g8pIt/P2GNM7t1eao77v3cAFfLNrM1r257DqUz64D+e7nQZfE95SZ4jlCoEureHq2TaRFXDQT521kUNdWTLgxLaC2BWMJ3Zhat2rbfl74dhW/SOvI2T1bhySGRVl7uP4fc9mfW0ha55aMOfMYzj2+TaUDrg7nF3H1G+ms2X6AD399KnHRkZ4xAXtYnL2X6KgILu2XyvDebUsl3N0H8/nHrHX8c8569ucVEiGQFB9Ny7hoWsZH0yo+muSEGPdIdM/bN29KjzYJpT5YPvkpm/s/XES/ji1466ZTaN60pHpp76EC/pm+nh/X7WJwt1Zc0Lstx6QkVPoeqCoLsvbwwbwspq/czpBjW3P3uT0Cmp00GPIKi9hxIJ/t+3LJ2Z9HzoE8Uls05dRuyeVmO62uYCxwMRx4EbfAxQRVfarM8TNxC2D0Ba5R1Y+quqYldGOCb22OmxytX8cWAb9m275cRrwyi237SnrPREdF0KtdM3YdzGfjrkM0bRLJ8N5tubhvO+at38076es5VFDEBb3b8n9DutOrXbNqj9T9aukW7vrPAnq0TuSdm0+hqFj5x6x1vPvDBg7mF3FMcvyRWT2Pa5vI8N5tGdAliZioCKKjImgSGUGEZ2bQDzKyWL39AHHRkQzsmsTszJ0AXD+oM/93djeSPQ3fOw7kMWfNTuZk7uBwQRHnn9CWs3u2Drj6S1VZv/MQyzfv87Sr7OPnrftLjX721Sw2ivNOaMtFfdpxWveaJfcaJXQRicQtQTcMyMYtQTdKVZf7nNMFaAbcD3xuCd2Y8LJ6234+mp9N1+R4+nRozrFtEmkSGYGqMn/Dbj7+aRNfLt7MvtxCROCSvu25c2h3jm1z9H30/Zmxcju3vTOfpPhodh7Mp7ComIv7tuf2Id04vl0zNu85zFdLt/K/pVvI2LCbitLWSZ1acPWAjlzUtz0JMVFs2nOYl75dzYfzs4j1fCit2OIGowEkxkbRJDKCXQfziYuO5Jzj23BRn3ac2LE5zZs2oWmTyCMNxtv25TJr9Q5mZbqHt/toZIRwTHI8x7drRreUBNo0iyElMYbWibG0Sohm+eZ9TF6yhW+Wb2N/XiHNYqN4fOQJXNa/Q7Xeq5om9MHAH1T1fM/2QwCq+qSfc98GJllCN6bhyS0oIn3NTjq3iquy6qM65q7dyf0fLeL07in8+qxj6NzKf9/67ftzWbP9IAVFxUce+UVKr3aJFQ4CW5NzgOe+WcX0n7dzYocWnN4jmdO6J9O7fTPATQ0xackWvlq6lV0H84+8rkmk0Cy2CbFNIo+UvpPiozmtezKndmtF7/bNy1UjVSSvsIhZq3fw5ZItXDewEyd3TjratwioeUK/Erf48y2e7RuAgap6p59z38YSujEmTBUWFfPjul1s2HWIvYcLjjwO5hVyfLtmnN49uUbVS8FQb6bPFZExwBiATp2qNz2rMcbUlqjICE7tnsypoQ6kmgKpmd8EdPTZ7uDZd9RU9Q1VTVPVtJSUlOpcwhhjTAUCSejzgB4i0lVEooFrgM9rNyxjjDFHq8qErqqFwJ3AFGAF8IGqLhORJ0RkBICIDBCRbOAXwN9EZFltBm2MMaa8gOrQVXUyMLnMvnE+z+fhqmKMMcaEiM2MY4wxDYQldGOMaSAsoRtjTANhCd0YYxqIkM22KCI5wIZqvjwZ2BHEcOpaOMcfzrGDxR9K4Rw71J/4O6uq34E8IUvoNSEiGRUNfQ0H4Rx/OMcOFn8ohXPsEB7xW5WLMcY0EJbQjTGmgQjXhP5GqAOooXCOP5xjB4s/lMI5dgiD+MOyDt0YY0x54VpCN8YYU4YldGOMaSDCLqGLyHARWSkimSLyYKjjqYqIvCki20Vkqc++JBH5RkRWe362DGWMFRGRjiIyXUSWi8gyERnr2V/v4xeRWBH5UUQWeWJ/3LO/q4jM9fz9vO+ZErreEpFIEVkgIpM822ETv4isF5ElIrJQRDI8++r93w6AiLQQkY9E5GcRWSEig8Mh9rBK6J4Fq18FLgB6AaNEpFdoo6rS28DwMvseBKaqag9gqme7PioE7lPVXsAg4A7P+x0O8ecBQ1X1RKAfMFxEBgFPA8+randgN3BzCGMMxFjctNVe4Rb/2araz6f/djj87QC8CHylqscBJ+L+Dep/7KoaNg9gMDDFZ/sh4KFQxxVA3F2ApT7bK4F2nuftgJWhjjHA3+MzYFi4xQ/EAT8BA3Ej/aL8/T3VtwduSuqpwFBgEiBhFv96ILnMvnr/twM0B9bh6TQSTrGHVQkdSAWyfLazPfvCTRtV3eJ5vhVoE8pgAiEiXYD+wFzCJH5PdcVCYDvwDbAG2KNu0Rao/38/LwC/BYo9260Ir/gV+FpE5nvWE4bw+NvpCuQAb3mquyaISDxhEHu4JfQGR93Hfb3uOyoiCcDHwD2qus/3WH2OX1WLVLUfrqR7CnBciEMKmIhcDGxX1fmhjqUGTlfVk3BVpHeIyJm+B+vx304UcBLwuqr2Bw5SpnqlvsYebgk9aAtWh9g2EWkH4Pm5PcTxVEhEmuCS+b9V9RPP7rCJH0BV9wDTcVUULUTEu1JXff77OQ0YISLrgYm4apcXCZ/4UdVNnp/bgU9xH6rh8LeTDWSr6lzP9ke4BF/vYw+3hN5QFqz+HLjR8/xGXN10vSMiAvwDWKGqz/kcqvfxi0iKiLTwPG+Kq/tfgUvsV3pOq5exA6jqQ6raQVW74P7Op6nqdYRJ/CISLyKJ3ufAecBSwuBvR1W3Alki0tOz6xxgOWEQe8gr8avRYHEhsApXH/pIqOMJIN7/AFuAAtwn/824utCpwGrgWyAp1HFWEPvpuK+Vi4GFnseF4RA/0BdY4Il9KTDOs/8Y4EcgE/gQiAl1rAH8LkOASeEUvyfORZ7HMu//1XD42/HE2Q/I8Pz9/BdoGQ6x29B/Y4xpIMKtysUYY0wFLKEbY0wDYQndGGMaCEvoxhjTQFhCN8aYBsISujHGNBCW0I0xpoH4fyinRGTriDhQAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_test, y_test, epochs= 200, batch_size=30)\n",
        "loss = model.evaluate(x_test,y_test)\n",
        "print('accuracy:',loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naLxkrPmnmL8",
        "outputId": "e585e836-b998-484b-bf00-9b65ebb49b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1232 - accuracy: 0.8387\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1152 - accuracy: 0.8387\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1448 - accuracy: 0.7742\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1290 - accuracy: 0.8065\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0965 - accuracy: 0.8710\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1127 - accuracy: 0.8710\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.8387\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1335 - accuracy: 0.8065\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.8065\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.8710\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0777 - accuracy: 0.9032\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0951 - accuracy: 0.8710\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1084 - accuracy: 0.8387\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0928 - accuracy: 0.8710\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.8710\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0819 - accuracy: 0.9032\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0951 - accuracy: 0.9032\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0668 - accuracy: 0.9355\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1020 - accuracy: 0.8387\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9355\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1181 - accuracy: 0.8710\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0928 - accuracy: 0.8387\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0633 - accuracy: 0.9355\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.9032\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0571 - accuracy: 0.9032\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0922 - accuracy: 0.8710\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.9032\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.8387\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9355\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9032\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1206 - accuracy: 0.7742\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0639 - accuracy: 0.9355\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0850 - accuracy: 0.8710\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1164 - accuracy: 0.8387\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0779 - accuracy: 0.9032\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0915 - accuracy: 0.9032\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0924 - accuracy: 0.8710\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0663 - accuracy: 0.9355\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0986 - accuracy: 0.8710\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0673 - accuracy: 0.9032\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0778 - accuracy: 0.8710\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0769 - accuracy: 0.8710\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9032\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0689 - accuracy: 0.8710\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 0.9677\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0576 - accuracy: 0.9355\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.9032\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0487 - accuracy: 0.9355\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0989 - accuracy: 0.9032\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0579 - accuracy: 0.9032\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0645 - accuracy: 0.9032\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0787 - accuracy: 0.9355\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0823 - accuracy: 0.9355\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.9032\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9355\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9032\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.9677\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9677\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.9032\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9355\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9355\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0433 - accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0543 - accuracy: 0.9677\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0552 - accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0931 - accuracy: 0.9032\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0545 - accuracy: 0.9677\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0636 - accuracy: 0.9677\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 0.9355\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0820 - accuracy: 0.9355\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 0.9355\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0555 - accuracy: 0.9355\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0703 - accuracy: 0.9677\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0690 - accuracy: 0.9677\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0535 - accuracy: 0.9677\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.9677\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.9355\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9355\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9677\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 0.9677\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0496 - accuracy: 0.9677\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9355\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0555 - accuracy: 0.9677\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0273 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.9032\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0841 - accuracy: 0.8710\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0560 - accuracy: 0.9677\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0414 - accuracy: 0.9677\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0381 - accuracy: 0.9677\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0458 - accuracy: 0.9677\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0409 - accuracy: 0.9355\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0901 - accuracy: 0.9032\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0783 - accuracy: 0.8710\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 0.9677\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.9355\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0423 - accuracy: 0.9355\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0666 - accuracy: 0.9355\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0498 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0477 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0589 - accuracy: 0.9677\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0309 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0454 - accuracy: 0.9677\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0500 - accuracy: 0.9677\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0376 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 0.9677\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0496 - accuracy: 0.9355\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9355\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0327 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0396 - accuracy: 0.9677\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0816 - accuracy: 0.9032\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0370 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0652 - accuracy: 0.9677\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.9677\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0261 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0879 - accuracy: 0.8710\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0790 - accuracy: 0.8710\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9677\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9677\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9677\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0259 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0431 - accuracy: 0.9355\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0497 - accuracy: 0.9677\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0461 - accuracy: 0.9677\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 0.9677\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0273 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0507 - accuracy: 0.9677\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0512 - accuracy: 0.9677\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0568 - accuracy: 0.9677\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0580 - accuracy: 0.9355\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0295 - accuracy: 0.9677\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0624 - accuracy: 0.9032\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0396 - accuracy: 0.9677\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0354 - accuracy: 0.9677\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0503 - accuracy: 0.9677\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0750 - accuracy: 0.9032\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9677\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0321 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0561 - accuracy: 0.9677\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0317 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 0.9677\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0352 - accuracy: 0.9677\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9677\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0666 - accuracy: 0.9355\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0436 - accuracy: 0.9677\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9677\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0602 - accuracy: 0.9355\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0318 - accuracy: 0.9677\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0469 - accuracy: 0.9677\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0441 - accuracy: 0.9677\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0437 - accuracy: 0.9677\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0509 - accuracy: 0.9355\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0325 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0317 - accuracy: 0.9677\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0650 - accuracy: 0.9032\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0383 - accuracy: 0.9677\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 0.9355\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0512 - accuracy: 0.9355\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9355\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9677\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0320 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0409 - accuracy: 0.9677\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9032\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9355\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.9677\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0461 - accuracy: 0.9677\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0440 - accuracy: 0.9677\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "accuracy: [0.01664157025516033, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "n_fold=6\n",
        "skf=KFold(n_splits=n_fold, shuffle=True, random_state=3)\n",
        "\n",
        "for train, test in skf.split(x,y) :\n",
        "  x=normalization_df.iloc[:,1:14]\n",
        "\n",
        "  y=df.iloc[:,14]\n",
        "\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1,random_state=3)\n",
        "  model = Sequential()\n",
        "  model.add(Dense(10,  input_dim=13, activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(30,  activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(40,  activation='relu'))\n",
        "  model.add(Dense(1))\n",
        "  model.summary()\n",
        "  model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(x_train, y_train, epochs=200, batch_size=30, validation_split=0.2)\n",
        "  loss = model.evaluate(x_train,y_train)\n",
        "  print('accuracy:',loss)\n",
        "\n",
        "  y_loss = history.history['loss']\n",
        "  y_accu = history.history['accuracy']\n",
        "\n",
        "  x_len = np.arange(len(y_loss))\n",
        "\n",
        "  plt.plot(x_len,y_loss)\n",
        "  plt.plot(x_len,y_accu, marker='.', c=\"red\")\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48108
        },
        "id": "NzUAWsDI2Orw",
        "outputId": "20408842-2a8e-4803-9c8a-5f7ee9a62580"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 10)                140       \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 30)                330       \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 30)                0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,751\n",
            "Trainable params: 1,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 26ms/step - loss: 0.3209 - accuracy: 0.5484 - val_loss: 0.2781 - val_accuracy: 0.5455\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2543 - accuracy: 0.5899 - val_loss: 0.2570 - val_accuracy: 0.5455\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2269 - accuracy: 0.6590 - val_loss: 0.2502 - val_accuracy: 0.5455\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1956 - accuracy: 0.7097 - val_loss: 0.2324 - val_accuracy: 0.6182\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2010 - accuracy: 0.6774 - val_loss: 0.2212 - val_accuracy: 0.6545\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1921 - accuracy: 0.6866 - val_loss: 0.2125 - val_accuracy: 0.7091\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1877 - accuracy: 0.7235 - val_loss: 0.2071 - val_accuracy: 0.7091\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1701 - accuracy: 0.7419 - val_loss: 0.2043 - val_accuracy: 0.7091\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1803 - accuracy: 0.7419 - val_loss: 0.2045 - val_accuracy: 0.6909\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1803 - accuracy: 0.7419 - val_loss: 0.1993 - val_accuracy: 0.7091\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1768 - accuracy: 0.7281 - val_loss: 0.1980 - val_accuracy: 0.7091\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1602 - accuracy: 0.7696 - val_loss: 0.2010 - val_accuracy: 0.6909\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1488 - accuracy: 0.7788 - val_loss: 0.2036 - val_accuracy: 0.6545\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1609 - accuracy: 0.7558 - val_loss: 0.2084 - val_accuracy: 0.6364\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1561 - accuracy: 0.7604 - val_loss: 0.2066 - val_accuracy: 0.6727\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1588 - accuracy: 0.7281 - val_loss: 0.2059 - val_accuracy: 0.6727\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1531 - accuracy: 0.7419 - val_loss: 0.2037 - val_accuracy: 0.6727\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1463 - accuracy: 0.7788 - val_loss: 0.2011 - val_accuracy: 0.6727\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1394 - accuracy: 0.7926 - val_loss: 0.2022 - val_accuracy: 0.6727\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1535 - accuracy: 0.7696 - val_loss: 0.1946 - val_accuracy: 0.6909\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1452 - accuracy: 0.8157 - val_loss: 0.1959 - val_accuracy: 0.6909\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1355 - accuracy: 0.8157 - val_loss: 0.2009 - val_accuracy: 0.6909\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1271 - accuracy: 0.8295 - val_loss: 0.2070 - val_accuracy: 0.6545\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1301 - accuracy: 0.8018 - val_loss: 0.2051 - val_accuracy: 0.6545\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1387 - accuracy: 0.8111 - val_loss: 0.1965 - val_accuracy: 0.6909\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1346 - accuracy: 0.8203 - val_loss: 0.1953 - val_accuracy: 0.7091\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1247 - accuracy: 0.8203 - val_loss: 0.1897 - val_accuracy: 0.7091\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1334 - accuracy: 0.8157 - val_loss: 0.1903 - val_accuracy: 0.7273\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1187 - accuracy: 0.8525 - val_loss: 0.1807 - val_accuracy: 0.7455\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1271 - accuracy: 0.8249 - val_loss: 0.1824 - val_accuracy: 0.7273\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1210 - accuracy: 0.8249 - val_loss: 0.1866 - val_accuracy: 0.6909\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1178 - accuracy: 0.8525 - val_loss: 0.1841 - val_accuracy: 0.7091\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1176 - accuracy: 0.8387 - val_loss: 0.1905 - val_accuracy: 0.6909\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1098 - accuracy: 0.8664 - val_loss: 0.1955 - val_accuracy: 0.6545\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1152 - accuracy: 0.8618 - val_loss: 0.1909 - val_accuracy: 0.6909\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1187 - accuracy: 0.8525 - val_loss: 0.1855 - val_accuracy: 0.6909\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1109 - accuracy: 0.8479 - val_loss: 0.1881 - val_accuracy: 0.6909\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1076 - accuracy: 0.8571 - val_loss: 0.1948 - val_accuracy: 0.6545\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1126 - accuracy: 0.8664 - val_loss: 0.1916 - val_accuracy: 0.6727\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1211 - accuracy: 0.8295 - val_loss: 0.1876 - val_accuracy: 0.6727\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1063 - accuracy: 0.8618 - val_loss: 0.1869 - val_accuracy: 0.6727\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1063 - accuracy: 0.8756 - val_loss: 0.1870 - val_accuracy: 0.6727\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1099 - accuracy: 0.8479 - val_loss: 0.1874 - val_accuracy: 0.6727\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1002 - accuracy: 0.8756 - val_loss: 0.1940 - val_accuracy: 0.6545\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1133 - accuracy: 0.8571 - val_loss: 0.1899 - val_accuracy: 0.6545\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 0.8710 - val_loss: 0.1839 - val_accuracy: 0.6727\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1065 - accuracy: 0.8571 - val_loss: 0.1829 - val_accuracy: 0.6727\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.8802 - val_loss: 0.1878 - val_accuracy: 0.6545\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1033 - accuracy: 0.8756 - val_loss: 0.1868 - val_accuracy: 0.6545\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0984 - accuracy: 0.8848 - val_loss: 0.1848 - val_accuracy: 0.7091\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1075 - accuracy: 0.8387 - val_loss: 0.1878 - val_accuracy: 0.6909\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1091 - accuracy: 0.8571 - val_loss: 0.1991 - val_accuracy: 0.6182\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1026 - accuracy: 0.8710 - val_loss: 0.2002 - val_accuracy: 0.6364\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1065 - accuracy: 0.8433 - val_loss: 0.1943 - val_accuracy: 0.6727\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0918 - accuracy: 0.8848 - val_loss: 0.1879 - val_accuracy: 0.7091\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.8571 - val_loss: 0.1877 - val_accuracy: 0.6545\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0995 - accuracy: 0.8571 - val_loss: 0.1895 - val_accuracy: 0.6364\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0952 - accuracy: 0.8894 - val_loss: 0.1912 - val_accuracy: 0.6364\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.8479 - val_loss: 0.1902 - val_accuracy: 0.6182\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.8249 - val_loss: 0.1905 - val_accuracy: 0.6182\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0980 - accuracy: 0.8986 - val_loss: 0.1893 - val_accuracy: 0.6182\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1056 - accuracy: 0.8710 - val_loss: 0.1868 - val_accuracy: 0.6545\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0990 - accuracy: 0.8618 - val_loss: 0.1880 - val_accuracy: 0.6182\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0931 - accuracy: 0.8710 - val_loss: 0.1903 - val_accuracy: 0.6182\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0931 - accuracy: 0.8802 - val_loss: 0.1979 - val_accuracy: 0.6000\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0906 - accuracy: 0.8756 - val_loss: 0.1939 - val_accuracy: 0.6545\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0940 - accuracy: 0.8664 - val_loss: 0.1963 - val_accuracy: 0.6545\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0948 - accuracy: 0.8756 - val_loss: 0.1973 - val_accuracy: 0.6364\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1012 - accuracy: 0.8894 - val_loss: 0.1957 - val_accuracy: 0.6909\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0899 - accuracy: 0.8986 - val_loss: 0.1916 - val_accuracy: 0.6909\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0947 - accuracy: 0.8894 - val_loss: 0.1906 - val_accuracy: 0.6727\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9032 - val_loss: 0.1832 - val_accuracy: 0.6727\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.8664 - val_loss: 0.1835 - val_accuracy: 0.6727\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0833 - accuracy: 0.8940 - val_loss: 0.1846 - val_accuracy: 0.6545\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0846 - accuracy: 0.9032 - val_loss: 0.1842 - val_accuracy: 0.6727\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0915 - accuracy: 0.8802 - val_loss: 0.1815 - val_accuracy: 0.6727\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9078 - val_loss: 0.1818 - val_accuracy: 0.6727\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.8802 - val_loss: 0.1843 - val_accuracy: 0.6727\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0786 - accuracy: 0.9171 - val_loss: 0.1874 - val_accuracy: 0.6727\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9124 - val_loss: 0.1926 - val_accuracy: 0.6727\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0932 - accuracy: 0.8894 - val_loss: 0.1932 - val_accuracy: 0.6727\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0929 - accuracy: 0.8894 - val_loss: 0.1956 - val_accuracy: 0.6364\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0850 - accuracy: 0.8802 - val_loss: 0.1984 - val_accuracy: 0.6364\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.8848 - val_loss: 0.2036 - val_accuracy: 0.6364\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0873 - accuracy: 0.8756 - val_loss: 0.1981 - val_accuracy: 0.6727\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0840 - accuracy: 0.8802 - val_loss: 0.1966 - val_accuracy: 0.7091\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.9032 - val_loss: 0.1971 - val_accuracy: 0.6727\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0839 - accuracy: 0.9078 - val_loss: 0.1980 - val_accuracy: 0.6182\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9032 - val_loss: 0.1957 - val_accuracy: 0.6364\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0795 - accuracy: 0.9078 - val_loss: 0.1933 - val_accuracy: 0.6364\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.8848 - val_loss: 0.1945 - val_accuracy: 0.6545\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9032 - val_loss: 0.1935 - val_accuracy: 0.6545\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.8986 - val_loss: 0.1848 - val_accuracy: 0.6727\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0860 - accuracy: 0.9124 - val_loss: 0.1826 - val_accuracy: 0.7091\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9032 - val_loss: 0.1945 - val_accuracy: 0.6364\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9217 - val_loss: 0.2030 - val_accuracy: 0.6182\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0836 - accuracy: 0.8986 - val_loss: 0.2003 - val_accuracy: 0.6364\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9171 - val_loss: 0.2037 - val_accuracy: 0.6364\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9263 - val_loss: 0.2068 - val_accuracy: 0.6545\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0840 - accuracy: 0.8940 - val_loss: 0.2127 - val_accuracy: 0.6364\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0845 - accuracy: 0.8894 - val_loss: 0.2065 - val_accuracy: 0.6545\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0888 - accuracy: 0.8986 - val_loss: 0.2030 - val_accuracy: 0.6545\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0838 - accuracy: 0.9032 - val_loss: 0.2056 - val_accuracy: 0.6182\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0670 - accuracy: 0.9401 - val_loss: 0.1985 - val_accuracy: 0.6545\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0770 - accuracy: 0.9171 - val_loss: 0.1976 - val_accuracy: 0.6545\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0758 - accuracy: 0.9124 - val_loss: 0.2003 - val_accuracy: 0.6545\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0805 - accuracy: 0.8986 - val_loss: 0.2044 - val_accuracy: 0.6182\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0742 - accuracy: 0.9078 - val_loss: 0.2083 - val_accuracy: 0.6182\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0690 - accuracy: 0.9217 - val_loss: 0.2018 - val_accuracy: 0.6545\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0810 - accuracy: 0.9078 - val_loss: 0.1983 - val_accuracy: 0.6545\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0766 - accuracy: 0.9078 - val_loss: 0.2049 - val_accuracy: 0.6364\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0797 - accuracy: 0.9171 - val_loss: 0.2034 - val_accuracy: 0.6364\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0710 - accuracy: 0.9217 - val_loss: 0.1963 - val_accuracy: 0.6545\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0812 - accuracy: 0.8986 - val_loss: 0.1975 - val_accuracy: 0.6545\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 0.9171 - val_loss: 0.2076 - val_accuracy: 0.6364\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0765 - accuracy: 0.8986 - val_loss: 0.2017 - val_accuracy: 0.6545\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0643 - accuracy: 0.9263 - val_loss: 0.1985 - val_accuracy: 0.7091\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0811 - accuracy: 0.8940 - val_loss: 0.2028 - val_accuracy: 0.6182\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.9263 - val_loss: 0.2066 - val_accuracy: 0.6182\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0744 - accuracy: 0.9032 - val_loss: 0.2026 - val_accuracy: 0.6545\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0807 - accuracy: 0.8894 - val_loss: 0.2054 - val_accuracy: 0.6182\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0775 - accuracy: 0.8894 - val_loss: 0.2107 - val_accuracy: 0.6000\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0671 - accuracy: 0.9309 - val_loss: 0.2058 - val_accuracy: 0.6364\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0714 - accuracy: 0.9124 - val_loss: 0.2082 - val_accuracy: 0.6182\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0636 - accuracy: 0.9124 - val_loss: 0.2130 - val_accuracy: 0.6000\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0712 - accuracy: 0.9032 - val_loss: 0.2168 - val_accuracy: 0.6182\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0665 - accuracy: 0.9217 - val_loss: 0.2077 - val_accuracy: 0.6182\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0658 - accuracy: 0.9309 - val_loss: 0.2043 - val_accuracy: 0.6182\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0635 - accuracy: 0.9263 - val_loss: 0.2017 - val_accuracy: 0.6364\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9032 - val_loss: 0.1978 - val_accuracy: 0.6727\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0723 - accuracy: 0.9355 - val_loss: 0.2035 - val_accuracy: 0.6364\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0771 - accuracy: 0.9078 - val_loss: 0.2031 - val_accuracy: 0.6727\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.8894 - val_loss: 0.2079 - val_accuracy: 0.6545\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.9539 - val_loss: 0.2049 - val_accuracy: 0.6727\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0734 - accuracy: 0.9078 - val_loss: 0.2055 - val_accuracy: 0.6909\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 0.9309 - val_loss: 0.2048 - val_accuracy: 0.6364\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9217 - val_loss: 0.2026 - val_accuracy: 0.6545\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 0.9124 - val_loss: 0.2011 - val_accuracy: 0.6727\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.9124 - val_loss: 0.2016 - val_accuracy: 0.6727\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0572 - accuracy: 0.9447 - val_loss: 0.2084 - val_accuracy: 0.6364\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0738 - accuracy: 0.9263 - val_loss: 0.2071 - val_accuracy: 0.6545\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9078 - val_loss: 0.2060 - val_accuracy: 0.6364\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.9078 - val_loss: 0.2062 - val_accuracy: 0.6364\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0658 - accuracy: 0.8986 - val_loss: 0.2117 - val_accuracy: 0.6545\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.9447 - val_loss: 0.2105 - val_accuracy: 0.6909\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.8940 - val_loss: 0.2067 - val_accuracy: 0.6909\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9355 - val_loss: 0.2079 - val_accuracy: 0.6727\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9263 - val_loss: 0.2126 - val_accuracy: 0.6364\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0662 - accuracy: 0.9309 - val_loss: 0.2119 - val_accuracy: 0.6182\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0617 - accuracy: 0.9124 - val_loss: 0.2189 - val_accuracy: 0.6182\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.9124 - val_loss: 0.2187 - val_accuracy: 0.6364\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.9263 - val_loss: 0.2143 - val_accuracy: 0.6545\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0571 - accuracy: 0.9309 - val_loss: 0.2222 - val_accuracy: 0.6364\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0667 - accuracy: 0.9032 - val_loss: 0.2254 - val_accuracy: 0.6182\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0657 - accuracy: 0.9124 - val_loss: 0.2179 - val_accuracy: 0.6364\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0672 - accuracy: 0.9355 - val_loss: 0.2133 - val_accuracy: 0.6364\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.9124 - val_loss: 0.2067 - val_accuracy: 0.6727\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0643 - accuracy: 0.9309 - val_loss: 0.2230 - val_accuracy: 0.5818\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0620 - accuracy: 0.9263 - val_loss: 0.2263 - val_accuracy: 0.5818\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0578 - accuracy: 0.9355 - val_loss: 0.2055 - val_accuracy: 0.6727\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0688 - accuracy: 0.9078 - val_loss: 0.2089 - val_accuracy: 0.6364\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0525 - accuracy: 0.9401 - val_loss: 0.2139 - val_accuracy: 0.6364\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0644 - accuracy: 0.9217 - val_loss: 0.2089 - val_accuracy: 0.6182\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0625 - accuracy: 0.9309 - val_loss: 0.2145 - val_accuracy: 0.6364\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0606 - accuracy: 0.9263 - val_loss: 0.2175 - val_accuracy: 0.6364\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0667 - accuracy: 0.9124 - val_loss: 0.2126 - val_accuracy: 0.6364\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0535 - accuracy: 0.9493 - val_loss: 0.2158 - val_accuracy: 0.6182\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0545 - accuracy: 0.9355 - val_loss: 0.2226 - val_accuracy: 0.6182\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.9263 - val_loss: 0.2173 - val_accuracy: 0.5818\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0433 - accuracy: 0.9724 - val_loss: 0.2211 - val_accuracy: 0.6000\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9355 - val_loss: 0.2206 - val_accuracy: 0.6364\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.9309 - val_loss: 0.2127 - val_accuracy: 0.6545\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.9309 - val_loss: 0.2228 - val_accuracy: 0.6364\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9217 - val_loss: 0.2179 - val_accuracy: 0.6364\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0640 - accuracy: 0.8986 - val_loss: 0.2206 - val_accuracy: 0.6364\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 0.9217 - val_loss: 0.2270 - val_accuracy: 0.6182\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9355 - val_loss: 0.2163 - val_accuracy: 0.6182\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9171 - val_loss: 0.2234 - val_accuracy: 0.6364\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.9401 - val_loss: 0.2215 - val_accuracy: 0.6364\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9355 - val_loss: 0.2218 - val_accuracy: 0.6364\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0635 - accuracy: 0.9263 - val_loss: 0.2331 - val_accuracy: 0.6364\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.9263 - val_loss: 0.2269 - val_accuracy: 0.6364\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9401 - val_loss: 0.2285 - val_accuracy: 0.6364\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.9263 - val_loss: 0.2148 - val_accuracy: 0.6364\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9217 - val_loss: 0.2292 - val_accuracy: 0.6364\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0655 - accuracy: 0.9355 - val_loss: 0.2309 - val_accuracy: 0.6364\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9447 - val_loss: 0.2238 - val_accuracy: 0.6182\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0586 - accuracy: 0.9309 - val_loss: 0.2249 - val_accuracy: 0.6182\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0607 - accuracy: 0.9309 - val_loss: 0.2322 - val_accuracy: 0.6000\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0572 - accuracy: 0.9493 - val_loss: 0.2314 - val_accuracy: 0.6182\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0529 - accuracy: 0.9447 - val_loss: 0.2343 - val_accuracy: 0.6000\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0499 - accuracy: 0.9493 - val_loss: 0.2404 - val_accuracy: 0.5818\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9401 - val_loss: 0.2370 - val_accuracy: 0.6000\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0713 - accuracy: 0.8940 - val_loss: 0.2402 - val_accuracy: 0.6000\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0536 - accuracy: 0.9401 - val_loss: 0.2297 - val_accuracy: 0.6000\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0564 - accuracy: 0.9263 - val_loss: 0.2384 - val_accuracy: 0.6182\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0549 - accuracy: 0.9447 - val_loss: 0.2416 - val_accuracy: 0.6182\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0581 - accuracy: 0.9447 - val_loss: 0.2309 - val_accuracy: 0.6182\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0581 - accuracy: 0.9493 - val_loss: 0.2306 - val_accuracy: 0.6182\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0552 - accuracy: 0.9447 - val_loss: 0.2259 - val_accuracy: 0.6182\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.8971\n",
            "accuracy: [0.07091015577316284, 0.8970588445663452]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwU9f3H8dd3NydJCIEkXOE+BOQ2ICggiFqgCtYbDzyLWPGorS3+2p9nxWq1KtUqVKnHzxNPBFEBiYgJcqrcEG4QSAhXQu7s9/fHd4ed3ewmAZNsdvk8H4997OzM7Mx3J5v3fPc735lRWmuEEEKEPkewCyCEEKJ2SKALIUSYkEAXQogwIYEuhBBhQgJdCCHCRESwVpycnKzbt28frNULIURIWrly5UGtdYq/adUGulJqJnAxkKO17ulnugKeB8YAhcBNWutV1S23ffv2rFixorrZhBBC2CildgaaVpMml9eAUVVMHw10cT8mAi+dTOGEEELUjmoDXWu9GDhUxSzjgDe0sRRoopRqWVsFFEIIUTO1cVC0NbDb9nqPe1wlSqmJSqkVSqkVubm5tbBqIYQQlnrt5aK1nqG1Ttdap6ek+G3TF0IIcYpqI9D3Am1sr9Pc44QQQtSj2gj02cAEZQwCjmqt99XCcoUQQpyEmnRbfAcYDiQrpfYADwGRAFrrl4HPMV0WszHdFm+uq8IKIcQJWVmQkQHDh8PgwcEuTYNQbaBrrcdXM10Dd9ZaiYQQojpZWSbIKyogKgoWLpRQR079F0KEoq++gtJSE+ilpaamLiTQhRAhqEMHz3BUlKmtCwl0IcJaVhY88YR5DifR0eY5IgK+/FKaW9yCdnEuIUQdy8qC884Dlyv025l9D4Bu3GjGl5dD06bBKwvU/MBsPRzElUAXIlzNnQtlZWbYamf2FyTVBU2we5NkZcGIEeYzxMSYHdPGjWYnVVoKq1bBmWfW7frtAX7++VBSAk4naG12mFa5fLeP9d4jR+CZZ8y8kZFwyy0wYUKtb08JdCFqItihdio6d/YMB2pntnqLlJebZgzfUPrmG7jgAhNcdV3LD7SNMzJMgIJ5zsgwgT58OHz7rQn0G2745evxN/6778zOpKLCbJ8bbzRl0NpsM0tRETz8sHlYZW7WDO66y+x07EpLYfp0eP31Wt+eEuhCVMdqurD+qRtq04VvICUlmfGpqfDJJ/7L/PXXnsDxV4t/7TVPcJWWwhtvnPyOrSYBWlwMF13kf8cxfDgoZaZpDTt3wvr1Jmh//tl8tquuClwe+3qKiuBXvzJ/S6cTXnwRJk40O4bzzzc1aOtvDHDTTd6/csrKTBn8mT/frEdrs3yHwzv07bSu+lfTKZJAF6I6CxbUrOmitp1MUwhUbpbYs8eMP3wYBgzwv7zWtuvoRURUrsUnJppnpUwA/uc/Joyio+G55yAvr+qgBk8TRUyM5z3NmsE993jGDx0aeMfRs6dZZ3w8FBTAjBnmdU6OqamXl5v5xoyBFi28mzKysrzXf/bZnvWUl8PkydCrFzz7bOX1//e/nl8Glv37zfOQIbB8ued74XKZMtkD33q2dkZKmZB3ODzHNWq5d44EuhBQdXi2auUZrq1/wuoOrFX3q2DuXLj0Uk9N8+KLPeFj7XSOHjWvy8rgo4/guuu8a6CDB0NhoZnH4QB/dxArLjbPfftCmzYwe7Z5XVQEkyaZkLLXaF9+Gd56yxP69iaK4mK4805TZqVMWcBMt4ISPDsOl8sM33uvGT92LLz9ticoV63yLKO01NTUwQTxokXm81nNNdb6t2/3/nxlZXD33bB2rff4/fs929MK5IoKs90BVq6EadM8O6ff/c5Mj4z0/OLR2ry+6SZIT/fs/Pz9vWuL1jooj7POOksLETSZmVpPnWqeMzO1jorSWimtY2PNa7uXX7Z+7Gv94INVL6sm05Ys0ToiQmuHw6zX6TTD9nU//rhnnU6nWYZl8WKtk5I80615rOHoaLOc667zjBs1yjOslNaTJpllXX+9WZb1ft/Pf955Zvw552j9hz94r9O+7kmTzHp9x99+u1kfmM/o7/0Oh9a9emkdGWlex8RUng5az57tmQfMNoyO9izf/rjoIvM57NtRKbO9hw837/VXDt9hpcy8vuvw/Zvcc48Z/8or3p8h0HfqFwBW6AC5KoEuGpaqwrG2LFjgHaLnnx/4H1VrrSdONKHXrJnWPXt6ly0z0/PPGxPjmZaZqfUVV5h1OJ1mPdOnm2VfcYV3yPhb94cfVg5oa7nVhdENN5h5hw0z5QVTdvv81jI7ddK6Rw/P+x0O78/fvLkZn5Ki9R13eAeq9YiNNdvI3/g33jDDkZFaN27sP9AbNTLb7vLL/U8HrePjTXkmTaq8I5k0qXK5rPC2fy5r2rRp5rNbO6uqHhERWv/pT+az2JflG9Lz5plp//M/5vmaa6r+Tv0CEugiNCxaZL78Vq1o+vTaXb61sxg2zH8QWsHjuzNJTzcPqxYbFWVCxFqePUSsnZFvwDgcZroV8PbAsAegte7PPvOM79LFszO49Vbv9fnWftu21XrgQLOMjh21Hj/eE8rJyd5l6tfPPF9+uVm3tRyrDIcOmXGpqea5d29Tk46NNZ/B+ozDhmn96197ymR9pjff1Pq228zwnXd61nvOOWaHYl8GaH3ttZ7PY20ra1rbtp5fU9b67dsrM9P8TQYO9N4+/v7O1vusX2b2v71vjd8KY+tvbf0dfL8j27eb+Xv0MM9z5/ovZy2QQBcNm/XPYoVCVeFa1futf1J//3Bz5nhq5b4/ne2v09O931daav7phw6t/N7YWO+ABdPMMXiw9zh/67EC59JLPa+feMKzXmtHYX+fPSytWuKLL3qaOlJTtf7rX818//u/Zt7779e6b18zfexYT3D7bufp0z3b/8orTTjOmGFe33yzZ177jmz69MpNERER5nOA1pMne6bbg9P+a+Wddzzjn3zSOwSnT9d60CDPZ7cHcVVNXNZOwtp2Dod3s4m9xmztCKzPZb22djg1DeOKCs8vtaZNtXa56uzXpgS6CC7fL7b99bx55h/HevjWaqv7qTp9uud99sC2h0ZmpicYrEdCgicElfL8Mjj7bO/lv/66me+228wyfWt91bUPW2WzasnWo1Ur8xwXZ2qVCQmmxmxto2uv1Tox0f9y4+JM27B9XtC6e3et77vPE4Cg9dVXe8oQE2O2yYUXVt6xTJ3qaTbwLbu9+eeFFzzbZupU/zvIqVO1bt3ae1qgpqXvvvMf9NZne+QR/0FclQ8+8CyvUSOtH3vMLPdkasynEsZ9+ugTv0DqkAS6OHWnWsuw1+KsA4DWP6y9zdnejqmU+Qe0aqFRUVWvNzPT/wExe20xUO3YXmMcO9aUdexYE6IVFWb5L73kCSUrDCdN8n6vv8Cyj7MfmOzf3zP8pz95hsePr3xQsndvU9O3t93aP5d9uzz2mGd9vu3rffp43m9vPrB/Bqs93d58ZP8M8+d7XmdkeG9/f23L9p2sNT4qyn+td+rUqgM7UBNLdTp1Msu84ILK38m6Oj5z9dVmnbfcUjfLd6sq0KXbogjM6jpXXh741GZ/Fi/2nKThcJjuXGC6c82Y4ekKV1oKe33uVjhwIDz+OIweDX36VL2+Dz80kRGI1a/YWr/T6Rm2n/Dx1VcwZYrpwzx7NvzhD9Cpk+nOZi2/tNR0O3vpJejXz3TZs6Y5HKYPt1KmG5z1uaOjYdgwT1e7tWs9XeCmTTMn/OTkmOVayyopMdt5wwb4/e/N6eIZGbBsGXz6qSdq7X3hXS7Pcq11W935xoyBzZtN+a0ul1Z3vjfeMPPY+21bp9NbtDbdBRMTTTfIoiLPtMGDTVmtsyKtbnnWyTXWtrngAu8zKO3d9YYPN98te/ns7OuoaTe/rCxz8hGY72JWlnmf9agrjRqZ59jYultHdQIlfV0/pIbeAPnWYOw1tpr+3M3MNAew/NWYra6B9tpf06Zm2Gr3fPxxs5zJk838t97qad/0ddddnhqgdYDN4ah84NFeU4yMNNP8tam+/Xbg2r69PX/qVO/2WauLnL8DZ/ZmCd+DmPb2ZXuXP+tXi72LZFU1Vd9pDz7oWdZnn51czdR+cNFfWWvaXFHXzRtVsf99armHSUD2Xz3V/bL8hZAml9NUdf8ovgcTfbvf2Zs07F3nqlqfv+YI63Hllf7H2/tIz5tnljVtmvc80dGV21eHDjU/rX0PiD73nOd9gwd7/9S3luGvTdXeZ9m+0/HtcXMygWWf197s4LtDmTRJ63HjKu8AfYO7Jv3dMzO9jyWcSrjYyx3ogGJ176/r7qdVrbuOepgEVI87EQn004m9lmjVev19qa3+zFbvgUmTvGtk1heyUSMz7uab/a/Hvty//c07CO21e9D6N7/xLN9eI7VOxgDTG8V3Wb7LjI3V+umnzWvfcmmt9TffeN7j70BboM/g28dbKU/tO9B2PtVeOP52KL5t2NbBypNl/1XwS8KlqrI2dPW9Q6nHnYgEeriornuevYYcqFeBxTqQZq8hWsFrHXQrKPDMM2SI93qsnUVkpKdJ5IYbPOv2PQjmdJqav9Wl7uWXvZscfH/SV1fbr+qXwy8JNGtH6O/kkdrmb4fi72DlqSy3tsMlmDXuUFFP20gCPRzYa9TW6eJW7dqqgdrPogvU/mt96R5+2DPdamKxutYNG2bm3bLFvG7d2qzvoYfMfKNHV16HPYisJgr7F9zq4WGd9BKobdlfH+EBAwIHu7+ujb800ILdXGDvF/1LliMBHJYk0BuqmraJau19pp1vX2grGAPVaK2AXrzYc4DLPu+jj2q9d69n2Z06eeYHTz9nq/tZoHCt6hfBJZeYadZp6YHalgM1D1nd42pyZmd121aIEFZVoEu3xWBZsoQTtweLiPBclxk8Nx2wLoX6/POmy5rF6fR0u7OiDTzdzcaPN1fXKy833fRatDDjn3/e052trMx0dUtIMJdZte45OXo0zJsHx4/Dvn1mnHVdbZer8sX67V3krNe+3c+ysuCLL8zw++/DHXdU7o4Ggbum+XaPu/de073P4YAXXvDfFa2uu6gJ0RAFSvq6fpz2NXR7jdvebq2194V97CeLWG3crVubZ+saG/ZHUpJ3G3vXrqYXSUaGOcPQXrNv29a0jTdtas4edDrNmXmg9bJlnt4in39euWZutTFfeqn3wVR/BxFruweA1L7FaQxpcgmSQAcup071f2W5Cy6o3F3Pt33Zaudu08a7V4S9PdrebDF+vNYtWlS+vgVoPWJE5YtIWV0XZ87U+s9/NtNdrsq9YOx9r6trrw5GNzIhwlRVgS5NLnUlK8ucJVhebs4cW7jQnCE5cqSZrpS5W3l+vueuJwsWmIddairk5pq4jYoyy5w1C1JSYMcO71tzgXm231Wne3d45x3vZUZEmHL5NpeAKYvTCTNnmuaYFi3MOiZMMPdAtM7oe/hhT5NGdWfyncrZfkKIkyaBXlcyMrxvaZWRAVu2eAdv167wz3+acPzqK+/3OxyeU8kTE6FdO/j3v03b+6xZ8MMP5lTyqCizHqfTzF9e7t2G3a2b9zKjosyyNm40NxHOzDTt0dYp406nWeeSJeb1GWeY91YVyjVpr5Y2bSHqnAR6XTn3XM+w02lCcMMG73n69jUh9/DD5ma91g5AKXP9i+7dzYFMMNc3GTzYzGfVrCsq4Le/hbZtAx9YtALd4fBcs2PyZDPu9dfN8q3baOXlwa5d5o7kULn2LqEsRMMWqC2mrh9h34a+erWnXfrii824AQNMl0B/18Xwd0KL/YzH1avNfCfbHr1okWcZ1hmhVR2gzMz0Povz0ktrdbMIIX4ZqmhDdwR7hxKyFi82tWaru5+vVavM85lnmqaRI0fMjWXbtTO1ZfA0xYDpsvjNN/C3v3muati3r5kWGWna2sHT9PHYYzW7+mFWlvf6wDS7OJ2Br263YAHExZnX/frVZGsIIRoAaXI5FUuWmCDU2nPA0zdYV62C+HgT1PfcAxdeaJow+vUzIevvcqG+TRrr1nna0X/1K896TqbpY/hwcxlXa30TJphHVQcohwwxfdlfecW01VuXHxVCNGgS6KfiX//yPpnH6lEyZw689Za5LvKyZSa8U1LMfCtWmOcXXjDXwrauHV1VUGZkeHqx2NdzMgIdzKxuOd27m+dPPzUnBdX0WuhCiKCRQD8Z8+ebWuucOZ5xEREmKB99FB56yHv+Xr1M04wVyuC5UcIDD1S/Pt/atW/zSE2dysHM4mLPwddT3ZkIIeqVBHpNZWXBRRd5Xlt3v7ntNti6FR55pPJ71qyBTZtM6Ft9zU8mmIPZf3vEiNrZmQgh6k2NAl0pNQp4HnACr2it/+4zvS3wOtDEPc8UrfXntVzW4Jo/3/u1y2VO+lm82PQPt2rgvqyuhRb77b5qIlhdBeVkICFCTrWBrpRyAi8CFwJ7gOVKqdla6/W22f4KvK+1fkkp1QP4HGhfB+UNng4dvF9HRZkeLIsWecY5HJCeDq1amQtcWSf5nGyINxTS71yIkFKTGvpAIFtrvQ1AKfUuMA6wB7oGGruHE4Gfa7OQQZWVZWqp1s2Fr7gCkpPNAc+77vLMZ90U+LnnTAha75ParRCintQk0FsDu22v9wBn+8zzMPCVUuouIA64wN+ClFITgYkAbdu2Pdmy1r+sLHP3eutSs2DOrmzUCJ54whPy9jub23uRSJALIepRbZ1YNB54TWudBowB3lRKVVq21nqG1jpda52eYnXna8jmzDG9PSoqzKNJExPmYGre1gk60dHeYS6EEEFQkxr6XqCN7XWae5zdrcAoAK11llIqBkgGcmqjkHWmqmaRrCz47DPvcdaFqkAOGgohGpyaBPpyoItSqgMmyK8BrvWZZxcwEnhNKdUdiAFya7OgtS4ry3TNsw5c2k+csZpaios982vt/046EuRCiAai2iYXrXU5MBn4EtiA6c2yTin1qFJqrHu2PwC/VUr9CLwD3OS+iEzDlJVlTskvKTFNKfZrqoAZLikxw06n51ookZH1XVIhhKixGvVDd/cp/9xn3IO24fXAub7va5CsmrkV2FD5xJnhw02IV1R4379z2jT4zW+kVi6EaJBOv6st2mvfllmzzPMTT3guRJWSAr17wy23eOYrL/euyQshRANy+p36P3y459oq0dEm3J96ygS5y2Vq6x99BPv3w333mSsP2m+9JqfACyEaqNOvht6vnwn0ESNME4pS5vT9sjJPe7pVY+/f/+SvPy6EEEFy+tXQN240NfHbb4dt2ypPj4qCmBgzbN3cQXqzCCFCQHgHutXPvFkzWL3ajEtNNc+9epl7ccbEeO7k43CYmzU//LA5iWjTJglyIUTICN9A99ebBUyvFacTunQx3RCtk4OKikyzyo4d5kbMWsPIkdLMIoQIGeHbhv7115XDHEw7eXKyp0/54MHmZhMTJpjX06ZVvhuREEKEgPAN9NhY82xdVMsuIaHyzZ07dYLERFi+3LwOdBNlIYRooMIz0LOyYOZMc5PmRx+F6dNh0iRISzPTt241zSn2UF+6FPLzzbDTaW5KIc0tQogQEn5t6PbrsEREmOC2Qjk+Hp5+2v9Nl32bVtq2lTAXQoSU8KuhZ2R4eq1o7R3Ul11mmmL8NadYN2SWphYhRIgKjxq6/TK41nVYrLM+7cFc1SVv5XK4QogQF/qBnpVlAri83NSwFy40fcxzc+H990/ukrdyApEQIoSFfpOL1cTicpnnRYvMQc9LLpFwFkKcVkI/0Pv39wxHRZkTho4d8x4vhBCngdAP9KQkz/CMGZ5hCXQhxGkm9NvQt2zxDBcWmmuxOByePuVCCHGaCP0aena2ORu0aVP49FN46y3Tnj56dOWzQYUQIoyFR6C3aQPdu8MXX5gwB7kOixDitBP6gb5li7ld3LJlnjB3OOTkICHEaSf0Az0725zdWVFhXjsccMEFch0WIcRpJ7QD/fBhyMuDAQM8p+1HR5sbVEiYCyFOM6Hdy+Xjj81zWpqcti+EOO2Fbg09KwvuuMMMP/KIeX7gAQlzIcRpK3QDPSMDysrMcFmZ9GgRQpz2QjfQhw83beYgPVqEEIJQDvTBg2HIENNlUXq0CCFECAc6mLsS9e4tYS6EEIR6oP/8M7RuHexSCCFEgxC6ge5ymUBv1SrYJRFCiAYhdAM9N9fcpUhq6EIIAYRyoP/8s3mWQBdCCCCUA33vXvMsTS5CCAHUMNCVUqOUUpuUUtlKqSkB5rlKKbVeKbVOKfV27RbTDyvQpYYuhBBADa7lopRyAi8CFwJ7gOVKqdla6/W2eboADwDnaq0PK6VS66rAJ/z8s7mxRYsWdb4qIYQIBTWpoQ8EsrXW27TWpcC7wDifeX4LvKi1Pgygtc6p3WL6sXcvNG8OEaF9fTEhhKgtNQn01sBu2+s97nF2XYGuSqnvlFJLlVKj/C1IKTVRKbVCKbUiNzf31Eps2btXmluEEMKmtg6KRgBdgOHAeOA/SqkmvjNprWdordO11ukpKSm/bI1btsDx43LfUCGEcKtJoO8F2thep7nH2e0BZmuty7TW24HNmICvG5mZsHUrbNoEI0dKqAshBDUL9OVAF6VUB6VUFHANMNtnnk8wtXOUUsmYJphttVhOb3PmmGet5WbQQgjhVm2ga63LgcnAl8AG4H2t9Tql1KNKqbHu2b4E8pRS64FFwP1a67y6KvSJni1yM2ghhDihRl1EtNafA5/7jHvQNqyB+9yPuudymecpU+Dii+Vqi0IIQajeU3TNGkhNhccfD3ZJhBCiwQjNU//XroWePYNdCiGEaFBCL9BdLli3Dnr1CnZJhBCiQQm9QP/oI9P/PDY22CURQogGJbQCPSsLrrvODD/7rPQ/F0IIm9AK9IwMKCszw+Xl0v9cCCFsQivQhw+HmBjpfy6EEH6EVrfFwYNh4UJTMx8+XPqfCyGETWgFOpgQlyAXQohKQqvJRQghREAS6EIIESYk0IUQIkxIoAshRJiQQBdCiDAhgS6EEGFCAl0IIcKEBLoQQoQJCXQhhAgTEuhCCBEmJNCFECJMSKALIUSYkEAXQogwIYEuhBBhQgJdCCHChAS6EEKECQl0IYQIExLoQggRJiTQhRAiTEigCyFEmJBAF0KIMCGBLoQQYUICXQghwoQEuhBChAkJdCGECBM1CnSl1Cil1CalVLZSakoV812ulNJKqfTaK6IQQoiaqDbQlVJO4EVgNNADGK+U6uFnvgTgHuD72i6kEEKI6tWkhj4QyNZab9NalwLvAuP8zPcY8CRQXIvlE0IIUUM1CfTWwG7b6z3ucScopfoDbbTWc6takFJqolJqhVJqRW5u7kkXVgghRGC/+KCoUsoB/BP4Q3Xzaq1naK3TtdbpKSkpv3TVQgghbGoS6HuBNrbXae5xlgSgJ5ChlNoBDAJmy4FRIYSoXzUJ9OVAF6VUB6VUFHANMNuaqLU+qrVO1lq311q3B5YCY7XWK+qkxEIIIfyqNtC11uXAZOBLYAPwvtZ6nVLqUaXU2LouoBBCiJqJqMlMWuvPgc99xj0YYN7hv7xYQgghTpacKSqEEGFCAl0IIcKEBLoQQoQJCXQhhAgTEuhCCBEmJNCFECJMSKALIUSYkEAXQogwIYEuhBBhQgJdCCHCRMgF+ptLd5L+t/mUVbiCXRQhhGhQQi7QIxyKgwWl5OaXBLsoQgjRoIRcoLdIjAFg31G5050QQtiFXKC3dAf6fgl0IYTwEnKB3qKxO9CPSaALIYRdyAV6YmwkMZEO9h8tCnZRhBCiQQm5QFdK0aJxDPuPyUFRIYSwC7lAB3NgVGroQgjhLSQDvWVirPRyEUIIHyEZ6M0bx5BzrASXSwe7KEII0WCEZKC3TIyhtMLFocLSYBdFCCEajJAM9OaNpS+6EEL4CslAl5OLhBCispAO9H1ycpEQQpwQkoHeLD4ap0Ox74h0XRRCCEtIBrrToeiYHMfan48FuyhCCNFghGSgA5zbOZnl2w9RUl4R7KIIIUSDELKBfk6nZhSVVbB615FgF0UIIRqEkA30szs2w6EgM/tgsIsihBANQsgGemJsJL3SmvDd1rxgF0UIIRqEkA10gCGdm/HD7iMUlJQHuyhCCBF0IR3oZ3doRoVLs3rX4WAXRQghgi6kA71f2yY4FKzcKYEuhBA1CnSl1Cil1CalVLZSaoqf6fcppdYrpX5SSi1USrWr/aJWlhATyRktGkugCyEENQh0pZQTeBEYDfQAxiulevjMthpI11r3Bj4AnqrtggZyVrsmrN51hAq5lK4Q4jRXkxr6QCBba71Na10KvAuMs8+gtV6ktS50v1wKpNVuMQNLb9eUgpJyVu86zOLNuWgtwS6EOD3VJNBbA7ttr/e4xwVyKzDvlxTqZJzVLgmA61/9ngkzl/Hiouz6WrUQQjQotXpQVCl1PZAO/CPA9IlKqRVKqRW5ubm1ss60pFjaNm1EfHQkQ7sk88z8zXz248+1smwhhAglETWYZy/QxvY6zT3Oi1LqAuAvwHla6xJ/C9JazwBmAKSnp9dK24hSilmTBhMT6SQ6wsHVM5Zy1zur+WLtfp65qg8xkc7aWI0QQjR4NamhLwe6KKU6KKWigGuA2fYZlFL9gOnAWK11Tu0Xs2rNG8eQGBtJTKST928fxL0XdGHumn18uGpPfRdFCCGCptoauta6XCk1GfgScAIztdbrlFKPAiu01rMxTSzxwCylFMAurfXYOix3QNERTu4Z2YWv1h3g/5buokfLxtz2+gqOFJXRMTmOO0d0ZlzfVrjLKYQQYUMFq1dIenq6XrFiRZ0t/63vd/KXj9fSNC6K2Egn4/q24uuNOWzcn89Tl/fmqgFtql+IEEI0MEqplVrrdH/TQvpM0aqM69uauCgnhwtLefbqvvxpVDc+v3soPVo25pUl26R7oxAi7IRtoMdHRzD1sl48fUUfBnZoCoDDobj53PZsPlDAd9lylUYhRHgJ20AHU0u//Czvc5wu6dOK5PgoXl2yDYBZK3Zz62vL2ZpbwKb9+SzfcSgYRRVCiF+sJt0Ww0pMpJNbhnTgqS828e6yXTw2Zz3HSyvI2Jx74vIB4we25eGxPYiOMF0eXS7NzkOFdEiOC2bRhRCiSmFdQ0MVx9MAABb3SURBVA/ktiEd6Zwaz5SP1lDm0nwwaTA3Dm7PQ5f0YNJ5nXhn2S5umrmc4+7rrE/7egsjns7gg5XSDVII0XCddjV0gKgIB09c1ourp2dxx3mdSG/flPT2TU9M79o8nj/O+pEbXv2e567uxyvfbifSqZjy4U+0ahLDOZ2Sg1h6IYTwL2y7LdZEzrFiUhKi/fZJ/2LtPu56ZzURDgfF5RXMun0wUz5aw5HCUj6/ZyipCTEn5i0td6EURDpPyx88Qoh6dFp2W6yJ1MYxAU8wGtWzJf+ZkI5La8b1aUV6+6b8+7r+FJSU8/v3fjjR3l5QUs6lL37HuX//mlkrdkt3SCFE0JzWgV6d4Wek8t2U83nqij4AdG2ewCNjz+S77Dwen7uB4rIK7nlnNZsO5JOSEM39H/zEf77dxupdhxn61NdkZh8M8icQQpxOTss29JORHB/t9frqAW3ZuD+fmd9t5/0VuykoKeexS3ty/dltueP/VvHUF5to0iiSgwWlPPnFRt6ZOIhn52/m4t6t6NOmSZA+hRDidHBat6GfqgqX5q+frOFYcTkTBrXj7I7NADhSWMqY57/laFEZVw9oy8zvttOtRQIb9+cTHeHg75f3Ylyf1jgcNb+OzNbcAuKiImiRGFP9zEKIsFdVG7oEei3bd7SIwtIK0pJiGf6PDPYdLeb3F3Rl8ZZcVu48TKeUOHq0SqRLajx3juiMAuZvOMCrS7Yzslsqt5/X6cSy1u49ypUvZ9GmaSxf3DPspHYEQojwVFWgS5NLLWuZGHti+Nmr+7LlQD7XD2rH70Z0Yu5P+3h72S7W7DnCZz/+zM68QvKOl5CxKZeE6AiWbT9EoygnNwxuz9bcAm59fTkAmw8U8NX6/Yzq2dJrXfnFZTz62XrObNWYcX1bkxQXVauf5cCxYpo3ll8GQoQKqaEHydNfbuKFRdlEOR38z5huXDOwLZPfXsWCDTn0b9uEDfvyiYl08H+3nc3kt1cTE+nkoUt68MXa/cz5aR//vKoPS7fl8e+MrQDERTn53YjOXDOgDc182v0/XLmHhRsPUFaheWTsmTSNi2LvkSI6pcQHLN9/v9vOI5+t55kr+3D5WWmUV7iIkG6ZQgSdNLk0QFprZq3cQ89WifRo1RiAkvIK3szayVvf76JDchxPXNaL5o1j+GDlHv4460cAIhyKJo2icGnN8ZJyxvRqyW1DO/Dcgi3MX38AgM6p8ZzZqjE3ntOe7JwC/vTBT7RuEsvRojLioyNQCvYfK2b2nUPolZZYqWwZm3K45bXlKKVIjo/ir7/uwZ8++InfDu3A7y/sWuW15LXWHC+tID5afvwJURck0EOc1prlOw5TUl5Bp5R4CksrGPvCEspdmq//cB5pSY0A0+b+zeZcVu08zOrdRzhSWEqEw8GADkm8fvNANh8wzTipjWPYnlvA2R2b8a/x/fhk9V4yNuXSOimWQR2bcfc7q2mfHMeU0d24ceYyAJo0iuRIYRnjB7bh0XE9/Z5EVVxWwT3vrubbLQf57K4hXr8AyipcZOcU0L1l4/rZaEKEKQn0MLR8xyEKissZ0S3V7/T84jIen7uBn/Yc5c1bB55ohqlwaZwOxXMLNvPcgi10bR7P5gMFtEyM4cCxYlwauqTG8/ZvB5GSEM0fZ/3IlgP5vHbzQF5Zso0XF23l7A5NGdOrJcnx0QzrmkzGplwWbjjAT3uPsv3gcWIinPRKS+S6s9vyxdr93HtBV6Yt3MLcNfv4780DGHFG6omyKPB7sFdrzZfr9nOwoJTuLRtzVrskjpeUs/twId1ayE5BnL4k0EUlRwvLGPLk1wA8fVUfLurRnPX7jvHJ6r1MHNaJlASzA7C+H1Yzy8er9/DAR2soLnO5x4PWkJoQTfvkOG45twNHCkuZ8tEaAJwOhUtrtDbt/B1T4pk9+VwOFpRy48xluLRm+g1n8fHqvUQ6Hdw5ojMA7y3fxZ8/NMtwKHjy8t68uXQnP+05yi3nduBPo86o8gbgu/IKiYlyeF2i4WSUlrv4aNUe+rRpIr8qRIMigS782nIgn7joCFo1ia1+ZpvisgoKSyvIzing64059G2TyEU9WpyoaWuteXTOelo3ieXi3q14/PMNnNmqMc3iorj/g5+YMLgdS7YcZN/RYiIcioLScqyv4Zu3DqR9szhGPbeY3mlNePqqPtz19ipW7TpChEPxqzNbMHfNPlITorn9vE7ccm57jhSW8ebSnew4eJxBHZvRp00TLn8pk+T4KL64dxjHist47bsdLNhwgL/+ugfDuqYAsP9oMbn5JSeOI2it+eSHvWzYl8+CDQfYlnucSKfiz6O6cdvQjrW34evArrxC2jSNlXvlngYk0EWDUF7hYvTz37Ilp4C0pFievbovcVERPP3VJq5KT+PJLzZRVFpBuctFcZmLL+4dSlpSI44UlvI/H69hXN/W/OrMFmRtzeNfX28hc2se913YlUWbcvhh9xGSGkVx6HgpMZEOoiOcHC0qY1zfVizZcpDDhaU0i4/mWFEZ/5mQTv92Sfx62rf8fKSIN289m0Edm7Fg/QFue2MF0REOOiTHcdf5Xfh49V4WbDjAnLuG0LO15wDyoo05fPLDXv540Rm0aWqOYfzzq03sOVLE3ed3YdmOQ8RHRzCmV0teXJTNj7uPMG18P69fFfPW7OODlXuYMSEdp0ORX1zGQ5+uo0mjKG46pz1tmzWq0XZdu/coF/9rCfdd2JW7R3bB5dJozC8bCfjwI4EuGoz84jJKy12VulYCZG3N4/pXv+estkk8eEkPrwD1pbXmrndWM+enfQC8fH1/LurRgpe+2co7y3bx4rX9eS1zBx+v3kubprG8euMAkuOjufY/S9l8IJ9uLRqzcf8xWibGcry0nGnX9OPBT9cS4XQw756hJw76HisuY9DUhYzp1ZLBHZvx4KdrSUmIZkdeIWAuDfHKjemUV7i44uUsrzIqBZPO68RL7q6lo85sQaMos6N56fqzGP38YrbmHuft286mc/N4Jry6jC05BSeOK3w46Ry/vZB8PfTpWl7P2kmEQ/G74Z34b+YO8ovL6dYigTl3DUEpxcqdhzleWk56uyQSYiL5ZnMu7Zo2or37pi0VLs2KHYfo06aJ36asN7N2kFtQyn0Xdq22PKJuSaCLkHGksJTE2Mga1SyLSiv4/Xs/MKhjU246t0Ol6YePl/Ja5g6uH9TuxDGB/OIyHpq9jo9W7eXukV24rF9rrpmxlP3HigF4/ZaBnOdukrH87ydreW/5bpwORfvkOFo3iaVvm0TO79aciW+u4MCxYpLjo1HAzJsHMG/NftLbJ/GPLzfx056jdEyJ4+LerZi2cAtRTgelFS4u6tGcr9zdTK88K42isgoWbDjAjBvS6Zwaz2X/ziQ+JoKbz23Pl+sO8LdxPSkqq+DZ+Zu56dz2DHJfbqKkvIKzpy6kT1oTNuw7Rk5+CYM6NqVjSjxvf7+LF67tx5ItB3l3+W4A2jdrxMjuzXl1yXYSoiN44br+nNc1hde+287Dn62ncUwEF/ZowdAuyYzq2YKYSCd5BSUMeXIRJeUVfHP/iBO/SOx8j7WcjOMl5VRoTeOYyJN+b0OyM+84zy/cwgOju5/4vtUFCXQhfNjbnIvLKvhg5R4KS8uZOKxTpXmzc/K54J+LSWoUybx7hnldV+fw8VL+/OFPfLX+AC9f39/rbN79R4t5bO567hzeme4tE1i4IYdeaYn8cdaPfLvlIMnxUZzbOZkv1u6npNzF3ed35r6LzgBg8eZcJri7jDoUpCU1oqisgtz8EgAGd2xGm6axNI6J5JUl23nt5gGkJESTnVPAJb1boYGRz2Tg0rD7cCHXDGjD8DNS+cvHazhYUMolfVqx5UA+W3IK+PCOc7j3XXPyWrcWCXyzOZfDhWWkJEQzeURnfj5axIzF21DAb4d15IHR3ckvLuPv8zYy/IxUIp2K37/3AykJ0dx4TnuuHdiWzK15/Dsjm6RGUeTkl7D/aDH92jahd1oTuqTGM7BDU2IinRSVVvDrad8SG+Vkzl1DyC0o4ecjxfRs1ZgIp4PtB4/z+NwN3DmiE/3aJgFmR77ncCFdmicE/PtWuDR7DxdV2Wzlcmnyi8tJbOTZkezKK2Tj/mNcdGYLtuUW8OOeI/ymX1rAZdjXd+XLmazadYS7R3ap018yEuhC/EJvf7+Lbi0T6O8OFTutNfuPFXtd9qEqW3MLGP38t0we0Zn0dklc+8r3NI2L4pv7h5Ngq6W+v2I3MZFOWjeJ5fpXvicm0sEbt5zNvLX7yNyax8684xwuLKN542gyp4zE6dP98/XMHTw0ex3N4qJYdP9wGsdE8vORIpbvOMQlvVuRX1zOhc9+Q1mFi8OFZUwb34+xfVrhcmmWbs/jXwuzydqWB8Cve7XEpTVZ2/KYe/dQ7p/1I5lbzTSl4IzmCURHOvlx9xF+O7QD76/YQ3SEg9goJ03jokhNiGbVriMndkixkU4u7dcapcy2BfjvzQN44vMNbD5QQHx0BAPaJ7nPpyjjzFaN+WzyEABufm05Wdvy+P6BkSTFRbH5QD5Lt+VxZqtE+rdtwqJNOTw5bxObDuTzxGW9GD+wLcVlFby3fDexUU4u75/G3+au5/3luzleWsHl/dN4/Dc9iXI6uPhfS1i/7xh/GdOd/363nZ+PFvPBpMGc1S6JjfvzydyaR6eUOM7rmuL1a2TG4q1M/Xwjqe6a+XdTzq+zG95IoAvRwOTkF9Mszvzz3/r6ci7t25pL+7UOOH92Tj4xkc4TJ5GBqRX+sPswjWMi/dZWj5eUc8XLWdw+rGPAZX+5bj+3v7mSFo1j+PbPI7xCSGvN3DX7eCNrJ1N/04u8ghKunrH0xPSnLu/NocJStuce538v6UGjSCd3v2uOayRERzDn7iG0axbntbxDx0tZs/co89bs58NVeyh3aS7vn8Y3m3MoKXeRX1zOPSO7kHe8hMzsPBJiIrjozBb848tN/P2yXuTml/DM/M0APHFZL/eVT9eeWEfn1Hiycwpo36wRyfHRrN59hIt7t+T7bYdONKt1TI5j28HjjOvbiiaxkbyxdCfdWzRmdM8WPDN/M62bxLL3SNGJHVKv1ol0SonntcwdJ9bTq3UiD17SgwHtm7LlQD6//tcSRpyRwuX905j45kruPr8z+SXlpCU1Ys/hQj5cuYfC0gpaNonhmgFtuSq9zSk3y0igCyECeiljK2e0iOf8bs2rnXf5jkOs3XuU9s3i/J7UVlJewdS5GxjZvfmJ7qGBZOfkM+enfdw6pAOvLtnOcwu2MLJbKq/eNMBrPpdLM/bFJazdewyAX53ZnM0HCkiOj2LXoULaJDXiySt6M2vFHhZvzmX82W25ZkAbSspd3PracjYfyOesdkncfG4Hlu84xLSFW7jvwq5MPr8LYHos3fPuao4Vl9M7LZHXbx7I/R/8xBVnpbH94HGe/GIjADcMasft53Ukc2sez83fzM9Hi7moR3P2HC5i39Eivvr9eSQ1imToU4vYd7T4xPGSCIdiTK+WpCXF8sPuI2RuzePhS3r4Pe5TExLoQogG7UhhKY/OWc99F3b1+hViyc7JZ8GGHNo2bcT53VL596Jspn2dDZhzF4Z2Cbzz0Fp7NY8UlVYQG+Xdk2dXXiH/+GoTtw/r6NW7qqCknDHPf8uQLsk8fmnPE8spLC3n5YytvLl0J4cLy3jh2n5c3LsVAD/sPsLew0WM7J7KsaIynA7l1atra24BqQnRXs1rJ0MCXQgRVjYfyOeiZxfTq3UisyefW6f97V0uHfBeBMVlFezIO16vl6OQ66ELIcJK1+YJ/OHCrgzpklznJ09VdWMZ0zOo4VwaQgJdCBGS7hrZJdhFaHDkjgVCCBEmJNCFECJMSKALIUSYkEAXQogwUaNAV0qNUkptUkplK6Wm+JkerZR6zz39e6VU+9ouqBBCiKpVG+hKKSfwIjAa6AGMV0r18JntVuCw1roz8CzwZG0XVAghRNVqUkMfCGRrrbdprUuBd4FxPvOMA153D38AjFRyZX0hhKhXNQn01sBu2+s97nF+59FalwNHgWa+C1JKTVRKrVBKrcjNzT21EgshhPCrXk8s0lrPAGYAKKVylVI7T3FRycDBWitY7WqoZZNynRwp18lrqGULt3K1CzShJoG+F2hje53mHudvnj1KqQggEciraqFa66ovxVYFpdSKQNcyCLaGWjYp18mRcp28hlq206lcNWlyWQ50UUp1UEpFAdcAs33mmQ3c6B6+AvhaB+uqX0IIcZqqtoautS5XSk0GvgScwEyt9Tql1KPACq31bOBV4E2lVDZwCBP6Qggh6lGN2tC11p8Dn/uMe9A2XAxcWbtFq9KMelzXyWqoZZNynRwp18lrqGU7bcoVtOuhCyGEqF1y6r8QQoQJCXQhhAgTIRfo1V1Xph7L0UYptUgptV4ptU4pdY97/MNKqb1KqR/cjzFBKNsOpdQa9/pXuMc1VUrNV0ptcT8n1XOZzrBtkx+UUseUUvcGa3sppWYqpXKUUmtt4/xuI2VMc3/nflJK9a/ncv1DKbXRve6PlVJN3OPbK6WKbNvu5XouV8C/nVLqAff22qSU+lVdlauKsr1nK9cOpdQP7vH1ss2qyIe6/Y5prUPmgellsxXoCEQBPwI9glSWlkB/93ACsBlzrZuHgT8GeTvtAJJ9xj0FTHEPTwGeDPLfcT/mBImgbC9gGNAfWFvdNgLGAPMABQwCvq/ncl0ERLiHn7SVq719viBsL79/O/f/wY9ANNDB/T/rrM+y+Ux/BniwPrdZFflQp9+xUKuh1+S6MvVCa71Pa73KPZwPbKDyJREaEvv1dl4HLg1iWUYCW7XWp3qm8C+mtV6M6WJrF2gbjQPe0MZSoIlSqmV9lUtr/ZU2l9QAWIo5ua9eBdhegYwD3tVal2ittwPZmP/dei+bUkoBVwHv1NX6A5QpUD7U6Xcs1AK9JteVqXfKXC64H/C9e9Rk98+mmfXdtOGmga+UUiuVUhPd45prrfe5h/cDzYNQLss1eP+DBXt7WQJto4b0vbsFU5OzdFBKrVZKfaOUGhqE8vj72zWk7TUUOKC13mIbV6/bzCcf6vQ7FmqB3uAopeKBD4F7tdbHgJeATkBfYB/m5159G6K17o+55PGdSqlh9ona/MYLSn9VZc42HgvMco9qCNurkmBuo0CUUn8ByoG33KP2AW211v2A+4C3lVL1eQv6Bvm38zEe78pDvW4zP/lwQl18x0It0GtyXZl6o5SKxPyx3tJafwSgtT6gta7QWruA/1CHPzUD0VrvdT/nAB+7y3DA+gnnfs6p73K5jQZWaa0PuMsY9O1lE2gbBf17p5S6CbgYuM4dBLibNPLcwysxbdVd66tMVfztgr69AJS5rtRlwHvWuPrcZv7ygTr+joVaoNfkujL1wt029yqwQWv9T9t4e7vXb4C1vu+t43LFKaUSrGHMAbW1eF9v50bg0/osl41XjSnY28tHoG00G5jg7okwCDhq+9lc55RSo4A/AWO11oW28SnK3IAGpVRHoAuwrR7LFehvNxu4Rpk7mXVwl2tZfZXL5gJgo9Z6jzWivrZZoHygrr9jdX20t7YfmKPBmzF71r8EsRxDMD+XfgJ+cD/GAG8Ca9zjZwMt67lcHTE9DH4E1lnbCHN9+oXAFmAB0DQI2ywOcxXORNu4oGwvzE5lH1CGaa+8NdA2wvQ8eNH9nVsDpNdzubIx7avW9+xl97yXu//GPwCrgEvquVwB/3bAX9zbaxMwur7/lu7xrwGTfOatl21WRT7U6XdMTv0XQogwEWpNLkIIIQKQQBdCiDAhgS6EEGFCAl0IIcKEBLoQQoQJCXQhhAgTEuhCCBEm/h+iq1Pg61A/WwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 10)                140       \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 30)                330       \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 30)                0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,751\n",
            "Trainable params: 1,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 30ms/step - loss: 0.3777 - accuracy: 0.4885 - val_loss: 0.3297 - val_accuracy: 0.5818\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2650 - accuracy: 0.6175 - val_loss: 0.3047 - val_accuracy: 0.5818\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2179 - accuracy: 0.7097 - val_loss: 0.2771 - val_accuracy: 0.5818\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2172 - accuracy: 0.6820 - val_loss: 0.2554 - val_accuracy: 0.6000\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1795 - accuracy: 0.7604 - val_loss: 0.2349 - val_accuracy: 0.6182\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1846 - accuracy: 0.7327 - val_loss: 0.2232 - val_accuracy: 0.6364\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1637 - accuracy: 0.7512 - val_loss: 0.2154 - val_accuracy: 0.6727\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1722 - accuracy: 0.7696 - val_loss: 0.2140 - val_accuracy: 0.6727\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1504 - accuracy: 0.7788 - val_loss: 0.2062 - val_accuracy: 0.6909\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1563 - accuracy: 0.7834 - val_loss: 0.1957 - val_accuracy: 0.7091\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1551 - accuracy: 0.7742 - val_loss: 0.1947 - val_accuracy: 0.7091\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1466 - accuracy: 0.7742 - val_loss: 0.1944 - val_accuracy: 0.7273\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1438 - accuracy: 0.8065 - val_loss: 0.1928 - val_accuracy: 0.7091\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1428 - accuracy: 0.7972 - val_loss: 0.2023 - val_accuracy: 0.7091\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1372 - accuracy: 0.7972 - val_loss: 0.2134 - val_accuracy: 0.7091\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1391 - accuracy: 0.7926 - val_loss: 0.1983 - val_accuracy: 0.6909\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1335 - accuracy: 0.8111 - val_loss: 0.1978 - val_accuracy: 0.6909\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1400 - accuracy: 0.8018 - val_loss: 0.1965 - val_accuracy: 0.6727\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 0.8525 - val_loss: 0.1990 - val_accuracy: 0.7091\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1212 - accuracy: 0.8387 - val_loss: 0.2085 - val_accuracy: 0.7273\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1274 - accuracy: 0.8387 - val_loss: 0.1999 - val_accuracy: 0.7455\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1278 - accuracy: 0.8295 - val_loss: 0.1877 - val_accuracy: 0.7455\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1288 - accuracy: 0.8249 - val_loss: 0.1926 - val_accuracy: 0.7455\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1341 - accuracy: 0.8111 - val_loss: 0.1965 - val_accuracy: 0.7455\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1184 - accuracy: 0.8341 - val_loss: 0.1940 - val_accuracy: 0.7455\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1175 - accuracy: 0.8802 - val_loss: 0.1960 - val_accuracy: 0.7091\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1086 - accuracy: 0.8433 - val_loss: 0.1960 - val_accuracy: 0.6909\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1174 - accuracy: 0.8387 - val_loss: 0.1951 - val_accuracy: 0.7091\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.8618 - val_loss: 0.1931 - val_accuracy: 0.7455\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1082 - accuracy: 0.8479 - val_loss: 0.1938 - val_accuracy: 0.7455\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1138 - accuracy: 0.8664 - val_loss: 0.1943 - val_accuracy: 0.7636\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1163 - accuracy: 0.8525 - val_loss: 0.1941 - val_accuracy: 0.7636\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1090 - accuracy: 0.8525 - val_loss: 0.2008 - val_accuracy: 0.7636\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.8756 - val_loss: 0.2012 - val_accuracy: 0.7455\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1184 - accuracy: 0.8387 - val_loss: 0.1951 - val_accuracy: 0.7455\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0997 - accuracy: 0.8756 - val_loss: 0.1942 - val_accuracy: 0.7636\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1084 - accuracy: 0.8525 - val_loss: 0.1975 - val_accuracy: 0.7636\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1016 - accuracy: 0.8848 - val_loss: 0.1954 - val_accuracy: 0.7636\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.8295 - val_loss: 0.1939 - val_accuracy: 0.7636\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1106 - accuracy: 0.8479 - val_loss: 0.1997 - val_accuracy: 0.7636\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1047 - accuracy: 0.8710 - val_loss: 0.1964 - val_accuracy: 0.7636\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0981 - accuracy: 0.8756 - val_loss: 0.2009 - val_accuracy: 0.7636\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1021 - accuracy: 0.8664 - val_loss: 0.2023 - val_accuracy: 0.7636\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1031 - accuracy: 0.8802 - val_loss: 0.1908 - val_accuracy: 0.7455\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.8802 - val_loss: 0.1941 - val_accuracy: 0.7455\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.8848 - val_loss: 0.1981 - val_accuracy: 0.7636\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1020 - accuracy: 0.8571 - val_loss: 0.1962 - val_accuracy: 0.7455\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0950 - accuracy: 0.8802 - val_loss: 0.1965 - val_accuracy: 0.7455\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1035 - accuracy: 0.8525 - val_loss: 0.1985 - val_accuracy: 0.7455\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1068 - accuracy: 0.8479 - val_loss: 0.1931 - val_accuracy: 0.7455\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.8571 - val_loss: 0.2033 - val_accuracy: 0.7273\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.8848 - val_loss: 0.1969 - val_accuracy: 0.7455\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1037 - accuracy: 0.8802 - val_loss: 0.2053 - val_accuracy: 0.7455\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0848 - accuracy: 0.8986 - val_loss: 0.1977 - val_accuracy: 0.7455\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0899 - accuracy: 0.8802 - val_loss: 0.1922 - val_accuracy: 0.7455\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0882 - accuracy: 0.8848 - val_loss: 0.1933 - val_accuracy: 0.7455\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0847 - accuracy: 0.8940 - val_loss: 0.2007 - val_accuracy: 0.7091\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0942 - accuracy: 0.8848 - val_loss: 0.1953 - val_accuracy: 0.7273\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.8986 - val_loss: 0.1940 - val_accuracy: 0.7091\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.8848 - val_loss: 0.2053 - val_accuracy: 0.6727\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0936 - accuracy: 0.8986 - val_loss: 0.1993 - val_accuracy: 0.7091\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0870 - accuracy: 0.8756 - val_loss: 0.1978 - val_accuracy: 0.7091\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9032 - val_loss: 0.1997 - val_accuracy: 0.7273\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0934 - accuracy: 0.8940 - val_loss: 0.1989 - val_accuracy: 0.7091\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9032 - val_loss: 0.2051 - val_accuracy: 0.7091\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9032 - val_loss: 0.2050 - val_accuracy: 0.6727\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0916 - accuracy: 0.8802 - val_loss: 0.1961 - val_accuracy: 0.7091\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0858 - accuracy: 0.9032 - val_loss: 0.1931 - val_accuracy: 0.7273\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1033 - accuracy: 0.8848 - val_loss: 0.1884 - val_accuracy: 0.7091\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0840 - accuracy: 0.9078 - val_loss: 0.1897 - val_accuracy: 0.7273\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9032 - val_loss: 0.1922 - val_accuracy: 0.7455\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0892 - accuracy: 0.8940 - val_loss: 0.1930 - val_accuracy: 0.7091\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9263 - val_loss: 0.1966 - val_accuracy: 0.7091\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9217 - val_loss: 0.1991 - val_accuracy: 0.6909\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.8940 - val_loss: 0.1939 - val_accuracy: 0.6909\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9032 - val_loss: 0.1922 - val_accuracy: 0.7273\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9171 - val_loss: 0.1999 - val_accuracy: 0.6909\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 0.9078 - val_loss: 0.2025 - val_accuracy: 0.6909\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.9032 - val_loss: 0.1957 - val_accuracy: 0.6909\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0840 - accuracy: 0.9078 - val_loss: 0.2003 - val_accuracy: 0.7091\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0799 - accuracy: 0.9032 - val_loss: 0.2018 - val_accuracy: 0.6909\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0795 - accuracy: 0.9124 - val_loss: 0.2023 - val_accuracy: 0.6727\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0836 - accuracy: 0.8940 - val_loss: 0.2092 - val_accuracy: 0.6727\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.8848 - val_loss: 0.1998 - val_accuracy: 0.7091\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9032 - val_loss: 0.1989 - val_accuracy: 0.7091\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.8986 - val_loss: 0.2049 - val_accuracy: 0.6727\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.9263 - val_loss: 0.1933 - val_accuracy: 0.7091\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.8940 - val_loss: 0.1889 - val_accuracy: 0.7091\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 0.9263 - val_loss: 0.1953 - val_accuracy: 0.7273\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9124 - val_loss: 0.1894 - val_accuracy: 0.7273\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9078 - val_loss: 0.1967 - val_accuracy: 0.7091\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0799 - accuracy: 0.9217 - val_loss: 0.1957 - val_accuracy: 0.6909\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9171 - val_loss: 0.1964 - val_accuracy: 0.6909\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.8894 - val_loss: 0.2018 - val_accuracy: 0.6909\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0784 - accuracy: 0.9078 - val_loss: 0.2024 - val_accuracy: 0.6909\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0775 - accuracy: 0.9355 - val_loss: 0.1961 - val_accuracy: 0.6909\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0711 - accuracy: 0.9355 - val_loss: 0.1902 - val_accuracy: 0.7273\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.9217 - val_loss: 0.1969 - val_accuracy: 0.6909\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 0.9217 - val_loss: 0.2020 - val_accuracy: 0.6909\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.8986 - val_loss: 0.2052 - val_accuracy: 0.6909\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0743 - accuracy: 0.9124 - val_loss: 0.2126 - val_accuracy: 0.6727\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0717 - accuracy: 0.9124 - val_loss: 0.2096 - val_accuracy: 0.6909\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0843 - accuracy: 0.9171 - val_loss: 0.2175 - val_accuracy: 0.6909\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0613 - accuracy: 0.9401 - val_loss: 0.2224 - val_accuracy: 0.6545\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0765 - accuracy: 0.9124 - val_loss: 0.2022 - val_accuracy: 0.6909\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0747 - accuracy: 0.9078 - val_loss: 0.1962 - val_accuracy: 0.7091\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0760 - accuracy: 0.9032 - val_loss: 0.2017 - val_accuracy: 0.6909\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0762 - accuracy: 0.9124 - val_loss: 0.2012 - val_accuracy: 0.6909\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0793 - accuracy: 0.8986 - val_loss: 0.1910 - val_accuracy: 0.7273\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0682 - accuracy: 0.9355 - val_loss: 0.1957 - val_accuracy: 0.6909\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0792 - accuracy: 0.9032 - val_loss: 0.2041 - val_accuracy: 0.6909\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0751 - accuracy: 0.9171 - val_loss: 0.2043 - val_accuracy: 0.6909\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0718 - accuracy: 0.9078 - val_loss: 0.2152 - val_accuracy: 0.6909\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0715 - accuracy: 0.9309 - val_loss: 0.2150 - val_accuracy: 0.6909\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0687 - accuracy: 0.9585 - val_loss: 0.2102 - val_accuracy: 0.6909\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0619 - accuracy: 0.9355 - val_loss: 0.2116 - val_accuracy: 0.6909\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0632 - accuracy: 0.9355 - val_loss: 0.2157 - val_accuracy: 0.6909\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9217 - val_loss: 0.2197 - val_accuracy: 0.6727\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 0.8940 - val_loss: 0.2176 - val_accuracy: 0.6727\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.9355 - val_loss: 0.2107 - val_accuracy: 0.6909\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.9217 - val_loss: 0.2149 - val_accuracy: 0.6727\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.8940 - val_loss: 0.2165 - val_accuracy: 0.6727\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.9401 - val_loss: 0.2063 - val_accuracy: 0.6909\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.9309 - val_loss: 0.2032 - val_accuracy: 0.6909\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.9309 - val_loss: 0.2155 - val_accuracy: 0.6909\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9124 - val_loss: 0.2082 - val_accuracy: 0.6909\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.8986 - val_loss: 0.2098 - val_accuracy: 0.6909\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.9401 - val_loss: 0.2009 - val_accuracy: 0.6727\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9124 - val_loss: 0.2113 - val_accuracy: 0.6727\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0741 - accuracy: 0.9124 - val_loss: 0.2224 - val_accuracy: 0.6909\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0767 - accuracy: 0.8986 - val_loss: 0.2109 - val_accuracy: 0.6727\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0669 - accuracy: 0.9309 - val_loss: 0.2181 - val_accuracy: 0.6727\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0625 - accuracy: 0.9493 - val_loss: 0.2224 - val_accuracy: 0.6545\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9217 - val_loss: 0.2150 - val_accuracy: 0.6727\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9447 - val_loss: 0.2111 - val_accuracy: 0.6909\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9355 - val_loss: 0.2128 - val_accuracy: 0.6909\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.9078 - val_loss: 0.2179 - val_accuracy: 0.6909\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9309 - val_loss: 0.2106 - val_accuracy: 0.6727\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0666 - accuracy: 0.9355 - val_loss: 0.2154 - val_accuracy: 0.6909\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0671 - accuracy: 0.9171 - val_loss: 0.2173 - val_accuracy: 0.6727\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9171 - val_loss: 0.2184 - val_accuracy: 0.6909\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9309 - val_loss: 0.2195 - val_accuracy: 0.6727\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0591 - accuracy: 0.9447 - val_loss: 0.2114 - val_accuracy: 0.6909\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9124 - val_loss: 0.2103 - val_accuracy: 0.6909\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0607 - accuracy: 0.9447 - val_loss: 0.2231 - val_accuracy: 0.6727\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0670 - accuracy: 0.9032 - val_loss: 0.2068 - val_accuracy: 0.6909\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0595 - accuracy: 0.9539 - val_loss: 0.2122 - val_accuracy: 0.6909\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.9401 - val_loss: 0.2185 - val_accuracy: 0.6727\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0678 - accuracy: 0.9263 - val_loss: 0.2215 - val_accuracy: 0.6909\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0697 - accuracy: 0.9032 - val_loss: 0.2123 - val_accuracy: 0.6909\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0683 - accuracy: 0.9355 - val_loss: 0.2194 - val_accuracy: 0.6727\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0582 - accuracy: 0.9263 - val_loss: 0.2157 - val_accuracy: 0.6727\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0574 - accuracy: 0.9447 - val_loss: 0.2118 - val_accuracy: 0.6727\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0623 - accuracy: 0.9309 - val_loss: 0.2191 - val_accuracy: 0.6545\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0573 - accuracy: 0.9401 - val_loss: 0.2258 - val_accuracy: 0.6727\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0682 - accuracy: 0.9355 - val_loss: 0.2212 - val_accuracy: 0.6545\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0668 - accuracy: 0.9217 - val_loss: 0.2137 - val_accuracy: 0.6727\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0739 - accuracy: 0.9263 - val_loss: 0.2165 - val_accuracy: 0.6727\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0692 - accuracy: 0.9217 - val_loss: 0.2204 - val_accuracy: 0.6727\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0560 - accuracy: 0.9447 - val_loss: 0.2286 - val_accuracy: 0.6545\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0598 - accuracy: 0.9355 - val_loss: 0.2235 - val_accuracy: 0.6727\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0663 - accuracy: 0.9171 - val_loss: 0.2277 - val_accuracy: 0.6545\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0553 - accuracy: 0.9447 - val_loss: 0.2409 - val_accuracy: 0.6727\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0632 - accuracy: 0.9309 - val_loss: 0.2292 - val_accuracy: 0.6364\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0533 - accuracy: 0.9355 - val_loss: 0.2236 - val_accuracy: 0.6545\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9401 - val_loss: 0.2232 - val_accuracy: 0.6727\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 0.9401 - val_loss: 0.2160 - val_accuracy: 0.6364\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 0.9447 - val_loss: 0.2167 - val_accuracy: 0.6364\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0564 - accuracy: 0.9585 - val_loss: 0.2204 - val_accuracy: 0.6364\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0521 - accuracy: 0.9631 - val_loss: 0.2271 - val_accuracy: 0.6364\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9493 - val_loss: 0.2301 - val_accuracy: 0.6364\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0601 - accuracy: 0.9309 - val_loss: 0.2250 - val_accuracy: 0.6364\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0546 - accuracy: 0.9309 - val_loss: 0.2296 - val_accuracy: 0.6364\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0563 - accuracy: 0.9263 - val_loss: 0.2271 - val_accuracy: 0.6364\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0529 - accuracy: 0.9447 - val_loss: 0.2308 - val_accuracy: 0.6364\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0600 - accuracy: 0.9401 - val_loss: 0.2334 - val_accuracy: 0.6364\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0591 - accuracy: 0.9539 - val_loss: 0.2285 - val_accuracy: 0.6182\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0594 - accuracy: 0.9355 - val_loss: 0.2221 - val_accuracy: 0.6545\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0454 - accuracy: 0.9585 - val_loss: 0.2324 - val_accuracy: 0.6364\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0566 - accuracy: 0.9493 - val_loss: 0.2390 - val_accuracy: 0.6364\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0654 - accuracy: 0.9171 - val_loss: 0.2298 - val_accuracy: 0.6727\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0532 - accuracy: 0.9447 - val_loss: 0.2299 - val_accuracy: 0.6182\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0583 - accuracy: 0.9493 - val_loss: 0.2231 - val_accuracy: 0.6545\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0714 - accuracy: 0.9263 - val_loss: 0.2132 - val_accuracy: 0.6909\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0711 - accuracy: 0.9263 - val_loss: 0.2218 - val_accuracy: 0.6545\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0641 - accuracy: 0.9355 - val_loss: 0.2122 - val_accuracy: 0.6727\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0631 - accuracy: 0.9124 - val_loss: 0.2140 - val_accuracy: 0.6727\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0619 - accuracy: 0.9263 - val_loss: 0.2224 - val_accuracy: 0.7091\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0542 - accuracy: 0.9631 - val_loss: 0.2201 - val_accuracy: 0.6727\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0646 - accuracy: 0.9309 - val_loss: 0.2267 - val_accuracy: 0.6545\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0533 - accuracy: 0.9355 - val_loss: 0.2236 - val_accuracy: 0.6545\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0661 - accuracy: 0.9309 - val_loss: 0.2195 - val_accuracy: 0.6545\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0502 - accuracy: 0.9539 - val_loss: 0.2247 - val_accuracy: 0.6545\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0467 - accuracy: 0.9539 - val_loss: 0.2215 - val_accuracy: 0.6545\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0658 - accuracy: 0.9401 - val_loss: 0.2215 - val_accuracy: 0.6727\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0660 - accuracy: 0.9401 - val_loss: 0.2217 - val_accuracy: 0.6727\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0529 - accuracy: 0.9401 - val_loss: 0.2184 - val_accuracy: 0.6727\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0573 - accuracy: 0.9263 - val_loss: 0.2220 - val_accuracy: 0.6545\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0527 - accuracy: 0.9585 - val_loss: 0.2221 - val_accuracy: 0.6727\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0614 - accuracy: 0.9447 - val_loss: 0.2172 - val_accuracy: 0.6727\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9154\n",
            "accuracy: [0.07249721139669418, 0.9154411554336548]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_28 (Dense)            (None, 10)                140       \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 30)                330       \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 30)                0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,751\n",
            "Trainable params: 1,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 28ms/step - loss: 0.5931 - accuracy: 0.5346 - val_loss: 0.4143 - val_accuracy: 0.5455\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3574 - accuracy: 0.5392 - val_loss: 0.2961 - val_accuracy: 0.5273\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2887 - accuracy: 0.5161 - val_loss: 0.2511 - val_accuracy: 0.5636\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.2522 - accuracy: 0.5576 - val_loss: 0.2227 - val_accuracy: 0.6727\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2394 - accuracy: 0.6313 - val_loss: 0.1999 - val_accuracy: 0.7455\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1916 - accuracy: 0.7558 - val_loss: 0.1858 - val_accuracy: 0.7091\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2013 - accuracy: 0.6959 - val_loss: 0.1777 - val_accuracy: 0.7273\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1735 - accuracy: 0.7465 - val_loss: 0.1722 - val_accuracy: 0.7273\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1634 - accuracy: 0.7696 - val_loss: 0.1712 - val_accuracy: 0.7455\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1581 - accuracy: 0.7834 - val_loss: 0.1706 - val_accuracy: 0.7636\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1692 - accuracy: 0.7788 - val_loss: 0.1712 - val_accuracy: 0.7636\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1699 - accuracy: 0.7650 - val_loss: 0.1684 - val_accuracy: 0.7636\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1580 - accuracy: 0.7650 - val_loss: 0.1684 - val_accuracy: 0.7636\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1590 - accuracy: 0.7650 - val_loss: 0.1672 - val_accuracy: 0.7636\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1516 - accuracy: 0.7742 - val_loss: 0.1691 - val_accuracy: 0.7455\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1512 - accuracy: 0.8018 - val_loss: 0.1672 - val_accuracy: 0.7455\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1536 - accuracy: 0.7788 - val_loss: 0.1673 - val_accuracy: 0.7455\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1450 - accuracy: 0.7926 - val_loss: 0.1698 - val_accuracy: 0.7455\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1374 - accuracy: 0.8111 - val_loss: 0.1722 - val_accuracy: 0.7455\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1302 - accuracy: 0.8111 - val_loss: 0.1717 - val_accuracy: 0.7455\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1377 - accuracy: 0.8341 - val_loss: 0.1687 - val_accuracy: 0.7273\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1425 - accuracy: 0.7926 - val_loss: 0.1684 - val_accuracy: 0.7273\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1399 - accuracy: 0.8018 - val_loss: 0.1694 - val_accuracy: 0.7273\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1246 - accuracy: 0.8479 - val_loss: 0.1741 - val_accuracy: 0.7455\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1327 - accuracy: 0.8479 - val_loss: 0.1704 - val_accuracy: 0.7273\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1258 - accuracy: 0.8387 - val_loss: 0.1682 - val_accuracy: 0.7273\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1262 - accuracy: 0.7880 - val_loss: 0.1665 - val_accuracy: 0.7273\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1313 - accuracy: 0.8387 - val_loss: 0.1674 - val_accuracy: 0.7273\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1215 - accuracy: 0.8387 - val_loss: 0.1725 - val_accuracy: 0.7455\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1184 - accuracy: 0.8387 - val_loss: 0.1716 - val_accuracy: 0.7455\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1119 - accuracy: 0.8848 - val_loss: 0.1680 - val_accuracy: 0.7636\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1098 - accuracy: 0.8710 - val_loss: 0.1673 - val_accuracy: 0.7636\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1168 - accuracy: 0.8710 - val_loss: 0.1716 - val_accuracy: 0.7818\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1142 - accuracy: 0.8571 - val_loss: 0.1712 - val_accuracy: 0.7818\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1208 - accuracy: 0.8433 - val_loss: 0.1730 - val_accuracy: 0.7818\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1064 - accuracy: 0.8664 - val_loss: 0.1728 - val_accuracy: 0.7636\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1250 - accuracy: 0.8479 - val_loss: 0.1747 - val_accuracy: 0.7818\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1183 - accuracy: 0.8479 - val_loss: 0.1763 - val_accuracy: 0.7818\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1139 - accuracy: 0.8433 - val_loss: 0.1795 - val_accuracy: 0.7818\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1185 - accuracy: 0.8525 - val_loss: 0.1789 - val_accuracy: 0.7818\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1208 - accuracy: 0.8387 - val_loss: 0.1795 - val_accuracy: 0.7818\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1158 - accuracy: 0.8525 - val_loss: 0.1826 - val_accuracy: 0.7818\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1085 - accuracy: 0.8756 - val_loss: 0.1789 - val_accuracy: 0.7818\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1018 - accuracy: 0.8618 - val_loss: 0.1791 - val_accuracy: 0.7818\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.8525 - val_loss: 0.1823 - val_accuracy: 0.7818\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1107 - accuracy: 0.8571 - val_loss: 0.1874 - val_accuracy: 0.7636\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1066 - accuracy: 0.8756 - val_loss: 0.1830 - val_accuracy: 0.7818\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0983 - accuracy: 0.8894 - val_loss: 0.1835 - val_accuracy: 0.7818\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0990 - accuracy: 0.8894 - val_loss: 0.1821 - val_accuracy: 0.7818\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0992 - accuracy: 0.8756 - val_loss: 0.1800 - val_accuracy: 0.7818\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1069 - accuracy: 0.8664 - val_loss: 0.1833 - val_accuracy: 0.7818\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1071 - accuracy: 0.8756 - val_loss: 0.1902 - val_accuracy: 0.7818\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0966 - accuracy: 0.8848 - val_loss: 0.1851 - val_accuracy: 0.7818\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.8756 - val_loss: 0.1811 - val_accuracy: 0.7818\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0848 - accuracy: 0.9124 - val_loss: 0.1785 - val_accuracy: 0.7818\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1005 - accuracy: 0.8664 - val_loss: 0.1823 - val_accuracy: 0.7636\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.8848 - val_loss: 0.1759 - val_accuracy: 0.7636\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.8525 - val_loss: 0.1747 - val_accuracy: 0.7636\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0924 - accuracy: 0.8848 - val_loss: 0.1796 - val_accuracy: 0.7636\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.8802 - val_loss: 0.1800 - val_accuracy: 0.7636\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.8802 - val_loss: 0.1758 - val_accuracy: 0.7455\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0920 - accuracy: 0.8986 - val_loss: 0.1752 - val_accuracy: 0.7636\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.8710 - val_loss: 0.1753 - val_accuracy: 0.7636\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.8802 - val_loss: 0.1774 - val_accuracy: 0.7636\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0844 - accuracy: 0.9032 - val_loss: 0.1778 - val_accuracy: 0.7636\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.8756 - val_loss: 0.1804 - val_accuracy: 0.7636\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.8894 - val_loss: 0.1886 - val_accuracy: 0.7636\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.8986 - val_loss: 0.1844 - val_accuracy: 0.7636\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0913 - accuracy: 0.8940 - val_loss: 0.1803 - val_accuracy: 0.7455\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0892 - accuracy: 0.8986 - val_loss: 0.1822 - val_accuracy: 0.7636\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0844 - accuracy: 0.9032 - val_loss: 0.1836 - val_accuracy: 0.7636\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0819 - accuracy: 0.9217 - val_loss: 0.1795 - val_accuracy: 0.7455\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0986 - accuracy: 0.8756 - val_loss: 0.1809 - val_accuracy: 0.7455\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0866 - accuracy: 0.8986 - val_loss: 0.1827 - val_accuracy: 0.7636\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.8756 - val_loss: 0.1841 - val_accuracy: 0.7636\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0810 - accuracy: 0.9124 - val_loss: 0.1847 - val_accuracy: 0.7636\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.8940 - val_loss: 0.1824 - val_accuracy: 0.7636\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.8986 - val_loss: 0.1839 - val_accuracy: 0.7636\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.9309 - val_loss: 0.1895 - val_accuracy: 0.7636\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0849 - accuracy: 0.9124 - val_loss: 0.1847 - val_accuracy: 0.7636\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.8940 - val_loss: 0.1847 - val_accuracy: 0.7455\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0777 - accuracy: 0.8894 - val_loss: 0.1835 - val_accuracy: 0.7455\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 0.9032 - val_loss: 0.1871 - val_accuracy: 0.7455\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9124 - val_loss: 0.1879 - val_accuracy: 0.7455\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.8894 - val_loss: 0.1826 - val_accuracy: 0.7273\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0758 - accuracy: 0.9171 - val_loss: 0.1826 - val_accuracy: 0.7455\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.8986 - val_loss: 0.1872 - val_accuracy: 0.7455\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0863 - accuracy: 0.9032 - val_loss: 0.1867 - val_accuracy: 0.7455\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0875 - accuracy: 0.8940 - val_loss: 0.1818 - val_accuracy: 0.7636\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0776 - accuracy: 0.8986 - val_loss: 0.1826 - val_accuracy: 0.7636\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0714 - accuracy: 0.9124 - val_loss: 0.1819 - val_accuracy: 0.7455\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0773 - accuracy: 0.8848 - val_loss: 0.1810 - val_accuracy: 0.7455\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.8986 - val_loss: 0.1773 - val_accuracy: 0.7455\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0758 - accuracy: 0.9032 - val_loss: 0.1789 - val_accuracy: 0.7455\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.8940 - val_loss: 0.1793 - val_accuracy: 0.7455\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0738 - accuracy: 0.9124 - val_loss: 0.1803 - val_accuracy: 0.7455\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0655 - accuracy: 0.9355 - val_loss: 0.1822 - val_accuracy: 0.7455\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9078 - val_loss: 0.1817 - val_accuracy: 0.7455\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0736 - accuracy: 0.9263 - val_loss: 0.1834 - val_accuracy: 0.7455\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0739 - accuracy: 0.9263 - val_loss: 0.1868 - val_accuracy: 0.7455\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9078 - val_loss: 0.1860 - val_accuracy: 0.7455\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.9124 - val_loss: 0.1817 - val_accuracy: 0.7273\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0800 - accuracy: 0.9032 - val_loss: 0.1813 - val_accuracy: 0.7455\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9171 - val_loss: 0.1884 - val_accuracy: 0.7455\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.9124 - val_loss: 0.1842 - val_accuracy: 0.7455\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9078 - val_loss: 0.1826 - val_accuracy: 0.7455\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.9217 - val_loss: 0.1839 - val_accuracy: 0.7455\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9401 - val_loss: 0.1870 - val_accuracy: 0.7455\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9171 - val_loss: 0.1879 - val_accuracy: 0.7455\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9171 - val_loss: 0.1840 - val_accuracy: 0.7455\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9124 - val_loss: 0.1854 - val_accuracy: 0.7455\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0690 - accuracy: 0.9124 - val_loss: 0.1856 - val_accuracy: 0.7455\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.9309 - val_loss: 0.1844 - val_accuracy: 0.7455\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0582 - accuracy: 0.9355 - val_loss: 0.1841 - val_accuracy: 0.7455\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.9493 - val_loss: 0.1880 - val_accuracy: 0.7455\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9124 - val_loss: 0.1847 - val_accuracy: 0.7455\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.9078 - val_loss: 0.1820 - val_accuracy: 0.7455\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0662 - accuracy: 0.9078 - val_loss: 0.1828 - val_accuracy: 0.7455\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0673 - accuracy: 0.9124 - val_loss: 0.1780 - val_accuracy: 0.7455\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9217 - val_loss: 0.1784 - val_accuracy: 0.7455\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.9355 - val_loss: 0.1825 - val_accuracy: 0.7636\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.9171 - val_loss: 0.1910 - val_accuracy: 0.7455\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0759 - accuracy: 0.9078 - val_loss: 0.1852 - val_accuracy: 0.7455\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9078 - val_loss: 0.1842 - val_accuracy: 0.7455\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9401 - val_loss: 0.1902 - val_accuracy: 0.7455\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0772 - accuracy: 0.9078 - val_loss: 0.1818 - val_accuracy: 0.7636\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0596 - accuracy: 0.9355 - val_loss: 0.1794 - val_accuracy: 0.7636\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9124 - val_loss: 0.1818 - val_accuracy: 0.7818\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.9217 - val_loss: 0.1810 - val_accuracy: 0.7818\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9263 - val_loss: 0.1841 - val_accuracy: 0.7636\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9217 - val_loss: 0.1839 - val_accuracy: 0.7636\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 0.9124 - val_loss: 0.1896 - val_accuracy: 0.7636\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.9263 - val_loss: 0.1899 - val_accuracy: 0.7636\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0509 - accuracy: 0.9585 - val_loss: 0.1898 - val_accuracy: 0.7636\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0682 - accuracy: 0.9263 - val_loss: 0.1866 - val_accuracy: 0.7636\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9217 - val_loss: 0.1858 - val_accuracy: 0.7636\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0745 - accuracy: 0.9078 - val_loss: 0.1844 - val_accuracy: 0.7636\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9355 - val_loss: 0.1823 - val_accuracy: 0.7455\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0627 - accuracy: 0.9401 - val_loss: 0.1849 - val_accuracy: 0.7636\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9355 - val_loss: 0.1879 - val_accuracy: 0.7455\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0641 - accuracy: 0.9217 - val_loss: 0.1851 - val_accuracy: 0.7636\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9401 - val_loss: 0.1852 - val_accuracy: 0.7636\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9355 - val_loss: 0.1881 - val_accuracy: 0.7636\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9447 - val_loss: 0.1874 - val_accuracy: 0.7636\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0655 - accuracy: 0.9263 - val_loss: 0.1873 - val_accuracy: 0.7455\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0532 - accuracy: 0.9539 - val_loss: 0.1837 - val_accuracy: 0.7636\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0652 - accuracy: 0.9309 - val_loss: 0.1860 - val_accuracy: 0.7455\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0543 - accuracy: 0.9493 - val_loss: 0.1865 - val_accuracy: 0.7455\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0631 - accuracy: 0.9355 - val_loss: 0.1857 - val_accuracy: 0.7636\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.9309 - val_loss: 0.1877 - val_accuracy: 0.7636\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0511 - accuracy: 0.9539 - val_loss: 0.1843 - val_accuracy: 0.7455\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0509 - accuracy: 0.9447 - val_loss: 0.1861 - val_accuracy: 0.7636\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0592 - accuracy: 0.9309 - val_loss: 0.1864 - val_accuracy: 0.7636\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0636 - accuracy: 0.9447 - val_loss: 0.1860 - val_accuracy: 0.7636\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9447 - val_loss: 0.1877 - val_accuracy: 0.7818\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0602 - accuracy: 0.9263 - val_loss: 0.1884 - val_accuracy: 0.7455\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0490 - accuracy: 0.9447 - val_loss: 0.1882 - val_accuracy: 0.7455\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0484 - accuracy: 0.9447 - val_loss: 0.1850 - val_accuracy: 0.7818\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0769 - accuracy: 0.9171 - val_loss: 0.1853 - val_accuracy: 0.7818\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0621 - accuracy: 0.9447 - val_loss: 0.1886 - val_accuracy: 0.7455\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0598 - accuracy: 0.9355 - val_loss: 0.1839 - val_accuracy: 0.7818\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0556 - accuracy: 0.9447 - val_loss: 0.1821 - val_accuracy: 0.7818\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0512 - accuracy: 0.9447 - val_loss: 0.1848 - val_accuracy: 0.7818\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0571 - accuracy: 0.9355 - val_loss: 0.1822 - val_accuracy: 0.7818\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0646 - accuracy: 0.9217 - val_loss: 0.1839 - val_accuracy: 0.7818\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0511 - accuracy: 0.9355 - val_loss: 0.1912 - val_accuracy: 0.7818\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0596 - accuracy: 0.9447 - val_loss: 0.1873 - val_accuracy: 0.7818\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9447 - val_loss: 0.1889 - val_accuracy: 0.7818\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9539 - val_loss: 0.1919 - val_accuracy: 0.7818\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9539 - val_loss: 0.1857 - val_accuracy: 0.7818\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9309 - val_loss: 0.1844 - val_accuracy: 0.7818\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0560 - accuracy: 0.9401 - val_loss: 0.1914 - val_accuracy: 0.7818\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0560 - accuracy: 0.9309 - val_loss: 0.1866 - val_accuracy: 0.7818\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0678 - accuracy: 0.9309 - val_loss: 0.1828 - val_accuracy: 0.7818\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0508 - accuracy: 0.9631 - val_loss: 0.1891 - val_accuracy: 0.7818\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0602 - accuracy: 0.9447 - val_loss: 0.1846 - val_accuracy: 0.7818\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0566 - accuracy: 0.9493 - val_loss: 0.1863 - val_accuracy: 0.7818\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0644 - accuracy: 0.9263 - val_loss: 0.1826 - val_accuracy: 0.7818\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0504 - accuracy: 0.9447 - val_loss: 0.1862 - val_accuracy: 0.7818\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0577 - accuracy: 0.9447 - val_loss: 0.1855 - val_accuracy: 0.7818\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9493 - val_loss: 0.1898 - val_accuracy: 0.7818\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0636 - accuracy: 0.9355 - val_loss: 0.1930 - val_accuracy: 0.7818\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0516 - accuracy: 0.9447 - val_loss: 0.1921 - val_accuracy: 0.7818\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0534 - accuracy: 0.9401 - val_loss: 0.1898 - val_accuracy: 0.7818\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0452 - accuracy: 0.9493 - val_loss: 0.1853 - val_accuracy: 0.7818\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0535 - accuracy: 0.9585 - val_loss: 0.1885 - val_accuracy: 0.7818\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0565 - accuracy: 0.9263 - val_loss: 0.1927 - val_accuracy: 0.7818\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0490 - accuracy: 0.9493 - val_loss: 0.1940 - val_accuracy: 0.7818\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0477 - accuracy: 0.9539 - val_loss: 0.1880 - val_accuracy: 0.7818\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9401 - val_loss: 0.1868 - val_accuracy: 0.7818\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0520 - accuracy: 0.9493 - val_loss: 0.1888 - val_accuracy: 0.7818\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.9401 - val_loss: 0.1867 - val_accuracy: 0.7818\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9539 - val_loss: 0.1878 - val_accuracy: 0.7818\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0548 - accuracy: 0.9447 - val_loss: 0.1843 - val_accuracy: 0.7818\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0385 - accuracy: 0.9724 - val_loss: 0.1914 - val_accuracy: 0.7818\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9539 - val_loss: 0.1898 - val_accuracy: 0.7818\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0434 - accuracy: 0.9585 - val_loss: 0.1932 - val_accuracy: 0.7818\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0593 - accuracy: 0.9401 - val_loss: 0.1944 - val_accuracy: 0.7818\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.9447 - val_loss: 0.1890 - val_accuracy: 0.7818\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9447 - val_loss: 0.1883 - val_accuracy: 0.7818\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9412\n",
            "accuracy: [0.06311947107315063, 0.9411764740943909]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUVdrA8d+ZloQQCCTU0AWVIjUiiAUUCxbAjg07dtfVfX31tSy77uquZS2rq2BZXde1uy6iKwISQQhVAemE0EIJoaWRNjPn/ePMZUpmkoBJhpk8388nn8zcuXPvmTuTJ88895xzldYaIYQQsc8W7QYIIYSoHxLQhRAiTkhAF0KIOCEBXQgh4oQEdCGEiBOOaO04PT1dd+vWLVq7F0KImLRs2bK9Wus24R6rNaArpd4GLgL2aK37hXlcAS8BFwCHgBu11j/Wtt1u3bqxdOnS2lYTQggRQCm1NdJjdSm5vAOcX8PjY4Bevp9JwGtH0jghhBD1o9aArrWeC+yvYZVxwD+0sRBIVUp1qK8GCiGEqJv6OCmaAWwPuJ/nW1aNUmqSUmqpUmppQUFBPexaCCGEpVF7uWitp2qtM7XWmW3ahK3pCyGEOEr1EdB3AJ0D7nfyLRNCCNGI6iOgTwMmKmMYUKi13lUP2xVCCHEE6tJt8QNgJJCulMoDfgs4AbTWrwNfY7os5mC6Ld7UUI0VQohjXnY2ZGXByJEwfHij7rrWgK61vrqWxzVwd721SAghYlV2NowaBVVVkJAAs2c3alCXof9CiPiTnQ1PP21+N6asLKioAK8XKivN/UYUtaH/QohGEMWv/1GTnQ1nnw3l5ZCYePRZ8tEcu759/bftdkhLM/9YGun4S0AXIl4tWGACicfzy7/+1xbcGvMfh7WvtDTYt6/6PrOyTDDX2mTLWVlH3qbsbDjrLPP8wH8KkV6ntby83Nx3OKBTJ7jrLpOt/5J/LEdAAroQjaWxs+V//9vUcsH/9f9oM9XAuvCLLwYH0vr8x1HXtlRUmPs2W/V9jhxplns85n5NWXKk9+T11/3BubIS/vEPeOstePddE6ADj0NaGtx7L7jdoBSkpMC4cfDPf/q3d7T/WI6QBHQhGsO8eSbj0xpcrsY5WZac7L/tcpmgdSSsYLdtmz+AVlRUzzo/+MD/j6O83AQ/qJ5Fg/+xiRP961jBNDs7+PFwGfC8ef62QHCt2lp/+HBo2xZ27zaP33WXCe5JSaa9Vjtyc/33XS5/gE5NhffeCz4Wb79t9mOpqIA77zS3bTYTzC3p6dCxY/DzlfL/Y4n0zaI+aK2j8jNkyBAtRMxbsEDrp54yv2tyySVam3Cutd1untMQ+wl0111mfzab1nPm1G2b1rIpU7R2ucxzXa7gtoe+jptv9i8DrZ3O4OcoZe4HPtfp1DohwTyWmKj1X/4S/HhCgr9dCxaY+4H7CPxJSjLttV7Lrl1m+VVXBa+nlGmrzVZ9Gzab+VHK/AQ+1qFD9WU1/Tgcpj1JSf59tW4d/PqUMo8fyfvpAyzVEeKqZOii6fqlJZDsbDjzzNpLDVlZMGOG/35N2XK4NmVnm/tud/iSR03tS0gw2aTLFfzY1Kn+zNXlgptvhkGD4J57TLatlAk9EJx9duoEW32zt3q9JnufOxfatzcZsbW+9Vwwt6uqgpdZGT2YrP7RR/0lEjBtnjzZ/Lz8cnBWDqZ9w4aZ13jzzXD33f5SyBNPmHVatap+TNatM+uFCrfM5usEmJRk2q6UOdEZeDwC22O9Pq3N+zN7tnkvly+Hjz8OXl/rX1YGiyRSpG/oH8nQRVhHk4ke7X5crl+UKenHH6896/7b34IzwubNI+9rwQKT3dlswW364x+DM0m7vfZ2Fxeb9W67zTzvueeC9xMuS3U4wmec1r7GjfOv16tX8DqjRpl1ImWtofuzMuKaMt3QbweBy5OStP7+e62bNav+baBnT/PaX33VnyVbx61Ll+BtBWbNoa/53HODs/wJE7S+4w5/uwOzdpvNfOuw26u/L4Gfk9DXIBm6iFtz5sA555iPfEOfXMvK8tdErZNeNfWcCKe01H/b4aiedc+ebTJHK3NTCkpKoFev8Nt76y1/9heYvfXs6V8nsF4buE5oZv/OOybjPfFE6NAB/v53OPVU89jXX4fPSEMzT6VMnbysDLp0MccGzHY3bw5ed948ePVV+Ogj+O47/zG56y545RWzv169THfCL78EpxP274fmzWHXLnOMbDbIzDSva/ly85zATF4pc7Jx6FD/sa6oCM7stYacHHP7N7/xf5tp0cJ8+9i2Da691py4tEydavallPkB8/mbPBny8sxrstngllvMeYl33zVttNvN+m53cA0+9LMzZgw895xpq80GDzxg6vRSQxcxqa5Z9w031J7x1pfPPvPvy+k0P0dS35w/X+v27bVu08Y859Zbq68zfnz4bHDGjPDba9vWv25gDfmdd/zLr7kmeJ0pU7S+9FJ//dfh0Pqhh/zZtlUHt27fcYfWkyb5X6fdHpyZt2pljoWVQVq1f2vbkTJsm828X3/8oz9ztdvN/qzX7XKZ1/T00/7nPf642U9gZmt9Uwl8P8Jlvk89FT5bDvcZmjvXvzxwOwsWBO8/sBavtdZffFH9eYGf57p+tuvxmyc1ZOgS0EXDilRGCOfGG8P/0UXa7i/5A3nhBX8gGDCg5mAQur/Ak3ROp9Y9epgTZ6HB4MQTzfZtNnMMrH0+/XT112KVDex2s37v3v7t3H671snJ5vGuXf3tPuus4H9E4cob4U7y2e1mf08+afYxZYp/Hacz+HU89ljwdgPLCg89FBz8rWMTGCADSxTWMV20yL/N//wn/Hv50kvB/3DvuKP6ex24L5fLvCfWvkI/b089FfyPJtJ7G6qm50VJTQFdSi5NWWP0i/7ss/AlgnD7374dmjWDQ4fMCa9I7U1Lg/vuM19hra5ode1fbHn3XWjXzpzMy801ywJPbDmdwd3MrBOIDgdcdJH/JJ3HA1u2mK/st99ulrlcMGKEOQF31VUwYIC/Hc8+C++/b06mWu3661/95R8rjK1da7o5fvedeS0jRpiv/2vWmPLHSSfBt98GlyQsVjnFZjPtVcps33ptHo8p4zz2mLmfleV/7V6vKRs88oh/e88/b54frqwwfnz142ydDLTKIlaJwjoZHNj9b8IEs37g/sCUs2w20x6v17zm0Pdx+PDq+4pUNhs50pSPAtsRuJ1In/+anncsihTpG/pHMvQoO5LM+ZeYODHyV12n01/emDfPnDC85BJ/RhS6vpXFhn71D82arNcWqXTy1Vf+7NXalt1uurQ99ZS537lz8Mm0SCfOrGMY7vHQ0smCBcHlh/HjTZYdmj0Hbm/wYPP7llu0vugic/vCC7V+5JHqzwttp9V9bsECk+EGZvNXXBF8vELLHqHH85d8Gwp9fl2y3traVB/taOjnNRCk5CKqefLJ4GDQEP2i587VOiXFv59Zs/yPWYHT2v+995rbV14Z/o/90kuDg3jg7dBSh9X/OnQbVpuHDw8OytZvq4ZaW++LwID50EPB/Y1DyxtK+fcfWPON9A9i/HizvXBlksC6+M03B7fdKkmcfXbk9zWwtBL4j6au72d9qWuwPsYC6bGipoAuJZemqlMn/+26fJUMLGGA/6tzYMkjcJ3ly02vAq/X9AbweEy/YGudhAT/tm028xUZoH9/mDbN9E1Wymzru+/g88+rtyk1FQ4eNCP2rJGLL70E//mPfx2rdHL22aYXjVL+Hg02m7+Xgtbm9Xz2WfjXb63r9fpLF1qbNlhf+9PS4KefTG8VqxQSeGxHjjSv25pnJJDVo+Shh8zP5MmmpGLxePw9MKy+44GlAGtk5ZNPmqH44UoE+/b5Sytud/XRlY01eVdoqSTSfhuzTfEiUqRv6B/J0KPszTf9mdzMmTWvO326v/xgnegKzQJnzAg+IRXuJN1vf+svhQSeVGzdOrjMMmWK1n37mhLMk09qPXRo+Iz2xRfDZ7mB+7zuuvAlk4ED/SMiQ3s5WPdDR0XecYf5SUioObu0ShyRTuSFlj/CnfQLLDFZ64TuN1IGW9Py+i5jiEaHZOhNSG0z0Vl+/NF/OzW15m2+/LL/RFtlJRQV+R+z2aB1a7juOv86oX2crRF3M2YEnyAF07f39df961ZUmHbffDM8+CA8/rhZbmXUNpvJflu2NCcOQwVmvikpMGtWcD9ly9q1/mNz0knB2aJ1Py0N7r+/ehY8cWLN2WVNmaX12MSJkectsdbLyqp57hNrvbruv66ZsYhdkSJ9Q/80uQy9MeqB1onGwGw1NBOz2tG3r+lqB1q/917kvrUej9YZGf5tJiVpff/9/qzxlFPCd50LPTHXq1fwfBxKmf3/7nfB6zudZr9/+EPwcitDDqy9B3ZVC/1WYLUt0knDup43kDquOMYgGXqUWXN+VFVF7mZXH6ZPD+7GpnVwV8FvvzWj1qywdtll8MUXJou98UaTWTudJqP1eMztoUNhxw4z2nDXLjMl6yOPmNns+vc3r83aZ+BIO4fDZNlW9jl9OmzcaOroRUVm+6eeakaG/ulP/lF0r7ziPzYOhz+j19p0XQN/dzaPB267zT+K8f77/dv59a9NFzswNfzbbjNzlQRm3HXpgiZ1XBFDJKA3hqwsf9Crj3mRI/WxXrjQ/A6dKCgtDebPDy6LABw4AMcdZ0ohVlkicBKlqirzPIC9e83vf//bnPhTCr7/3v+6rHmpIw1/toZajxwJe/aY7aanRy4DDB9uhpLfc49/8isrACckVC+DQHDpJCsruNTSpQtMmlS9vCJEPImUujf0T5MquSxYENwN7YILzPDro/ka/8EH/pN+geWU6dODyxzXXuvfZ+jUpYEli9NOq16qiNSlLnQbgWUOq7QS6fVb23U6/d3vQrvORXpupCleaxtJKicARRxCSi5RNniw+W2VLb7+2tx/913Tlc666ktWlrkaS02Z4xtvmN+hE/u/8op/Ha2hoMCfqQeOzAvM3j0eM1kUmGx5715TYpk/H668MviKNw5HcMZrnaAMDPFW18NQWVn+bwaBE0CFdp0LJ1zJoy5lEDkBKJogCeiNISfHBLzTT4dPPvEHVKv84vWax6D2aw9u2xZ8Py3NbG/VKn9faZfL1Mfnzave59nh8M/YZ7eb54GpazscJpi3amWuQrNokb+XBZhZ6cA8f/Ros4+61KRHjjSPh5uhriGHUkv9WzQxEtAbw7p15veYMeYkZGDGvH49LF7sD7o1TXq/ebP553DJJSZ79nhMQN2wwczzcdNNZorSwO53kyfDzJlm+0qZboJWt7tt2/wZv8cDGRlm2bBhJmgHBsTs7OA5OSZPDt/lL5xIc25I5ixE/YpUi2nonyZVQ7e64JWU+AeWWHN4hNamrSlGLd9/758V7777zDpXXx1+CHmkeTgi1ZJDHzvnHLOdcFPBWutLFz4hoooaauhKB34db0SZmZl66dKlUdl3vcnONkPSk5NNKWH06PAZ5/XXm8t0WZfuAjOL3//9n/9+RgYUFpreIJMmme01b24G12htsmKrB4rLZbLt0Mty2Wzwhz9Un7muppkHAwci3XuvycATEvy1fSHEMUUptUxrnRnuMSm5HK3sbHMCMzCoPv10+Pr3unXmyjGBrGk5y8vN/T59TGAtKYHf/a76/gLLNFb/69zc4Pk+7PbwNem6jFx8+mn/Sc+6nKwUQhxzbNFuQMwKvISZpazM1Jazs81JxUsugUsvhZUrobjYLLcMH24mkrKGxc+ZE36Ieii73d//evJkM1DJmvc6cFDOkbJOXFrbP9bnfRZCVCMZ+pH46itYsgTOO88EPJutehCeOTN8sF+40Mz4F5jBW7PfgX9WQut2IKurocMBt94aPJimvrrmSTc/IWKeBPS6mj8fLr7Y3H7mGRP8+vc3QfnRR+Ff/zIjJ7UOfxUZqz94YCkjsDtf4NVgDh6EF14w/yysYe7Wqc/QK7fUZ9c86eYnREyTgF5X//xn9a6FO3fChReak5j9+pnLhFmzAoZm7jZb+EtfRcqKrUt7hc74J6UQIUQEEtDryhpRCSawDh4M+fn+k52nnmr6gCsFvXubmvg115jHBg2KPJVtTVOdhpujRDJoIUQEEtBrYw2o+fJLf/njzTfNfNwQ3Htl4EBzpZ7iYtNr5bXX6qcNUgoRQtSBBPSaBE57C/4eKXa7f/RnYEDv2dOM4CwtNVdsF0KIRlSnbotKqfOVUuuVUjlKqYfDPN5FKTVHKfWTUmqlUuqC+m9qI8jONv2xre6F//1v9fnFlYKffza1b5sNdu/2P96rl+nDvXOnuS2EEI2o1gxdKWUHXgXOAfKAJUqpaVrrNQGrPQZ8rLV+TSnVB/ga6NYA7W042dkmq7ZGSs6ebTLtQC4XtG9vRn3On2/KL+ed5++K2LOnf93A20II0QjqkqEPBXK01rla60rgQ2BcyDoaaOG73RLYWX9NbCRZWWbUpzUt7bvvmq6IXbrAHXeYnzlzzAUhsrODr7GZlWVuB2blkqELIRpZXWroGcD2gPt5wCkh60wGvlVK3QskA6PDbUgpNQmYBNDFupzYsSK0O+Dbb5tyi9PpH8iTnW2yc2tO79CuiO3amZGbZWWwf39jtl4IIept6P/VwDta607ABcB7Sqlq29ZaT9VaZ2qtM9u0aVNPu66j0Pp4qM6d/f3MO3Xy1869Xn8GHnihBqXMZFyBIz8XLvTPzXLJJZH3JYQQDaAuAX0H0DngfiffskC3AB8DaK2zgUQgvT4aWC+sibQee8xk03feWT3Yzp5tfo8aBdt9X0isi0VYGfjIkaa+brebibWsOcEtVuCH4FKMEEI0groE9CVAL6VUd6WUC5gATAtZZxtwNoBSqjcmoBfUZ0N/kZkzg+vjU6aYeVUCg/qHH0KzZmYQkJWF2+1mOH7ghYtnz4Ynnww/q6I1g6JMcCWEiIJaa+haa7dS6h5gBmAH3tZar1ZK/R4z0fo04EHgDaXUrzEnSG/U0ZpoPZyVK4Pvh86rMn8+zJhhlr/8cvB6odfJrG0qWpngSggRJfF/gYtZs+Ccc8xtu90Eaa/XzFz4wAPmWppffgk7fFUkm82s5/WaLLum63sKIUQja9oXuJgyJfj+uefCN9+YnirPPBP8mM1mauTWrIeSZQshYkj8BfTQy63t2eOfAdHlgm7d/POLhxo9uvqJTiGEiBHxFdCzs00gd7tNpm1dkOKSSyAz03+S8t13/SdJLQkJEsyFEDEtvgJ64JWCKitNSaWszEywdd99/vWsE5dpafDTT2ZZ4FWAhBAiBsXXSdHsbDMvOZjyitttsvCkJDm5KYSICzWdFI2vi0QPH276gdtscNNN4edbEUKIOBVfAd3tNkPvvV4YM8YsCx3tKYQQcSq+AnpRkf92RYX5PXaslFuEEE1CfAX0wkL/7VmzzO9775VgLoRoEuI3oFuTbcmFJoQQTUT8BvTcXNO3vHPnyOsLIUQcic+A7vB1r+/Rw39hZyGEiHPxFe2sk6InnGB+y2XghBBNSHwFdCtD79/f/Jb6uRCiCYnPgN6ypfltt0evLUII0cjiL6A7HOYCz2AuViHX9RRCNBHxF9ATEsDjMffdbhnyL4RoMuIvoKemmqH+cl1PIUQTE1/T5xYVQfv28Mkncl1PIUSTE18BvbDQnBCt6ULOQggRp+Kv5GL1cBFCiCYm/gJ6ixbRboUQQkRF/AV0ydCFEE1U/AR0rxeKiyWgCyGarPgJ6MXFoLUEdCFEkxU/Ad2amEsCuhCiiYqfgB46j4sQQjQx8RPQ5883v3fsiG47hBAiSuIjoGdnw333mdsPPywTcgkhmqT4COhZWWYiLpAJuYQQTVZ8BPSRI/1zn8uEXEKIJio+Avrw4XDZZWYu9FmzZB4XIUSTFB8BHUAp6NIFTj012i0RQoioqFNAV0qdr5Rar5TKUUo9HGGdK5VSa5RSq5VS/6rfZtbBrl3QoUOj71YIIY4VtU6fq5SyA68C5wB5wBKl1DSt9ZqAdXoBjwAjtNYHlFJtG6rBEe3aBSed1Oi7FUKIY0VdMvShQI7WOldrXQl8CIwLWec24FWt9QEArfWe+m1mHUiGLoRo4uoS0DOA7QH383zLAh0PHK+Umq+UWqiUOj/chpRSk5RSS5VSSwsKCo6qwXuKylm2dT9er/YvPHTIDP2XgC6EaMLq66SoA+gFjASuBt5QSqWGrqS1nqq1ztRaZ7Zp0+aodvT5Tzu47LVsKtxe/8Jdu8xvCehCiCasLgF9B9A54H4n37JAecA0rXWV1nozsAET4OtdgsM0ucLt8S+UgC6EEHUK6EuAXkqp7kopFzABmBayzheY7BylVDqmBJNbj+08LMFhBhCFzdA7dmyIXQohREyoNaBrrd3APcAMYC3wsdZ6tVLq90qpsb7VZgD7lFJrgDnA/2it9zVEg11Whl4VENB37jS/JUMXQjRhtXZbBNBafw18HbLsiYDbGnjA99OgIpZcnE5IS2vo3QshxDEr5kaK+gN6SMmlfXszWlQIIZqo2AvozjA19LVrzeXnZNpcIUQTFnsBPbTkkp0NS5dCXh6cfbYEdSFEkxXDAd2Xoc+ZY7JzgMpKmQtdCNFkxWBA95VcrF4uvXzd3W02mQtdCNGk1amXy7HE6rbYbNli+HK1/0To7bfD9dfLXOhCiCYr5gJ6yk9LeHHaM5z+zA+gMJk5wDPPQPPmUW2bEEJEU2wF9Oxs2l58HuOqqlAAGlM/b9VKgrkQosmLrRp6VhZ4PChMLAdMQO/XL3ptEkKIY0RsBfSRIyEhAbey4XEEfLk444yoNUkIIY4VsRXQhw+HWbP4y+nX8emz70Fn3ySQCQnRbZcQQhwDYiugA+rUU3nz9AlUerV/lsWnnpIBRUKIJi/mAjpAgt1GxvJF/gFFVVUyoEgI0eTFZkB32tjQJ9MMJLLbZUCREEIQa90WfRIcdjYddxLMnm0y85EjZUCREKLJi9GAbjNzuQwfLoFcCCF8YrLk4nLYqKjy1L6iEEI0ITEZ0BOc9uD50IUQQsRoQHfYgi9BJ4QQIpYDumToQggRKHYDepUEdCGECBSjAd1OpUcCuhBCBIrRgC41dCGECBWbAd0pJRchhAgVmwHdId0WhRAiVIwGdCm5CCFEqJgM6C5ft0Wtde0rCyFEExGTAT3BYUNrcHsloAshhCVGA7odQOroQggRIDYDutM0WyboEkIIv9gM6A5fQJcMXQghDovRgC4lFyGECBWjAd3K0KXkIoQQljoFdKXU+Uqp9UqpHKXUwzWsd5lSSiulMuuvidW5rIAuo0WFEOKwWgO6UsoOvAqMAfoAVyul+oRZLwX4FbCovhsZyiq5yARdQgjhV5cMfSiQo7XO1VpXAh8C48Ks9yTwZ6C8HtsXlr+XiwR0IYSw1CWgZwDbA+7n+ZYdppQaDHTWWn9V04aUUpOUUkuVUksLCgqOuLEWqaELIUR1v/ikqFLKBvwFeLC2dbXWU7XWmVrrzDZt2hz1PqWXixBCVFeXgL4D6Bxwv5NvmSUF6AdkKaW2AMOAaQ15YlQydCGEqK4uAX0J0Esp1V0p5QImANOsB7XWhVrrdK11N611N2AhMFZrvbRBWozU0IUQIpxaA7rW2g3cA8wA1gIfa61XK6V+r5Qa29ANDMdlN82WXi5CCOHnqMtKWuuvga9Dlj0RYd2Rv7xZNUtw+mrokqELIcRhMlJUCCHiREwGdIdNYVPSy0UIIQLFZEBXSsl1RYUQIkRMBnSAJJed0gp3tJshhBDHjJgN6G1TEsgvqoh2M4QQ4pgRswG9XYtE8osafNoYIYSIGTEb0NtLQBdCiCAxG9DbtUxkb0kFbhlcJIQQQAwH9PYtEvFqKCiROroQQkAMB/R2LRIA2F0oZRchhICYDuiJAFJHF0IIn5gN6O1bmoAuGboQQhgxG9BbN3PhtCt2S190IYQAYjig22yKtinSdVEIISwxG9DBlF2k5CKEEEZsB3QZXCSEEIfFdEBv1yKR3UXlaK2j3RQhhIi6GA/oCRyq9FAssy4KIURsB/Tu6ckAbMwviXJLhBAi+mI6oJ/UqSUAq3cWRrklQggRfTEd0Nu3SCQt2cXPeRLQhRAipgO6Uop+GS35eYcEdCGEiOmADtAvowUb95RQXuWJdlOEECKqYj6gn5TREo9Xs253cbSbIoQQURXzAb1fhjkxKmUXIURTF/MBPSM1iVbNnCzI2RvtpgghRFTFfEBXSnH10C78d9Vulm8/GO3mCCFE1MR8QAe4a1RP0psn8OT0NTINgBCiyYqLgN48wcGvzu7Jsq0H5OSoEKLJiouADpDZrTUAmwpkGgAhRNMUNwG9W5qZ1yW3oDTKLRFCiOiIm4Ce5LKTkZpErmToQogmKm4COkCPNsnk7pUMXQjRNMVVQO+enszmglLp6SKEaJLqFNCVUucrpdYrpXKUUg+HefwBpdQapdRKpdRspVTX+m9q7XqkJ1Nc4aagpCIauxdCiKiqNaArpezAq8AYoA9wtVKqT8hqPwGZWuv+wKfAM/Xd0Lro0aY5AJv2lLIy76Bk6kKIJqUuGfpQIEdrnau1rgQ+BMYFrqC1nqO1PuS7uxDoVL/NrBvrCkaP/2cVY1+Zz+LN+6PRDCGEiIq6BPQMYHvA/TzfskhuAf4b7gGl1CSl1FKl1NKCgoK6t7KOMlKTcDls5OwxPV3mbqz/fQghxLHKUZ8bU0pdB2QCZ4Z7XGs9FZgKkJmZWe/1EJtN0bt9CqWVHhIcNhZs2lffuxBCiGNWXQL6DqBzwP1OvmVBlFKjgUeBM7XWUTsr+cYNmSTY7bwxL5fXvt9EcXkVKYnOaDVHCCEaTV1KLkuAXkqp7kopFzABmBa4glJqEDAFGKu13lP/zay7timJtGzm5NSeaXi8mkW5UkcXQjQNtQZ0rbUbuAeYAawFPtZar1ZK/V4pNda32rNAc+ATpdRypdS0CJtrNIO7tJKyixCiSalTDV1r/TXwdciyJwJuj67ndv1iiU47I3qm8+my7dx6enc6piZR5fHyj+yt5OwpoWfb5txyWvdoN1MIIepNXI0UDfXERX1wezW//mg5Hq9m6txcnpy+hi9X7OTJ6WtYlCvZuxAifvPJRgEAABhuSURBVMR1QO+WnszksX1ZtHk/V7+xkJdmb+TCkzqw5NHRZKQm8fh/VvHDxr2s2VkU7aYKIcQvFtcBHeDKzM78+bKTWJl3kCSnnclj+5LksvPbi/uwIb+E695axEV/ncf0lTsPP2fHwTKqPN4otloIIY6citbw+MzMTL106dJG29/2/Yeo8ngPTw+gteb7DQU4bDZenr2RZdsOMLRba/aXVrI+v5jRvdsx5foh2G2q0doohBC1UUot01pnhnss7jN0S+fWzQ4HczAXlx55QltO65XO2zedzGWDM6jyeElr7uKqzM7MWpvPn/67NootFkKII1OvI0VjVfMEB89cPiBoWYLTxhvzNpPazMXdo3oCJqv/1+JtfP7jDob3SGPi8K60bZEYjSYLIUQ1EtAj+O3FfSkqq+LZGetJcNi4blhX7n7/R2av20O3tGb8LSuHuRsL+M/dI1BKyjJCiOiTgB6B3aZ47ooBVHk0f/hqLR8v3c6G/BKeuKgPN43oxodLtvPI5z/zQ85eftp2ELdXc//ZvbDZFIcq3UxfsYvzT2pPC5l2QAjRSCSg18Bht/HihIFUerzMXJPPHy/px7WnmGt3XDo4gxdnbeC+D37iwKEqALbtK2VYjzSmzs0ld28ps9bmM+X6IUeUwR+qdNPMJW+LEOLINZmTokfLabfx2rWDmfObkYeDOUCCw85tp/fgwKEqLhmUwf2je/HF8p08/PnPlFV5uHpoF75dk89r32/C443ck6jS7WX7fjOV/KfL8ug/+Vs+W5YXtE55lYf1u4vlgh1CiBpJKlgHDrvt8MUzAt1waje6pSVz5gltcNptXDbYXNejXYtEnHZFQXEFz3yzng8Wb+NPl/ZnRM90AHYXlrNs6wEGdG7Jrz5czortB/nm/jN4Z8Fm3F7Ng5+sYOu+Uq45pSsvztrAf5bvpKzKw6gT2vDny/vTNkVOxAohqmsy/dCjwe3x8u2afP4ycwNb95UyeWxfBndpxa3vLmXHwTIAXHYbSsGJ7VNYkVfIYxf2Zs3OIj7/ycxQ7LAprsjsRIeWSbw6J4e0ZBfv3zaM7unJ7DhYxu3vLeXM49tw+5nHSb1eiCagpn7oEtAbQWFZFZP+sZRFvkvitWrmZPLYvvycV8g5fdrx3bo9TJmbi8thY8n/jaZlMydzNxQwbcVObju9Bye0TwFg1Y5CJr69GIdN8f6tp/DS7I18s2o3bq+mVTMn95zVi4nDu+K0B1fSVu0oJHdvKR1bJpLZrXWjv34hRP2RgH4McHu8LN6yn5+2HeS8vu3p2dY/yGlvSQVnPjOHc/u254WrBta4nQ35xVz75iIqqjwUlbu57+xenNO7HX/6Zi3zc/YxfmBHXrhq4OETsdNX7uTeD37Cepv/ftPJDOuexua9pfTp2CJo26t3FvKn/67jj+NPoktas/o9AEKIeiEBPQZs3VdK62RXna6ulFtQwrVvLkIBsx48k2YuB1prXvkuh+dnbuD8vu1plmCnvMrDzDX5DOrciifH9/P1yKmkVTMX6/OLmX7vaRyq9PDQpyv4zXkn8MLMDWwqKGV077a8ecPJFB6qosLtIbWZC5fDxp7icn7cepAEp40zerXBqzX3f7ScnQfL6Nq6GX+5ciC2CFMlHCit5MMl27n5tG4kOOz1fPSEaDokoMehovIqKt1e0psnHF6mteb309fwweJttG7mIsllp0eb5jx/5QBaJDpZvbOQ8a/Op3mCg/IqL2MHdGTr/lIWBlzVaUy/9vx31W5O75XOvI17AWiTksD1w7ry9vzNHPR10Zx0Rg+Ob5fCbz5ZQd+OLVi9s4hXrxnMhf07hG3v01+vZcrcXH5z7vHcc1avBjwyQsQ3CejisFU7CmmbksALszby6bLtVHk0D5xzPHuKy+naOpkbTu3G+S/NJe9AGROHdaVrejKfLN3OyrxC+nRoweSxffnnwq18s2o3bVskkJLo5Mt7RnDui3Nx2W2ceXwbPl2Wx6Aurbjx1G6c1iudQ5Vuhj01m9JKD067Yuavz6Rz6+CSzsw1+RyqdDNuYAZg/jnl7i2le1pyxKw/kNvjZcu+Q3RomUhygnTeEvFLArqoZvXOQi58+QdSEhwseOSsoFLP/tJK3F7v4e6R5tqs+xjctRWJTju7CssY9VwW5VVeXrlmEBf178hny/J48JMVAJzeK52cPSXsKizniiGdSE9J4LWsTbw0YSAPf2b66bdMcvLwmBOZcHJnlmw5wDVvLMRpt7H0sdEs2bKf3325hs17S7l5RHeeuLgPReVVNHc52F1Uzo1/X8wVQzpz2xk9APjipx08/PlKyqu8DOnaio8mDcNhlyEWIj7VFNAllWmi+nZsyVWZnendIaVa3b51sivovt2mONXXhx6gQ8skHjznBL5bt4cx/UyJZdzAjsxck09mt1bcclp3KtxeXpi5gbd+MH3r+2W0YOyAjnRq1YwfNu5lYe4+Hvn8Z/4+fzP5RRWkJDo4cKiKr37exUuzNuK0K87p086Uecoq+XLFTvp0bEl5pYcN+SX8+Zt1DD8ujUOVHv7n0xUM6JTK0O6t+VvWJl6avZEHzz0BgJw9JfwjewvJCQ7uGdWTKo8XpRQtk/yvecveUjqmJuFyVP8nsH53Md+u3s2kM3scrv3vOFhGSqJDuomKY45k6KJBHSitZNbafAZ0TuX4dimHl3u9mncWbOGHnL14vJpHL+zNTX9fQnF5FUXlbt6+MZMRPdO55NUFrNlVxOjebVmRV8iB0kpemjCI3325mtIKN4eqPHRPS+bfd42gZTMn//PJCj79MY/JvsnV/jJrA067jSqPl5ZJTorKqkh02rl7VE8mndGDn3cUctlrC+jZpjm/Gt2LSreXD5dsZ3dhOXeNPI7nvt3A3pIKzj6xLX+7bjA5e0q48vVsMlol8fldI2h+hOUdr1eTd6CMDqmJ1bqXBtJa88yM9ZRXebhuWFeOa9OcFdsPcuPfF/PBpGG0bubioc9W8vhFfTguYFporTXzc/YxqEtq2NJTflE5K33dZaPpwY9XkJLoYPLYvlFtRyySkouICX/+Zh2vZW3i+HbN+eZXZ2CzKfaVVLBl3yGGdG1FSYWbvcUVdEtPZsGmvUydm8uQLq248uTOtPNNY1xW6eHeD35i1tp8wHxzePyiPuQWlPL2D5s5vl1z1ucXM2N1PpcOyiB3byl5B8pw2RU7C8sByEhNIsllJ2dPCanNnFx3SldemZNDRmoSlR4vWmv2l1ZyWq82jDqhDYO6tOLE9in8+qPlrNpZyMDOrRjUOZXRvdsFdf/0eDW3vLuErPUFuOw2Jp3RgwfOOT7sOYJvVu3mjn8uA8zgsn/fNYK3fsjli+U7mXByZ1olu3gtaxOndG/Nh5OGHe6mOndDARPfXsy4gR15acIgwAT5PcUV7C4s545/LmNXYTmf3XkqQ7q2arg3swZllR4G/O5b3F4vsx8cGXYU9i+htY7rGVAloIuYkLOnmDEvzeO5KwYcPjl6NDxezd/m5NAiycnE4V3D/nH/dfZGnp+5AYBnL+/Phf07sH53MQkOO73aNcfj+wZxWs90+mW05Lt1+byzYCvrdhXx7s1DWZi7j99PX4PWoBT0SE8md28po05oy9pdRewqLCclwcE/bhnKoC4mcL40ayMvzNrArad1Z09xBdNW7OS4NsmUVLjxeKFL6ySev3IgrZu5OO/FubRKdvHWDZlc+PI8erZtzoq8QtCmBOZy2HA5bBQUV/DcFQO4fEgntNZc/no2P247gNbw/q2nMKJnOi/O2sCLszYCpsdSpdvLsB6tmXK9PyZY3xxCxx+UVrj5dFkelw7OoJnLwfSVOxl1YltaJDrxenXEE9Zer6a00h22G+78nL1c++YiAC4f0onnrhhQbR2AguIKCsuqgsZs1KbS7eWSv83n5G6tq2X/e4rK0XD4n7+lyuOl0u2NmZPpEtBFzCgsqwqqbzcUrTVPfb2WzXsPMfX6IXXqSRPqQGkllR4vL83eyEdLtvPUJf246uQugBkrcNM7S9hfUsmjF/ZmZ2E5L8/eyKWDMnj+ShPA3l+0jS9X7KRTq2YkOG18s2r34eyysKyKz+48lYGdU5ny/Sae/u86wPzz+Z9PVwLw0aRh/Ombdfy07SDn921P9zbJvJa1iccu7M17C7diU4pp94xg5LNZdE9PZvygDM7u3ZZ/LdrGK3NyGD8wg2VbD/DImBOZvnIXX/28i79dO5gLTjLnRSrdXm55dwnzNu7l+mFd6dEmmd99uYaLB3Tk9jN6cPXUhXRNb8bE4d24MrPz4eOyakchj32xig35xXx93+m0bu5i6Zb9jDqhLUopnpuxnte+38RlgzP47Mcd3DyiG5cP6Xx4RDTAtn2HuHJKNsXlVXz/0CgSfP+8Aq86Fs6rc3J4dsZ6XA4bCx85m+37D+H2emmR6OTKKdmkJDqZ9cCZQedLHvp0BfNz9jHj12cccQmtwPeP+bphXWocX5F34BAdWyYd1ecslAR0IRpYeZWHRGfwH/TOg2Xc+f6PrNh+EDDZ6B/G96u2nmXL3lJuf28ZbVsk8NB5J3JSp5aAKVGc+ewcMlol8e+7RnDF6wtwezWf33kqReVu3pqXyzsLtlBU7iYjNYnZD57J4s37mfj2YgZ0TmXF9oP84+ahnHF8G8AEodP+/B0er6ZjahLbfLN9tm+RSIXbw+/H9SNrfQEr8g6Ss6eEAZ1a8vOOQpKcdhx2G4VlVbRIdNDM5SCtuStoDMLSLfu55s1FtEh0UFbpYWj31pRXecnO3cfzVwzgsiGduOy1BXi8mrduyOR/P1vJ9xsK8Hg11w/rygPnnEBBSTk3vL2Ekgo3JRVuLh/ciZ93FJKzp4RP7xxO/06pACzdsp/Csio8Xs3aXcWUVFTx3sKtnNi+Bcu3H+SywZ346uedlFd5SXDYcNptlFS4eXJcXzbkl3Co0sMTF/Xh5KdmUen2ctvp3Xn0wj5B78manUV8uiyPc/q0Y/hxadXe86umLmTF9oM8dP4J3HHGceQUlASdKwJYtvUAl7++gPEDM3juigG/+DrFEtCFiBKtNXM37qWk3M0FJ7U/6tru9v2HSHDYaNsikZIKN0BQNqm1pqCkggSH/fA3nHv+9SPTV+6iR3oysx44Myg7XLWjkBaJTtq1TOD1rFyOa5vMie1TuODlH6h0e2nVzEnfji0ZO7Aj5/Vpz6jnsygpd/PVfadx/0fL2VRQwmd3nkqvtilcNTWbjfkl3HZ6D95ZYC7b+Okdw/nsxzye+tp8s+jYMpFDVR6m3X0aZz2fxW1n9OB/zz8RMN90Xpy1gfcWbiW1mYsqtxeXw8Y7Nw3lX4u38cHibdiU6X2V6LTz4LnH89XK3YfPk4ApeyU67LRvmcj7t57Cgx+vIDt3H21TErjltO5krS/giYv78NgXq/hp2wGsGa3POrEt363bw9BurVm27QBd05qRkujkzYmZvPXDZl7/fhMAiU7TnmE90iitcDNv417eX7SVeRv3cny75uQdKGNEz3Rmrsln6vVDOLdv+8Pftm5/bynfrdtDlUczuEsqHVKTmHByZ07v1eaoPgsS0IVogvYUlXPRX3/gwXOPP1wKqs2CTXspLndz1oltg3rhLN9+kIOHKhl5QlsKy6o4UFpJN9/JzB0Hy7hqSrbpvdMykQ9uG0a39GQq3V5uemcxmV1bc1H/Dlz48g9UerwAQd8YLGt2FvH76aupcHt55ZrBZKQmkV9UztVvLOSW07rTp0MLrpqykEqPlySnnV+N7sXwHml4tOaEdilBNfB5Gwu4/8PlvHbdEIZ2909ItzB3H9e9uYi7R/Vk+sqdbCoopW/HFrx3yync/M4SWjVzkp27j5ZJTvKLKrgysxO3n3kct7+3jJw9JXRunUR+UQWVbi8tEh3cP/p4zu7dlnP+MpdKj5eUBAe9O7Tgf8ecwO3vLePiAR15Z8EW7hnVk5ZJTj5dlkelx8v9o49n7ICOR/W+SkAXoolqrB4fWmvcXo1NqYglhUW5+5i/aR8KuOesnjV224ykoLiC4vIq2rZIrLXeHemkbWmFm+QEB3PW7eGmd5bw5Ph+XD/Mf/Ga2WvzmfTeMs46sS2vXzcEu02xt6SCDxdvY+2uYtq3TGR073Zkdmt1+DXMWL0bl93GpoIS/vDVWtKbuyipcFNe5cVltzH/4bNok5JQrS1HQwK6EEKEsWZnESe2T6kW+HceLKNtSsIRjzguLq9i+NPfcajSzUe3D2fnwTK0hvGDjr7XVigZKSqEEGGETiFt6ZiadFTbS0l08uzl/an0eDk5CtcekIAuhBD1aMxJ4WccbQwyg5EQQsQJCehCCBEnJKALIUScqFNAV0qdr5Rar5TKUUo9HObxBKXUR77HFymlutV3Q4UQQtSs1oCulLIDrwJjgD7A1UqpPiGr3QIc0Fr3BF4A/lzfDRVCCFGzumToQ4EcrXWu1roS+BAYF7LOOOBd3+1PgbNVPM9fKYQQx6C6BPQMYHvA/TzfsrDraK3dQCGQFrIOSqlJSqmlSqmlBQUFR9diIYQQYTXqSVGt9VStdabWOrNNm6ObmEYIIUR4dRlYtAPoHHC/k29ZuHXylFIOoCWwr6aNLlu2bK9SausRtDVQOrD3KJ/b0I7Vtkm7joy068gdq22Lt3Z1jfRAXQL6EqCXUqo7JnBPAK4JWWcacAOQDVwOfKdrmSRGa33UKbpSammkuQyi7Vhtm7TryEi7jtyx2ram1K5aA7rW2q2UugeYAdiBt7XWq5VSvweWaq2nAW8B7ymlcoD9mKAvhBCiEdVpLhet9dfA1yHLngi4XQ5cUb9NE0IIcSRidaTo1Gg3oAbHatukXUdG2nXkjtW2NZl2RW0+dCGEEPUrVjN0IYQQISSgCyFEnIi5gF7bRGGN2I7OSqk5Sqk1SqnVSqlf+ZZPVkrtUEot9/1cEIW2bVFK/ezb/1LfstZKqZlKqY2+360auU0nBByT5UqpIqXU/dE6Xkqpt5VSe5RSqwKWhT1GynjZ95lbqZQa3MjtelYptc63738rpVJ9y7sppcoCjt3rjdyuiO+dUuoR3/Far5Q6r6HaVUPbPgpo1xal1HLf8kY5ZjXEh4b9jGmtY+YH021yE9ADcAErgD5RaksHYLDvdgqwATN52WTgN1E+TluA9JBlzwAP+24/DPw5yu/jbswAiagcL+AMYDCwqrZjBFwA/BdQwDBgUSO361zA4bv954B2dQtcLwrHK+x75/s7WAEkAN19f7P2xmxbyOPPA0805jGrIT406Gcs1jL0ukwU1ii01ru01j/6bhcDa6k+x82xJHACtXeB8VFsy9nAJq310Y4U/sW01nMxYyYCRTpG44B/aGMhkKqUapDrjIVrl9b6W23mSAJYiBmt3agiHK9IxgEfaq0rtNabgRzM326jt803SeCVwAcNtf8IbYoUHxr0MxZrAb0uE4U1OmXmfx8ELPItusf3tentxi5t+GjgW6XUMqXUJN+ydlrrXb7bu4F2UWiXZQLBf2DRPl6WSMfoWPrc3YzJ5CzdlVI/KaW+V0qdHoX2hHvvjqXjdTqQr7XeGLCsUY9ZSHxo0M9YrAX0Y45SqjnwGXC/1roIeA04DhgI7MJ83Wtsp2mtB2PmsL9bKXVG4IPafMeLSn9VpZQLGAt84lt0LByvaqJ5jCJRSj0KuIH3fYt2AV201oOAB4B/KaXCX8a+YRyT712IqwlOHhr1mIWJD4c1xGcs1gJ6XSYKazRKKSfmzXpfa/05gNY6X2vt0Vp7gTdowK+akWitd/h+7wH+7WtDvvUVzvd7T2O3y2cM8KPWOt/XxqgfrwCRjlHUP3dKqRuBi4BrfYEAX0ljn+/2Mkyt+vjGalMN713UjxeAMhMFXgp8ZC1rzGMWLj7QwJ+xWAvohycK82V6EzATgzU6X23uLWCt1vovAcsD616XAKtCn9vA7UpWSqVYtzEn1Fbhn0AN3+//NGa7AgRlTNE+XiEiHaNpwERfT4RhQGHA1+YGp5Q6H3gIGKu1PhSwvI0yVxRDKdUD6AXkNmK7Ir1304AJylyasruvXYsbq10BRgPrtNZ51oLGOmaR4gMN/Rlr6LO99f2DORu8AfOf9dEotuM0zNellcBy388FwHvAz77l04AOjdyuHpgeBiuA1dYxwlxwZDawEZgFtI7CMUvGTKvcMmBZVI4X5p/KLqAKU6+8JdIxwvQ8eNX3mfsZyGzkduVg6qvW5+x137qX+d7j5cCPwMWN3K6I7x3wqO94rQfGNPZ76Vv+DnBHyLqNcsxqiA8N+hmTof9CCBEnYq3kIoQQIgIJ6EIIESckoAshRJyQgC6EEHFCAroQQsQJCehCCBEnJKALIUSc+H9MNUgnkz9/MQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_32 (Dense)            (None, 10)                140       \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 30)                330       \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 30)                0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,751\n",
            "Trainable params: 1,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 31ms/step - loss: 0.3372 - accuracy: 0.5945 - val_loss: 0.2184 - val_accuracy: 0.6727\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2467 - accuracy: 0.6590 - val_loss: 0.1808 - val_accuracy: 0.7273\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2119 - accuracy: 0.7005 - val_loss: 0.1736 - val_accuracy: 0.7273\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1895 - accuracy: 0.7650 - val_loss: 0.1748 - val_accuracy: 0.7455\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1872 - accuracy: 0.7143 - val_loss: 0.1794 - val_accuracy: 0.7455\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1764 - accuracy: 0.7650 - val_loss: 0.1814 - val_accuracy: 0.7455\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1700 - accuracy: 0.7512 - val_loss: 0.1838 - val_accuracy: 0.7455\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1747 - accuracy: 0.7604 - val_loss: 0.1855 - val_accuracy: 0.7091\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1626 - accuracy: 0.7972 - val_loss: 0.1832 - val_accuracy: 0.7273\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1556 - accuracy: 0.7926 - val_loss: 0.1811 - val_accuracy: 0.7273\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1534 - accuracy: 0.7650 - val_loss: 0.1821 - val_accuracy: 0.7273\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1507 - accuracy: 0.7834 - val_loss: 0.1835 - val_accuracy: 0.7091\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1504 - accuracy: 0.8111 - val_loss: 0.1853 - val_accuracy: 0.7636\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1325 - accuracy: 0.8341 - val_loss: 0.1850 - val_accuracy: 0.7455\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1620 - accuracy: 0.7696 - val_loss: 0.1833 - val_accuracy: 0.7455\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1476 - accuracy: 0.7834 - val_loss: 0.1826 - val_accuracy: 0.7455\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1453 - accuracy: 0.8341 - val_loss: 0.1841 - val_accuracy: 0.7455\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1512 - accuracy: 0.8111 - val_loss: 0.1838 - val_accuracy: 0.7636\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1439 - accuracy: 0.8157 - val_loss: 0.1827 - val_accuracy: 0.7636\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 0.7742 - val_loss: 0.1829 - val_accuracy: 0.7455\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1419 - accuracy: 0.8018 - val_loss: 0.1821 - val_accuracy: 0.7818\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1446 - accuracy: 0.7972 - val_loss: 0.1822 - val_accuracy: 0.7818\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1475 - accuracy: 0.8065 - val_loss: 0.1814 - val_accuracy: 0.7273\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1334 - accuracy: 0.8341 - val_loss: 0.1805 - val_accuracy: 0.7636\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1354 - accuracy: 0.8341 - val_loss: 0.1827 - val_accuracy: 0.7818\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1354 - accuracy: 0.8479 - val_loss: 0.1798 - val_accuracy: 0.7636\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1268 - accuracy: 0.8387 - val_loss: 0.1768 - val_accuracy: 0.7636\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1197 - accuracy: 0.8433 - val_loss: 0.1754 - val_accuracy: 0.7818\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1177 - accuracy: 0.8479 - val_loss: 0.1762 - val_accuracy: 0.8000\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1241 - accuracy: 0.8387 - val_loss: 0.1793 - val_accuracy: 0.8000\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1199 - accuracy: 0.8387 - val_loss: 0.1804 - val_accuracy: 0.7818\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1257 - accuracy: 0.8387 - val_loss: 0.1811 - val_accuracy: 0.7636\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1199 - accuracy: 0.8479 - val_loss: 0.1805 - val_accuracy: 0.8000\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1249 - accuracy: 0.8525 - val_loss: 0.1799 - val_accuracy: 0.8000\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1164 - accuracy: 0.8756 - val_loss: 0.1815 - val_accuracy: 0.7636\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1138 - accuracy: 0.8848 - val_loss: 0.1805 - val_accuracy: 0.7818\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1206 - accuracy: 0.8618 - val_loss: 0.1823 - val_accuracy: 0.7636\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1391 - accuracy: 0.8157 - val_loss: 0.1845 - val_accuracy: 0.7636\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1144 - accuracy: 0.8433 - val_loss: 0.1832 - val_accuracy: 0.7818\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1187 - accuracy: 0.8525 - val_loss: 0.1829 - val_accuracy: 0.7818\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1248 - accuracy: 0.8664 - val_loss: 0.1824 - val_accuracy: 0.7818\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1176 - accuracy: 0.8756 - val_loss: 0.1846 - val_accuracy: 0.8182\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1121 - accuracy: 0.8664 - val_loss: 0.1843 - val_accuracy: 0.7818\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1219 - accuracy: 0.8571 - val_loss: 0.1818 - val_accuracy: 0.8000\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1252 - accuracy: 0.8571 - val_loss: 0.1815 - val_accuracy: 0.8182\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1169 - accuracy: 0.8802 - val_loss: 0.1831 - val_accuracy: 0.8000\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.8618 - val_loss: 0.1869 - val_accuracy: 0.7818\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1134 - accuracy: 0.8756 - val_loss: 0.1866 - val_accuracy: 0.7636\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.8525 - val_loss: 0.1829 - val_accuracy: 0.8000\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1150 - accuracy: 0.8479 - val_loss: 0.1813 - val_accuracy: 0.8000\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1117 - accuracy: 0.8571 - val_loss: 0.1815 - val_accuracy: 0.8000\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1041 - accuracy: 0.8710 - val_loss: 0.1798 - val_accuracy: 0.7818\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1023 - accuracy: 0.8940 - val_loss: 0.1813 - val_accuracy: 0.8000\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1040 - accuracy: 0.8571 - val_loss: 0.1826 - val_accuracy: 0.8000\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1122 - accuracy: 0.8571 - val_loss: 0.1831 - val_accuracy: 0.7818\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1112 - accuracy: 0.8710 - val_loss: 0.1829 - val_accuracy: 0.8000\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1115 - accuracy: 0.8387 - val_loss: 0.1828 - val_accuracy: 0.8000\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1082 - accuracy: 0.8756 - val_loss: 0.1827 - val_accuracy: 0.7818\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.8756 - val_loss: 0.1807 - val_accuracy: 0.7818\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1086 - accuracy: 0.8710 - val_loss: 0.1845 - val_accuracy: 0.7818\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1116 - accuracy: 0.8525 - val_loss: 0.1865 - val_accuracy: 0.7818\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1001 - accuracy: 0.8848 - val_loss: 0.1862 - val_accuracy: 0.7818\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1101 - accuracy: 0.8710 - val_loss: 0.1863 - val_accuracy: 0.7818\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1037 - accuracy: 0.8848 - val_loss: 0.1836 - val_accuracy: 0.7636\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1032 - accuracy: 0.8664 - val_loss: 0.1817 - val_accuracy: 0.8000\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1047 - accuracy: 0.8664 - val_loss: 0.1807 - val_accuracy: 0.8000\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0992 - accuracy: 0.8848 - val_loss: 0.1827 - val_accuracy: 0.8000\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0961 - accuracy: 0.8756 - val_loss: 0.1840 - val_accuracy: 0.7818\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1000 - accuracy: 0.8848 - val_loss: 0.1853 - val_accuracy: 0.7636\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0951 - accuracy: 0.8848 - val_loss: 0.1864 - val_accuracy: 0.7636\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1074 - accuracy: 0.8756 - val_loss: 0.1840 - val_accuracy: 0.7818\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0923 - accuracy: 0.9032 - val_loss: 0.1856 - val_accuracy: 0.7818\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0986 - accuracy: 0.8802 - val_loss: 0.1877 - val_accuracy: 0.8000\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0969 - accuracy: 0.8618 - val_loss: 0.1860 - val_accuracy: 0.8000\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0901 - accuracy: 0.9032 - val_loss: 0.1837 - val_accuracy: 0.7818\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0862 - accuracy: 0.8802 - val_loss: 0.1843 - val_accuracy: 0.7818\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9032 - val_loss: 0.1841 - val_accuracy: 0.7818\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1016 - accuracy: 0.8802 - val_loss: 0.1858 - val_accuracy: 0.7455\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1019 - accuracy: 0.8756 - val_loss: 0.1865 - val_accuracy: 0.7636\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0754 - accuracy: 0.9355 - val_loss: 0.1875 - val_accuracy: 0.7818\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0930 - accuracy: 0.8986 - val_loss: 0.1841 - val_accuracy: 0.7636\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0916 - accuracy: 0.8802 - val_loss: 0.1782 - val_accuracy: 0.7636\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0840 - accuracy: 0.9032 - val_loss: 0.1776 - val_accuracy: 0.7636\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0894 - accuracy: 0.8894 - val_loss: 0.1783 - val_accuracy: 0.7636\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0928 - accuracy: 0.8756 - val_loss: 0.1856 - val_accuracy: 0.7636\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0947 - accuracy: 0.8848 - val_loss: 0.1923 - val_accuracy: 0.7455\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0858 - accuracy: 0.8894 - val_loss: 0.1925 - val_accuracy: 0.7455\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0872 - accuracy: 0.9032 - val_loss: 0.1942 - val_accuracy: 0.7455\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1007 - accuracy: 0.8986 - val_loss: 0.1942 - val_accuracy: 0.7455\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0875 - accuracy: 0.9078 - val_loss: 0.1920 - val_accuracy: 0.7455\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0919 - accuracy: 0.9078 - val_loss: 0.1910 - val_accuracy: 0.7636\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.8940 - val_loss: 0.1909 - val_accuracy: 0.7636\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0856 - accuracy: 0.9124 - val_loss: 0.1906 - val_accuracy: 0.7636\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.8986 - val_loss: 0.1912 - val_accuracy: 0.7636\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.8986 - val_loss: 0.1903 - val_accuracy: 0.7455\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0912 - accuracy: 0.8848 - val_loss: 0.1920 - val_accuracy: 0.7636\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9171 - val_loss: 0.1908 - val_accuracy: 0.7818\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0873 - accuracy: 0.9032 - val_loss: 0.1866 - val_accuracy: 0.7636\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9217 - val_loss: 0.1898 - val_accuracy: 0.7636\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9032 - val_loss: 0.1915 - val_accuracy: 0.7636\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9171 - val_loss: 0.1928 - val_accuracy: 0.7636\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0760 - accuracy: 0.9078 - val_loss: 0.1962 - val_accuracy: 0.7636\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9124 - val_loss: 0.1991 - val_accuracy: 0.7636\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.8802 - val_loss: 0.1966 - val_accuracy: 0.7636\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9078 - val_loss: 0.1933 - val_accuracy: 0.7636\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9032 - val_loss: 0.1826 - val_accuracy: 0.7455\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.8940 - val_loss: 0.1820 - val_accuracy: 0.7636\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9078 - val_loss: 0.1873 - val_accuracy: 0.7636\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 0.9078 - val_loss: 0.1955 - val_accuracy: 0.7455\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0800 - accuracy: 0.8940 - val_loss: 0.2007 - val_accuracy: 0.7455\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0777 - accuracy: 0.9078 - val_loss: 0.2048 - val_accuracy: 0.7455\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0842 - accuracy: 0.9217 - val_loss: 0.2068 - val_accuracy: 0.7273\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0819 - accuracy: 0.9171 - val_loss: 0.2037 - val_accuracy: 0.7455\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0792 - accuracy: 0.9309 - val_loss: 0.2006 - val_accuracy: 0.7455\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9309 - val_loss: 0.1959 - val_accuracy: 0.7455\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0784 - accuracy: 0.9124 - val_loss: 0.1965 - val_accuracy: 0.7455\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0863 - accuracy: 0.9078 - val_loss: 0.2017 - val_accuracy: 0.7455\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9309 - val_loss: 0.2077 - val_accuracy: 0.7636\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9217 - val_loss: 0.2063 - val_accuracy: 0.7273\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0751 - accuracy: 0.9124 - val_loss: 0.2073 - val_accuracy: 0.7455\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9171 - val_loss: 0.2065 - val_accuracy: 0.7455\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9263 - val_loss: 0.2097 - val_accuracy: 0.7455\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0854 - accuracy: 0.8986 - val_loss: 0.2123 - val_accuracy: 0.7273\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0789 - accuracy: 0.9401 - val_loss: 0.2116 - val_accuracy: 0.7273\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0767 - accuracy: 0.8986 - val_loss: 0.2113 - val_accuracy: 0.7455\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.9355 - val_loss: 0.2049 - val_accuracy: 0.7455\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0741 - accuracy: 0.9355 - val_loss: 0.1996 - val_accuracy: 0.7455\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0743 - accuracy: 0.9217 - val_loss: 0.1979 - val_accuracy: 0.7455\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9124 - val_loss: 0.2033 - val_accuracy: 0.7455\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9171 - val_loss: 0.1989 - val_accuracy: 0.7455\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.8940 - val_loss: 0.1988 - val_accuracy: 0.7273\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9309 - val_loss: 0.2039 - val_accuracy: 0.7273\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0763 - accuracy: 0.9263 - val_loss: 0.2051 - val_accuracy: 0.7455\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9447 - val_loss: 0.2101 - val_accuracy: 0.7455\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.9263 - val_loss: 0.2106 - val_accuracy: 0.7091\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0837 - accuracy: 0.9124 - val_loss: 0.2104 - val_accuracy: 0.7091\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.9539 - val_loss: 0.2073 - val_accuracy: 0.7455\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.9309 - val_loss: 0.2074 - val_accuracy: 0.7455\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9171 - val_loss: 0.2096 - val_accuracy: 0.7455\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9263 - val_loss: 0.2102 - val_accuracy: 0.7455\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.9447 - val_loss: 0.2082 - val_accuracy: 0.7455\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0656 - accuracy: 0.9309 - val_loss: 0.2033 - val_accuracy: 0.7455\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9309 - val_loss: 0.2060 - val_accuracy: 0.7455\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0704 - accuracy: 0.9263 - val_loss: 0.2076 - val_accuracy: 0.7455\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.9355 - val_loss: 0.2093 - val_accuracy: 0.7455\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9401 - val_loss: 0.2048 - val_accuracy: 0.7455\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9078 - val_loss: 0.2056 - val_accuracy: 0.7818\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0717 - accuracy: 0.9263 - val_loss: 0.2058 - val_accuracy: 0.7091\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0567 - accuracy: 0.9539 - val_loss: 0.2083 - val_accuracy: 0.7273\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0679 - accuracy: 0.9263 - val_loss: 0.2108 - val_accuracy: 0.7455\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0555 - accuracy: 0.9493 - val_loss: 0.2155 - val_accuracy: 0.7455\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0675 - accuracy: 0.9447 - val_loss: 0.2130 - val_accuracy: 0.7455\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0696 - accuracy: 0.9309 - val_loss: 0.2111 - val_accuracy: 0.7273\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0679 - accuracy: 0.9355 - val_loss: 0.2144 - val_accuracy: 0.7091\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0817 - accuracy: 0.9124 - val_loss: 0.2155 - val_accuracy: 0.7091\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0642 - accuracy: 0.9401 - val_loss: 0.2110 - val_accuracy: 0.7273\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0669 - accuracy: 0.9263 - val_loss: 0.2079 - val_accuracy: 0.7455\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0678 - accuracy: 0.9309 - val_loss: 0.2062 - val_accuracy: 0.7455\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0648 - accuracy: 0.9401 - val_loss: 0.2097 - val_accuracy: 0.7273\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0733 - accuracy: 0.9217 - val_loss: 0.2146 - val_accuracy: 0.6909\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0593 - accuracy: 0.9447 - val_loss: 0.2156 - val_accuracy: 0.6909\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0696 - accuracy: 0.9263 - val_loss: 0.2154 - val_accuracy: 0.6909\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0535 - accuracy: 0.9493 - val_loss: 0.2165 - val_accuracy: 0.6909\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0652 - accuracy: 0.9401 - val_loss: 0.2179 - val_accuracy: 0.6909\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0716 - accuracy: 0.9124 - val_loss: 0.2109 - val_accuracy: 0.7091\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0809 - accuracy: 0.9124 - val_loss: 0.2081 - val_accuracy: 0.7273\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0608 - accuracy: 0.9539 - val_loss: 0.2131 - val_accuracy: 0.7091\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0614 - accuracy: 0.9355 - val_loss: 0.2140 - val_accuracy: 0.7091\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0779 - accuracy: 0.9263 - val_loss: 0.2127 - val_accuracy: 0.6909\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0632 - accuracy: 0.9309 - val_loss: 0.2101 - val_accuracy: 0.7091\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0651 - accuracy: 0.9401 - val_loss: 0.2099 - val_accuracy: 0.7091\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0655 - accuracy: 0.9401 - val_loss: 0.2137 - val_accuracy: 0.6909\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0603 - accuracy: 0.9401 - val_loss: 0.2081 - val_accuracy: 0.6909\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0672 - accuracy: 0.9401 - val_loss: 0.2033 - val_accuracy: 0.7455\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0621 - accuracy: 0.9493 - val_loss: 0.1987 - val_accuracy: 0.7455\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0536 - accuracy: 0.9493 - val_loss: 0.2068 - val_accuracy: 0.7455\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0535 - accuracy: 0.9631 - val_loss: 0.2106 - val_accuracy: 0.7455\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0547 - accuracy: 0.9493 - val_loss: 0.2124 - val_accuracy: 0.7273\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0535 - accuracy: 0.9493 - val_loss: 0.2129 - val_accuracy: 0.7273\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0595 - accuracy: 0.9401 - val_loss: 0.2147 - val_accuracy: 0.6909\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0609 - accuracy: 0.9401 - val_loss: 0.2123 - val_accuracy: 0.6909\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0542 - accuracy: 0.9585 - val_loss: 0.2122 - val_accuracy: 0.6909\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0600 - accuracy: 0.9539 - val_loss: 0.2183 - val_accuracy: 0.6909\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0649 - accuracy: 0.9447 - val_loss: 0.2119 - val_accuracy: 0.6909\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0546 - accuracy: 0.9355 - val_loss: 0.2088 - val_accuracy: 0.6909\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.9309 - val_loss: 0.2112 - val_accuracy: 0.7091\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9401 - val_loss: 0.2109 - val_accuracy: 0.7273\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.9355 - val_loss: 0.2128 - val_accuracy: 0.7455\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9585 - val_loss: 0.2139 - val_accuracy: 0.7091\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0537 - accuracy: 0.9447 - val_loss: 0.2152 - val_accuracy: 0.7091\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.9217 - val_loss: 0.2154 - val_accuracy: 0.7091\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9401 - val_loss: 0.2171 - val_accuracy: 0.7091\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9124 - val_loss: 0.2132 - val_accuracy: 0.7273\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0634 - accuracy: 0.9401 - val_loss: 0.2131 - val_accuracy: 0.7091\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0569 - accuracy: 0.9447 - val_loss: 0.2047 - val_accuracy: 0.7273\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0560 - accuracy: 0.9493 - val_loss: 0.2044 - val_accuracy: 0.7455\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9447 - val_loss: 0.2054 - val_accuracy: 0.7455\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0764 - accuracy: 0.9124 - val_loss: 0.2090 - val_accuracy: 0.7091\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0557 - accuracy: 0.9401 - val_loss: 0.2150 - val_accuracy: 0.7091\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0662 - accuracy: 0.9217 - val_loss: 0.2205 - val_accuracy: 0.6727\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9118\n",
            "accuracy: [0.07241566479206085, 0.9117646813392639]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 10)                140       \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 30)                330       \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 30)                0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,751\n",
            "Trainable params: 1,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 28ms/step - loss: 0.8548 - accuracy: 0.6452 - val_loss: 0.5174 - val_accuracy: 0.6000\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4314 - accuracy: 0.7051 - val_loss: 0.3578 - val_accuracy: 0.5818\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.6590 - val_loss: 0.3172 - val_accuracy: 0.6182\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2811 - accuracy: 0.6359 - val_loss: 0.2930 - val_accuracy: 0.6182\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2576 - accuracy: 0.6636 - val_loss: 0.2729 - val_accuracy: 0.6182\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2437 - accuracy: 0.6544 - val_loss: 0.2571 - val_accuracy: 0.6727\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2221 - accuracy: 0.6820 - val_loss: 0.2519 - val_accuracy: 0.6182\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2339 - accuracy: 0.7051 - val_loss: 0.2468 - val_accuracy: 0.6182\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2182 - accuracy: 0.7327 - val_loss: 0.2403 - val_accuracy: 0.6727\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1966 - accuracy: 0.7419 - val_loss: 0.2313 - val_accuracy: 0.7273\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1883 - accuracy: 0.7465 - val_loss: 0.2253 - val_accuracy: 0.6909\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2091 - accuracy: 0.7327 - val_loss: 0.2197 - val_accuracy: 0.7091\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2028 - accuracy: 0.7512 - val_loss: 0.2126 - val_accuracy: 0.7273\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1741 - accuracy: 0.7742 - val_loss: 0.2059 - val_accuracy: 0.7455\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1758 - accuracy: 0.7926 - val_loss: 0.1985 - val_accuracy: 0.7455\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1703 - accuracy: 0.7742 - val_loss: 0.1950 - val_accuracy: 0.7455\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1784 - accuracy: 0.7558 - val_loss: 0.1918 - val_accuracy: 0.7273\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1569 - accuracy: 0.7742 - val_loss: 0.1952 - val_accuracy: 0.7818\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1579 - accuracy: 0.8018 - val_loss: 0.1899 - val_accuracy: 0.7636\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1703 - accuracy: 0.7972 - val_loss: 0.1877 - val_accuracy: 0.7636\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1705 - accuracy: 0.7788 - val_loss: 0.1854 - val_accuracy: 0.7455\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1611 - accuracy: 0.7926 - val_loss: 0.1842 - val_accuracy: 0.7636\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1505 - accuracy: 0.7926 - val_loss: 0.1860 - val_accuracy: 0.7455\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1573 - accuracy: 0.8018 - val_loss: 0.1869 - val_accuracy: 0.7455\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1646 - accuracy: 0.7834 - val_loss: 0.1841 - val_accuracy: 0.7455\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1483 - accuracy: 0.8111 - val_loss: 0.1840 - val_accuracy: 0.7636\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1602 - accuracy: 0.7834 - val_loss: 0.1884 - val_accuracy: 0.7273\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1464 - accuracy: 0.8157 - val_loss: 0.1872 - val_accuracy: 0.7455\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1536 - accuracy: 0.7880 - val_loss: 0.1843 - val_accuracy: 0.7273\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1450 - accuracy: 0.8018 - val_loss: 0.1825 - val_accuracy: 0.7091\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1404 - accuracy: 0.8065 - val_loss: 0.1831 - val_accuracy: 0.7091\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1488 - accuracy: 0.7972 - val_loss: 0.1842 - val_accuracy: 0.7091\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1412 - accuracy: 0.7926 - val_loss: 0.1830 - val_accuracy: 0.6909\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1387 - accuracy: 0.8065 - val_loss: 0.1816 - val_accuracy: 0.6909\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1433 - accuracy: 0.8157 - val_loss: 0.1812 - val_accuracy: 0.7091\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1381 - accuracy: 0.8111 - val_loss: 0.1801 - val_accuracy: 0.7091\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1443 - accuracy: 0.8018 - val_loss: 0.1804 - val_accuracy: 0.7091\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1289 - accuracy: 0.8065 - val_loss: 0.1807 - val_accuracy: 0.7091\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1430 - accuracy: 0.8295 - val_loss: 0.1802 - val_accuracy: 0.7091\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1301 - accuracy: 0.8387 - val_loss: 0.1787 - val_accuracy: 0.6909\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1515 - accuracy: 0.7696 - val_loss: 0.1784 - val_accuracy: 0.6727\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1379 - accuracy: 0.8065 - val_loss: 0.1811 - val_accuracy: 0.6909\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1334 - accuracy: 0.8157 - val_loss: 0.1805 - val_accuracy: 0.6909\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1348 - accuracy: 0.8203 - val_loss: 0.1835 - val_accuracy: 0.6727\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1451 - accuracy: 0.8018 - val_loss: 0.1857 - val_accuracy: 0.6909\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1319 - accuracy: 0.8157 - val_loss: 0.1850 - val_accuracy: 0.6909\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1337 - accuracy: 0.7742 - val_loss: 0.1863 - val_accuracy: 0.6909\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1388 - accuracy: 0.8111 - val_loss: 0.1858 - val_accuracy: 0.6909\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1239 - accuracy: 0.8387 - val_loss: 0.1852 - val_accuracy: 0.6909\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 0.8341 - val_loss: 0.1851 - val_accuracy: 0.6909\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1336 - accuracy: 0.8157 - val_loss: 0.1856 - val_accuracy: 0.6909\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1254 - accuracy: 0.8341 - val_loss: 0.1859 - val_accuracy: 0.7091\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1360 - accuracy: 0.8018 - val_loss: 0.1847 - val_accuracy: 0.7091\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1227 - accuracy: 0.8341 - val_loss: 0.1834 - val_accuracy: 0.6727\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.8433 - val_loss: 0.1835 - val_accuracy: 0.6727\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1277 - accuracy: 0.8341 - val_loss: 0.1834 - val_accuracy: 0.6727\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1178 - accuracy: 0.8387 - val_loss: 0.1829 - val_accuracy: 0.6727\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1245 - accuracy: 0.8249 - val_loss: 0.1858 - val_accuracy: 0.7091\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1196 - accuracy: 0.8341 - val_loss: 0.1846 - val_accuracy: 0.6909\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1272 - accuracy: 0.8203 - val_loss: 0.1842 - val_accuracy: 0.7091\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.8525 - val_loss: 0.1845 - val_accuracy: 0.7091\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1254 - accuracy: 0.8295 - val_loss: 0.1848 - val_accuracy: 0.6727\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1055 - accuracy: 0.8571 - val_loss: 0.1866 - val_accuracy: 0.7091\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.8710 - val_loss: 0.1874 - val_accuracy: 0.7091\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1173 - accuracy: 0.8479 - val_loss: 0.1859 - val_accuracy: 0.6909\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1176 - accuracy: 0.8571 - val_loss: 0.1858 - val_accuracy: 0.6727\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.8571 - val_loss: 0.1883 - val_accuracy: 0.7091\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.8111 - val_loss: 0.1881 - val_accuracy: 0.7091\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1127 - accuracy: 0.8710 - val_loss: 0.1878 - val_accuracy: 0.7091\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1154 - accuracy: 0.8571 - val_loss: 0.1855 - val_accuracy: 0.6727\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.8571 - val_loss: 0.1848 - val_accuracy: 0.6909\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.8203 - val_loss: 0.1860 - val_accuracy: 0.6727\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 0.8571 - val_loss: 0.1897 - val_accuracy: 0.7091\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.8387 - val_loss: 0.1930 - val_accuracy: 0.7273\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1101 - accuracy: 0.8571 - val_loss: 0.1898 - val_accuracy: 0.7091\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.8710 - val_loss: 0.1867 - val_accuracy: 0.7091\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0978 - accuracy: 0.8848 - val_loss: 0.1861 - val_accuracy: 0.6909\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1066 - accuracy: 0.8618 - val_loss: 0.1869 - val_accuracy: 0.7091\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1089 - accuracy: 0.8479 - val_loss: 0.1863 - val_accuracy: 0.7091\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1001 - accuracy: 0.8618 - val_loss: 0.1846 - val_accuracy: 0.7091\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1045 - accuracy: 0.8756 - val_loss: 0.1850 - val_accuracy: 0.7091\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1062 - accuracy: 0.8387 - val_loss: 0.1865 - val_accuracy: 0.7091\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.8571 - val_loss: 0.1874 - val_accuracy: 0.7091\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0990 - accuracy: 0.8618 - val_loss: 0.1899 - val_accuracy: 0.7091\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1107 - accuracy: 0.8571 - val_loss: 0.1899 - val_accuracy: 0.7091\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1000 - accuracy: 0.8710 - val_loss: 0.1888 - val_accuracy: 0.6727\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1165 - accuracy: 0.8433 - val_loss: 0.1893 - val_accuracy: 0.7091\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1061 - accuracy: 0.8710 - val_loss: 0.1870 - val_accuracy: 0.6727\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1000 - accuracy: 0.8756 - val_loss: 0.1874 - val_accuracy: 0.6909\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0951 - accuracy: 0.8940 - val_loss: 0.1903 - val_accuracy: 0.7091\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.8848 - val_loss: 0.1914 - val_accuracy: 0.7273\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.8986 - val_loss: 0.1851 - val_accuracy: 0.7091\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1073 - accuracy: 0.8479 - val_loss: 0.1834 - val_accuracy: 0.7273\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.8986 - val_loss: 0.1842 - val_accuracy: 0.7273\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1082 - accuracy: 0.8571 - val_loss: 0.1831 - val_accuracy: 0.7273\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1017 - accuracy: 0.8756 - val_loss: 0.1827 - val_accuracy: 0.7091\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1044 - accuracy: 0.8618 - val_loss: 0.1832 - val_accuracy: 0.7091\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1020 - accuracy: 0.8710 - val_loss: 0.1864 - val_accuracy: 0.7455\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.8986 - val_loss: 0.1884 - val_accuracy: 0.7273\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1041 - accuracy: 0.8756 - val_loss: 0.1865 - val_accuracy: 0.7273\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1039 - accuracy: 0.8387 - val_loss: 0.1887 - val_accuracy: 0.7273\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.8710 - val_loss: 0.1899 - val_accuracy: 0.7273\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0924 - accuracy: 0.8848 - val_loss: 0.1902 - val_accuracy: 0.7273\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0874 - accuracy: 0.8940 - val_loss: 0.1891 - val_accuracy: 0.7091\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0974 - accuracy: 0.8894 - val_loss: 0.1887 - val_accuracy: 0.7091\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0943 - accuracy: 0.8802 - val_loss: 0.1899 - val_accuracy: 0.6909\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0932 - accuracy: 0.8756 - val_loss: 0.1893 - val_accuracy: 0.7091\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0910 - accuracy: 0.9032 - val_loss: 0.1943 - val_accuracy: 0.7091\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0852 - accuracy: 0.8802 - val_loss: 0.1952 - val_accuracy: 0.7091\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0887 - accuracy: 0.9078 - val_loss: 0.1931 - val_accuracy: 0.7091\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0850 - accuracy: 0.9032 - val_loss: 0.1910 - val_accuracy: 0.7273\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1031 - accuracy: 0.8802 - val_loss: 0.1935 - val_accuracy: 0.7091\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0942 - accuracy: 0.8710 - val_loss: 0.1969 - val_accuracy: 0.7091\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0885 - accuracy: 0.8986 - val_loss: 0.1950 - val_accuracy: 0.6909\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0862 - accuracy: 0.9171 - val_loss: 0.1951 - val_accuracy: 0.6909\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9032 - val_loss: 0.1971 - val_accuracy: 0.7091\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9078 - val_loss: 0.1981 - val_accuracy: 0.7091\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0959 - accuracy: 0.8848 - val_loss: 0.1996 - val_accuracy: 0.7273\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0940 - accuracy: 0.8940 - val_loss: 0.2011 - val_accuracy: 0.7091\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 0.8986 - val_loss: 0.1998 - val_accuracy: 0.7091\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0840 - accuracy: 0.9078 - val_loss: 0.2027 - val_accuracy: 0.7091\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0835 - accuracy: 0.9078 - val_loss: 0.2081 - val_accuracy: 0.7273\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0916 - accuracy: 0.8986 - val_loss: 0.2015 - val_accuracy: 0.7091\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0921 - accuracy: 0.8940 - val_loss: 0.2006 - val_accuracy: 0.7091\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0909 - accuracy: 0.8848 - val_loss: 0.2008 - val_accuracy: 0.7273\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.8986 - val_loss: 0.2007 - val_accuracy: 0.7273\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0897 - accuracy: 0.8848 - val_loss: 0.1995 - val_accuracy: 0.7273\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9078 - val_loss: 0.2009 - val_accuracy: 0.7273\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.8894 - val_loss: 0.2037 - val_accuracy: 0.7091\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0867 - accuracy: 0.9032 - val_loss: 0.2033 - val_accuracy: 0.7091\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9263 - val_loss: 0.2024 - val_accuracy: 0.7273\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.8940 - val_loss: 0.2037 - val_accuracy: 0.7273\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0777 - accuracy: 0.9171 - val_loss: 0.2045 - val_accuracy: 0.7091\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0877 - accuracy: 0.8894 - val_loss: 0.2022 - val_accuracy: 0.7091\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9078 - val_loss: 0.2007 - val_accuracy: 0.7273\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9217 - val_loss: 0.2017 - val_accuracy: 0.7091\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 0.9217 - val_loss: 0.1967 - val_accuracy: 0.7273\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.9263 - val_loss: 0.1943 - val_accuracy: 0.7273\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0631 - accuracy: 0.9171 - val_loss: 0.1969 - val_accuracy: 0.7273\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0840 - accuracy: 0.9032 - val_loss: 0.1989 - val_accuracy: 0.7273\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9032 - val_loss: 0.1960 - val_accuracy: 0.7273\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0759 - accuracy: 0.9263 - val_loss: 0.1964 - val_accuracy: 0.7273\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0787 - accuracy: 0.9078 - val_loss: 0.1989 - val_accuracy: 0.7091\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.8894 - val_loss: 0.2010 - val_accuracy: 0.7091\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0714 - accuracy: 0.9171 - val_loss: 0.2064 - val_accuracy: 0.7091\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0877 - accuracy: 0.8986 - val_loss: 0.2045 - val_accuracy: 0.7091\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0807 - accuracy: 0.9078 - val_loss: 0.2035 - val_accuracy: 0.6909\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9171 - val_loss: 0.2058 - val_accuracy: 0.6909\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0777 - accuracy: 0.9078 - val_loss: 0.2131 - val_accuracy: 0.7091\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9263 - val_loss: 0.2083 - val_accuracy: 0.6909\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0820 - accuracy: 0.8986 - val_loss: 0.2066 - val_accuracy: 0.6909\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.9355 - val_loss: 0.2084 - val_accuracy: 0.7091\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0763 - accuracy: 0.9032 - val_loss: 0.2080 - val_accuracy: 0.6909\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.9124 - val_loss: 0.2039 - val_accuracy: 0.6909\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.9309 - val_loss: 0.2035 - val_accuracy: 0.7091\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0701 - accuracy: 0.9078 - val_loss: 0.2033 - val_accuracy: 0.6909\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0643 - accuracy: 0.9355 - val_loss: 0.2033 - val_accuracy: 0.7091\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.9171 - val_loss: 0.2065 - val_accuracy: 0.7091\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0659 - accuracy: 0.9217 - val_loss: 0.2051 - val_accuracy: 0.7091\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0652 - accuracy: 0.9309 - val_loss: 0.2073 - val_accuracy: 0.7091\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9171 - val_loss: 0.2114 - val_accuracy: 0.7091\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0698 - accuracy: 0.9401 - val_loss: 0.2143 - val_accuracy: 0.7091\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0636 - accuracy: 0.9309 - val_loss: 0.2169 - val_accuracy: 0.7091\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0685 - accuracy: 0.9263 - val_loss: 0.2123 - val_accuracy: 0.6909\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9309 - val_loss: 0.2117 - val_accuracy: 0.6909\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0627 - accuracy: 0.9447 - val_loss: 0.2129 - val_accuracy: 0.7091\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.9263 - val_loss: 0.2078 - val_accuracy: 0.7091\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.9171 - val_loss: 0.2063 - val_accuracy: 0.7091\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9401 - val_loss: 0.2056 - val_accuracy: 0.6909\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0662 - accuracy: 0.9078 - val_loss: 0.2086 - val_accuracy: 0.7273\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0605 - accuracy: 0.9217 - val_loss: 0.2065 - val_accuracy: 0.7273\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0543 - accuracy: 0.9355 - val_loss: 0.2043 - val_accuracy: 0.7273\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0590 - accuracy: 0.9401 - val_loss: 0.2051 - val_accuracy: 0.7273\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.9124 - val_loss: 0.2060 - val_accuracy: 0.7273\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0753 - accuracy: 0.9124 - val_loss: 0.2079 - val_accuracy: 0.7091\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0532 - accuracy: 0.9631 - val_loss: 0.2071 - val_accuracy: 0.7273\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0616 - accuracy: 0.9309 - val_loss: 0.2062 - val_accuracy: 0.7091\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0663 - accuracy: 0.9263 - val_loss: 0.2083 - val_accuracy: 0.6909\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0578 - accuracy: 0.9355 - val_loss: 0.2108 - val_accuracy: 0.6909\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0675 - accuracy: 0.9217 - val_loss: 0.2075 - val_accuracy: 0.7091\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0613 - accuracy: 0.9447 - val_loss: 0.2068 - val_accuracy: 0.7091\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.9309 - val_loss: 0.2068 - val_accuracy: 0.7091\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0611 - accuracy: 0.9401 - val_loss: 0.2101 - val_accuracy: 0.7273\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0602 - accuracy: 0.9355 - val_loss: 0.2116 - val_accuracy: 0.7273\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9217 - val_loss: 0.2100 - val_accuracy: 0.7273\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0669 - accuracy: 0.9171 - val_loss: 0.2119 - val_accuracy: 0.7273\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0549 - accuracy: 0.9447 - val_loss: 0.2114 - val_accuracy: 0.7273\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.9355 - val_loss: 0.2143 - val_accuracy: 0.7273\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0656 - accuracy: 0.9171 - val_loss: 0.2150 - val_accuracy: 0.7273\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0594 - accuracy: 0.9309 - val_loss: 0.2184 - val_accuracy: 0.7273\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9401 - val_loss: 0.2128 - val_accuracy: 0.7273\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.9309 - val_loss: 0.2154 - val_accuracy: 0.7273\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0639 - accuracy: 0.9493 - val_loss: 0.2140 - val_accuracy: 0.7091\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0594 - accuracy: 0.9309 - val_loss: 0.2122 - val_accuracy: 0.7273\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0615 - accuracy: 0.9263 - val_loss: 0.2128 - val_accuracy: 0.7091\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0625 - accuracy: 0.9309 - val_loss: 0.2086 - val_accuracy: 0.7091\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0701 - accuracy: 0.9124 - val_loss: 0.2091 - val_accuracy: 0.7091\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0535 - accuracy: 0.9447 - val_loss: 0.2150 - val_accuracy: 0.7091\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9309 - val_loss: 0.2134 - val_accuracy: 0.7091\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9401 - val_loss: 0.2148 - val_accuracy: 0.6909\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9191\n",
            "accuracy: [0.06990707665681839, 0.9191176295280457]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 10)                140       \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 30)                330       \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 30)                0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,751\n",
            "Trainable params: 1,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 25ms/step - loss: 0.2154 - accuracy: 0.7097 - val_loss: 0.2105 - val_accuracy: 0.6909\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1857 - accuracy: 0.7742 - val_loss: 0.2066 - val_accuracy: 0.6727\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1619 - accuracy: 0.7788 - val_loss: 0.2077 - val_accuracy: 0.6727\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1546 - accuracy: 0.8065 - val_loss: 0.2104 - val_accuracy: 0.6909\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1454 - accuracy: 0.8157 - val_loss: 0.2134 - val_accuracy: 0.6909\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1462 - accuracy: 0.8018 - val_loss: 0.2163 - val_accuracy: 0.6909\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1387 - accuracy: 0.8111 - val_loss: 0.2098 - val_accuracy: 0.6909\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1375 - accuracy: 0.8249 - val_loss: 0.2136 - val_accuracy: 0.6727\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1228 - accuracy: 0.8571 - val_loss: 0.2130 - val_accuracy: 0.7091\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1400 - accuracy: 0.8157 - val_loss: 0.2145 - val_accuracy: 0.7091\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1287 - accuracy: 0.8433 - val_loss: 0.2126 - val_accuracy: 0.7091\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1303 - accuracy: 0.8341 - val_loss: 0.2060 - val_accuracy: 0.7091\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1307 - accuracy: 0.8479 - val_loss: 0.2046 - val_accuracy: 0.7091\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1280 - accuracy: 0.8387 - val_loss: 0.2049 - val_accuracy: 0.7091\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1190 - accuracy: 0.8571 - val_loss: 0.2035 - val_accuracy: 0.7273\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1205 - accuracy: 0.8571 - val_loss: 0.2004 - val_accuracy: 0.7273\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1197 - accuracy: 0.8341 - val_loss: 0.1954 - val_accuracy: 0.7455\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1199 - accuracy: 0.8433 - val_loss: 0.1977 - val_accuracy: 0.7273\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1162 - accuracy: 0.8571 - val_loss: 0.2014 - val_accuracy: 0.7091\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1118 - accuracy: 0.8525 - val_loss: 0.1984 - val_accuracy: 0.7455\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1185 - accuracy: 0.8433 - val_loss: 0.2033 - val_accuracy: 0.7273\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1161 - accuracy: 0.8341 - val_loss: 0.2047 - val_accuracy: 0.7273\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1095 - accuracy: 0.8618 - val_loss: 0.2089 - val_accuracy: 0.7273\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1018 - accuracy: 0.8848 - val_loss: 0.2104 - val_accuracy: 0.7455\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1083 - accuracy: 0.8479 - val_loss: 0.2117 - val_accuracy: 0.7455\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1082 - accuracy: 0.8525 - val_loss: 0.2097 - val_accuracy: 0.7455\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1074 - accuracy: 0.8618 - val_loss: 0.2147 - val_accuracy: 0.7273\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1154 - accuracy: 0.8433 - val_loss: 0.2111 - val_accuracy: 0.7455\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1100 - accuracy: 0.8618 - val_loss: 0.2029 - val_accuracy: 0.7636\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.8664 - val_loss: 0.2038 - val_accuracy: 0.7636\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1091 - accuracy: 0.8618 - val_loss: 0.2044 - val_accuracy: 0.7636\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1027 - accuracy: 0.8802 - val_loss: 0.2037 - val_accuracy: 0.7636\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1012 - accuracy: 0.8802 - val_loss: 0.2047 - val_accuracy: 0.7455\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9032 - val_loss: 0.2167 - val_accuracy: 0.7091\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.8756 - val_loss: 0.2108 - val_accuracy: 0.7455\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0979 - accuracy: 0.8756 - val_loss: 0.2025 - val_accuracy: 0.7636\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0909 - accuracy: 0.8848 - val_loss: 0.2053 - val_accuracy: 0.7455\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1020 - accuracy: 0.8848 - val_loss: 0.2080 - val_accuracy: 0.7455\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.8710 - val_loss: 0.2019 - val_accuracy: 0.7455\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0984 - accuracy: 0.8710 - val_loss: 0.2039 - val_accuracy: 0.7273\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1075 - accuracy: 0.8664 - val_loss: 0.2063 - val_accuracy: 0.7273\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0918 - accuracy: 0.9078 - val_loss: 0.2060 - val_accuracy: 0.7636\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0861 - accuracy: 0.9032 - val_loss: 0.2061 - val_accuracy: 0.7818\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0885 - accuracy: 0.8894 - val_loss: 0.2038 - val_accuracy: 0.7636\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9078 - val_loss: 0.2075 - val_accuracy: 0.7455\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.8940 - val_loss: 0.2120 - val_accuracy: 0.7455\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 0.9124 - val_loss: 0.2191 - val_accuracy: 0.7818\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0916 - accuracy: 0.8894 - val_loss: 0.2121 - val_accuracy: 0.7455\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0988 - accuracy: 0.8710 - val_loss: 0.2141 - val_accuracy: 0.7455\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0934 - accuracy: 0.8756 - val_loss: 0.2135 - val_accuracy: 0.8000\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.8571 - val_loss: 0.2128 - val_accuracy: 0.8000\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.8848 - val_loss: 0.2114 - val_accuracy: 0.8000\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0862 - accuracy: 0.8756 - val_loss: 0.2049 - val_accuracy: 0.8000\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0903 - accuracy: 0.8894 - val_loss: 0.2021 - val_accuracy: 0.8000\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0916 - accuracy: 0.8848 - val_loss: 0.1930 - val_accuracy: 0.7818\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0863 - accuracy: 0.8940 - val_loss: 0.1931 - val_accuracy: 0.8000\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0916 - accuracy: 0.8986 - val_loss: 0.1986 - val_accuracy: 0.7818\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0826 - accuracy: 0.8986 - val_loss: 0.1967 - val_accuracy: 0.7818\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0842 - accuracy: 0.9032 - val_loss: 0.1998 - val_accuracy: 0.7818\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0925 - accuracy: 0.8848 - val_loss: 0.2079 - val_accuracy: 0.8000\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0913 - accuracy: 0.8940 - val_loss: 0.2054 - val_accuracy: 0.8000\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0850 - accuracy: 0.8940 - val_loss: 0.2023 - val_accuracy: 0.8000\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.8802 - val_loss: 0.2058 - val_accuracy: 0.8000\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0851 - accuracy: 0.9032 - val_loss: 0.2033 - val_accuracy: 0.8000\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9078 - val_loss: 0.2097 - val_accuracy: 0.8000\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0818 - accuracy: 0.9171 - val_loss: 0.2145 - val_accuracy: 0.8000\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0788 - accuracy: 0.9078 - val_loss: 0.2072 - val_accuracy: 0.8000\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0903 - accuracy: 0.8894 - val_loss: 0.2092 - val_accuracy: 0.8000\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9032 - val_loss: 0.2115 - val_accuracy: 0.8000\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9032 - val_loss: 0.2071 - val_accuracy: 0.7818\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0832 - accuracy: 0.8940 - val_loss: 0.2101 - val_accuracy: 0.7818\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0832 - accuracy: 0.8940 - val_loss: 0.2158 - val_accuracy: 0.7818\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0790 - accuracy: 0.8664 - val_loss: 0.2142 - val_accuracy: 0.7818\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0761 - accuracy: 0.9171 - val_loss: 0.2091 - val_accuracy: 0.7818\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0782 - accuracy: 0.9124 - val_loss: 0.2084 - val_accuracy: 0.7818\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0797 - accuracy: 0.8894 - val_loss: 0.2095 - val_accuracy: 0.7636\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0803 - accuracy: 0.9078 - val_loss: 0.2091 - val_accuracy: 0.7636\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9032 - val_loss: 0.2076 - val_accuracy: 0.7818\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0863 - accuracy: 0.8940 - val_loss: 0.2080 - val_accuracy: 0.7636\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.9078 - val_loss: 0.2117 - val_accuracy: 0.7636\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9124 - val_loss: 0.2092 - val_accuracy: 0.7818\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9032 - val_loss: 0.2116 - val_accuracy: 0.7636\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.8848 - val_loss: 0.2139 - val_accuracy: 0.7818\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9124 - val_loss: 0.2126 - val_accuracy: 0.7818\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9032 - val_loss: 0.2144 - val_accuracy: 0.7818\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.8710 - val_loss: 0.2165 - val_accuracy: 0.7818\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9217 - val_loss: 0.2184 - val_accuracy: 0.7636\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0800 - accuracy: 0.9032 - val_loss: 0.2140 - val_accuracy: 0.7636\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0793 - accuracy: 0.8986 - val_loss: 0.2189 - val_accuracy: 0.7455\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0719 - accuracy: 0.9171 - val_loss: 0.2175 - val_accuracy: 0.7273\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0743 - accuracy: 0.9078 - val_loss: 0.2157 - val_accuracy: 0.7455\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.9171 - val_loss: 0.2160 - val_accuracy: 0.7273\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0700 - accuracy: 0.9263 - val_loss: 0.2157 - val_accuracy: 0.7455\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0699 - accuracy: 0.9124 - val_loss: 0.2055 - val_accuracy: 0.7636\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0662 - accuracy: 0.9217 - val_loss: 0.2020 - val_accuracy: 0.7818\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0775 - accuracy: 0.9124 - val_loss: 0.2074 - val_accuracy: 0.7636\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0662 - accuracy: 0.9217 - val_loss: 0.2080 - val_accuracy: 0.7818\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0679 - accuracy: 0.9263 - val_loss: 0.2083 - val_accuracy: 0.7818\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0737 - accuracy: 0.9171 - val_loss: 0.2143 - val_accuracy: 0.7273\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0718 - accuracy: 0.9124 - val_loss: 0.2110 - val_accuracy: 0.7636\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0708 - accuracy: 0.9217 - val_loss: 0.2154 - val_accuracy: 0.7273\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0674 - accuracy: 0.9217 - val_loss: 0.2228 - val_accuracy: 0.7091\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0623 - accuracy: 0.9309 - val_loss: 0.2218 - val_accuracy: 0.7091\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0798 - accuracy: 0.8940 - val_loss: 0.2087 - val_accuracy: 0.7818\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0721 - accuracy: 0.9217 - val_loss: 0.2021 - val_accuracy: 0.8000\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0696 - accuracy: 0.9263 - val_loss: 0.2001 - val_accuracy: 0.7818\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.9309 - val_loss: 0.1965 - val_accuracy: 0.7818\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0713 - accuracy: 0.9078 - val_loss: 0.2051 - val_accuracy: 0.7636\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9309 - val_loss: 0.2069 - val_accuracy: 0.7636\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.9401 - val_loss: 0.2097 - val_accuracy: 0.7818\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9078 - val_loss: 0.2015 - val_accuracy: 0.7818\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0601 - accuracy: 0.9447 - val_loss: 0.2024 - val_accuracy: 0.7455\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.9171 - val_loss: 0.2091 - val_accuracy: 0.7273\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0629 - accuracy: 0.9309 - val_loss: 0.2094 - val_accuracy: 0.7091\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0626 - accuracy: 0.9124 - val_loss: 0.2105 - val_accuracy: 0.7273\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0621 - accuracy: 0.9309 - val_loss: 0.2109 - val_accuracy: 0.7455\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0624 - accuracy: 0.9263 - val_loss: 0.2097 - val_accuracy: 0.7273\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0667 - accuracy: 0.9171 - val_loss: 0.2163 - val_accuracy: 0.7273\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0659 - accuracy: 0.9355 - val_loss: 0.2176 - val_accuracy: 0.7091\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0662 - accuracy: 0.9124 - val_loss: 0.2123 - val_accuracy: 0.7455\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0784 - accuracy: 0.9032 - val_loss: 0.2124 - val_accuracy: 0.7455\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0593 - accuracy: 0.9309 - val_loss: 0.2162 - val_accuracy: 0.7273\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0611 - accuracy: 0.9263 - val_loss: 0.2149 - val_accuracy: 0.7273\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0648 - accuracy: 0.9171 - val_loss: 0.2169 - val_accuracy: 0.7273\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0569 - accuracy: 0.9493 - val_loss: 0.2158 - val_accuracy: 0.7273\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0679 - accuracy: 0.9355 - val_loss: 0.2041 - val_accuracy: 0.7636\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0611 - accuracy: 0.9309 - val_loss: 0.2012 - val_accuracy: 0.7636\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0739 - accuracy: 0.9124 - val_loss: 0.2007 - val_accuracy: 0.7636\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0684 - accuracy: 0.9171 - val_loss: 0.2053 - val_accuracy: 0.7273\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0700 - accuracy: 0.9078 - val_loss: 0.2088 - val_accuracy: 0.7273\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0576 - accuracy: 0.9355 - val_loss: 0.2139 - val_accuracy: 0.7273\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0577 - accuracy: 0.9355 - val_loss: 0.2120 - val_accuracy: 0.7273\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0687 - accuracy: 0.9217 - val_loss: 0.2078 - val_accuracy: 0.7455\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 0.9263 - val_loss: 0.2044 - val_accuracy: 0.7455\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0598 - accuracy: 0.9401 - val_loss: 0.2056 - val_accuracy: 0.7636\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0660 - accuracy: 0.9309 - val_loss: 0.2030 - val_accuracy: 0.7455\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9309 - val_loss: 0.2069 - val_accuracy: 0.7636\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9401 - val_loss: 0.1996 - val_accuracy: 0.7636\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0519 - accuracy: 0.9447 - val_loss: 0.1943 - val_accuracy: 0.7636\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0675 - accuracy: 0.9217 - val_loss: 0.1970 - val_accuracy: 0.7636\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0696 - accuracy: 0.8940 - val_loss: 0.2076 - val_accuracy: 0.7636\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0580 - accuracy: 0.9309 - val_loss: 0.2058 - val_accuracy: 0.7455\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0605 - accuracy: 0.9309 - val_loss: 0.2099 - val_accuracy: 0.7273\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0585 - accuracy: 0.9263 - val_loss: 0.2167 - val_accuracy: 0.7091\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0641 - accuracy: 0.9217 - val_loss: 0.2067 - val_accuracy: 0.7455\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9493 - val_loss: 0.2045 - val_accuracy: 0.7455\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0541 - accuracy: 0.9447 - val_loss: 0.2116 - val_accuracy: 0.7273\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0531 - accuracy: 0.9493 - val_loss: 0.2176 - val_accuracy: 0.7273\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0586 - accuracy: 0.9263 - val_loss: 0.2055 - val_accuracy: 0.7636\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0508 - accuracy: 0.9539 - val_loss: 0.2090 - val_accuracy: 0.7273\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0577 - accuracy: 0.9263 - val_loss: 0.2100 - val_accuracy: 0.7273\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0560 - accuracy: 0.9309 - val_loss: 0.2170 - val_accuracy: 0.7455\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0571 - accuracy: 0.9355 - val_loss: 0.2226 - val_accuracy: 0.7273\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0652 - accuracy: 0.9309 - val_loss: 0.2263 - val_accuracy: 0.7273\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9217 - val_loss: 0.2164 - val_accuracy: 0.7455\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9447 - val_loss: 0.2147 - val_accuracy: 0.7455\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0541 - accuracy: 0.9401 - val_loss: 0.2074 - val_accuracy: 0.7455\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9401 - val_loss: 0.2036 - val_accuracy: 0.7636\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0504 - accuracy: 0.9447 - val_loss: 0.2070 - val_accuracy: 0.7455\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0600 - accuracy: 0.9309 - val_loss: 0.2044 - val_accuracy: 0.7636\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0619 - accuracy: 0.9217 - val_loss: 0.2035 - val_accuracy: 0.7636\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9309 - val_loss: 0.2060 - val_accuracy: 0.7636\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.9217 - val_loss: 0.2146 - val_accuracy: 0.7455\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9355 - val_loss: 0.2168 - val_accuracy: 0.7455\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9309 - val_loss: 0.2185 - val_accuracy: 0.7273\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0544 - accuracy: 0.9309 - val_loss: 0.2154 - val_accuracy: 0.7273\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9401 - val_loss: 0.2066 - val_accuracy: 0.7455\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0496 - accuracy: 0.9493 - val_loss: 0.2017 - val_accuracy: 0.7636\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0562 - accuracy: 0.9309 - val_loss: 0.2077 - val_accuracy: 0.7455\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0604 - accuracy: 0.9263 - val_loss: 0.2132 - val_accuracy: 0.7455\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0514 - accuracy: 0.9447 - val_loss: 0.2171 - val_accuracy: 0.7273\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0466 - accuracy: 0.9539 - val_loss: 0.2177 - val_accuracy: 0.7273\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9677 - val_loss: 0.2211 - val_accuracy: 0.7273\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0555 - accuracy: 0.9401 - val_loss: 0.2173 - val_accuracy: 0.7273\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0581 - accuracy: 0.9401 - val_loss: 0.2168 - val_accuracy: 0.7273\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0432 - accuracy: 0.9631 - val_loss: 0.2225 - val_accuracy: 0.7273\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.9401 - val_loss: 0.2089 - val_accuracy: 0.7455\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0485 - accuracy: 0.9493 - val_loss: 0.2065 - val_accuracy: 0.7636\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0499 - accuracy: 0.9493 - val_loss: 0.2005 - val_accuracy: 0.7636\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0590 - accuracy: 0.9263 - val_loss: 0.2078 - val_accuracy: 0.7636\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0516 - accuracy: 0.9447 - val_loss: 0.2131 - val_accuracy: 0.7636\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9355 - val_loss: 0.2158 - val_accuracy: 0.7636\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9309 - val_loss: 0.2194 - val_accuracy: 0.7455\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0536 - accuracy: 0.9493 - val_loss: 0.2159 - val_accuracy: 0.7636\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.9263 - val_loss: 0.2129 - val_accuracy: 0.7636\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0598 - accuracy: 0.9309 - val_loss: 0.2149 - val_accuracy: 0.7636\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9585 - val_loss: 0.2139 - val_accuracy: 0.7636\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0496 - accuracy: 0.9447 - val_loss: 0.2177 - val_accuracy: 0.7455\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0484 - accuracy: 0.9493 - val_loss: 0.2212 - val_accuracy: 0.7455\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0519 - accuracy: 0.9355 - val_loss: 0.2303 - val_accuracy: 0.7273\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0468 - accuracy: 0.9447 - val_loss: 0.2224 - val_accuracy: 0.7455\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.9355 - val_loss: 0.2229 - val_accuracy: 0.7455\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9539 - val_loss: 0.2254 - val_accuracy: 0.7273\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9078 - val_loss: 0.2179 - val_accuracy: 0.7273\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0489 - accuracy: 0.9355 - val_loss: 0.2096 - val_accuracy: 0.7273\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0470 - accuracy: 0.9585 - val_loss: 0.2078 - val_accuracy: 0.7455\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0492 - accuracy: 0.9539 - val_loss: 0.2115 - val_accuracy: 0.7455\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0494 - accuracy: 0.9355 - val_loss: 0.2176 - val_accuracy: 0.7455\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0512 - accuracy: 0.9493 - val_loss: 0.2208 - val_accuracy: 0.7455\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0475 - accuracy: 0.9493 - val_loss: 0.2179 - val_accuracy: 0.7455\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9301\n",
            "accuracy: [0.06705980002880096, 0.9301470518112183]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_test, y_test, epochs= 200, batch_size=30)\n",
        "loss = model.evaluate(x_test,y_test)\n",
        "print('accuracy:',loss)"
      ],
      "metadata": {
        "id": "uTiis-hA9_HA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}